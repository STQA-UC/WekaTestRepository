<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>Evaluation.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers</a> &gt; <span class="el_source">Evaluation.java</span></div><h1>Evaluation.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    Evaluation.java
 *    Copyright (C) 1999 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.classifiers;

import weka.classifiers.evaluation.NominalPrediction;
import weka.classifiers.evaluation.ThresholdCurve;
import weka.classifiers.pmml.consumer.PMMLClassifier;
import weka.classifiers.xml.XMLClassifier;
import weka.core.Drawable;
import weka.core.FastVector;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.OptionHandler;
import weka.core.Range;
import weka.core.RevisionHandler;
import weka.core.RevisionUtils;
import weka.core.Summarizable;
import weka.core.Utils;
import weka.core.Version;
import weka.core.converters.ConverterUtils.DataSink;
import weka.core.converters.ConverterUtils.DataSource;
import weka.core.pmml.PMMLFactory;
import weka.core.pmml.PMMLModel;
import weka.core.xml.KOML;
import weka.core.xml.XMLOptions;
import weka.core.xml.XMLSerialization;
import weka.estimators.Estimator;
import weka.estimators.KernelEstimator;

import java.beans.BeanInfo;
import java.beans.Introspector;
import java.beans.MethodDescriptor;
import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.InputStream;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.io.OutputStream;
import java.io.Reader;
import java.lang.reflect.Method;
import java.util.Date;
import java.util.Enumeration;
import java.util.Random;
import java.util.zip.GZIPInputStream;
import java.util.zip.GZIPOutputStream;

/**
 * Class for evaluating machine learning models. &lt;p/&gt;
 *
 * ------------------------------------------------------------------- &lt;p/&gt;
 *
 * General options when evaluating a learning scheme from the command-line: &lt;p/&gt;
 *
 * -t filename &lt;br/&gt;
 * Name of the file with the training data. (required) &lt;p/&gt;
 *
 * -T filename &lt;br/&gt;
 * Name of the file with the test data. If missing a cross-validation 
 * is performed. &lt;p/&gt;
 *
 * -c index &lt;br/&gt;
 * Index of the class attribute (1, 2, ...; default: last). &lt;p/&gt;
 *
 * -x number &lt;br/&gt;
 * The number of folds for the cross-validation (default: 10). &lt;p/&gt;
 *
 * -no-cv &lt;br/&gt;
 * No cross validation.  If no test file is provided, no evaluation
 * is done. &lt;p/&gt;
 * 
 * -split-percentage percentage &lt;br/&gt;
 * Sets the percentage for the train/test set split, e.g., 66. &lt;p/&gt;
 * 
 * -preserve-order &lt;br/&gt;
 * Preserves the order in the percentage split instead of randomizing
 * the data first with the seed value ('-s'). &lt;p/&gt;
 *
 * -s seed &lt;br/&gt;
 * Random number seed for the cross-validation and percentage split
 * (default: 1). &lt;p/&gt;
 *
 * -m filename &lt;br/&gt;
 * The name of a file containing a cost matrix. &lt;p/&gt;
 *
 * -l filename &lt;br/&gt;
 * Loads classifier from the given file. In case the filename ends with &quot;.xml&quot;, 
 * a PMML file is loaded or, if that fails, options are loaded from XML. &lt;p/&gt;
 *
 * -d filename &lt;br/&gt;
 * Saves classifier built from the training data into the given file. In case 
 * the filename ends with &quot;.xml&quot; the options are saved XML, not the model. &lt;p/&gt;
 *
 * -v &lt;br/&gt;
 * Outputs no statistics for the training data. &lt;p/&gt;
 *
 * -o &lt;br/&gt;
 * Outputs statistics only, not the classifier. &lt;p/&gt;
 * 
 * -i &lt;br/&gt;
 * Outputs information-retrieval statistics per class. &lt;p/&gt;
 *
 * -k &lt;br/&gt;
 * Outputs information-theoretic statistics. &lt;p/&gt;
 *
 * -p range &lt;br/&gt;
 * Outputs predictions for test instances (or the train instances if no test
 * instances provided and -no-cv is used), along with the attributes in the specified range 
 * (and nothing else). Use '-p 0' if no attributes are desired. &lt;p/&gt;
 * 
 * -distribution &lt;br/&gt;
 * Outputs the distribution instead of only the prediction
 * in conjunction with the '-p' option (only nominal classes). &lt;p/&gt;
 *
 * -r &lt;br/&gt;
 * Outputs cumulative margin distribution (and nothing else). &lt;p/&gt;
 *
 * -g &lt;br/&gt; 
 * Only for classifiers that implement &quot;Graphable.&quot; Outputs
 * the graph representation of the classifier (and nothing
 * else). &lt;p/&gt;
 * 
 * -xml filename | xml-string &lt;br/&gt;
 * Retrieves the options from the XML-data instead of the command line. &lt;p/&gt;
 * 
 * -threshold-file file &lt;br/&gt;
 * The file to save the threshold data to.
 * The format is determined by the extensions, e.g., '.arff' for ARFF
 * format or '.csv' for CSV. &lt;p/&gt;
 *         
 * -threshold-label label &lt;br/&gt;
 * The class label to determine the threshold data for
 * (default is the first label) &lt;p/&gt;
 *         
 * ------------------------------------------------------------------- &lt;p/&gt;
 *
 * Example usage as the main of a classifier (called FunkyClassifier):
 * &lt;code&gt; &lt;pre&gt;
 * public static void main(String [] args) {
 *   runClassifier(new FunkyClassifier(), args);
 * }
 * &lt;/pre&gt; &lt;/code&gt; 
 * &lt;p/&gt;
 *
 * ------------------------------------------------------------------ &lt;p/&gt;
 *
 * Example usage from within an application:
 * &lt;code&gt; &lt;pre&gt;
 * Instances trainInstances = ... instances got from somewhere
 * Instances testInstances = ... instances got from somewhere
 * Classifier scheme = ... scheme got from somewhere
 *
 * Evaluation evaluation = new Evaluation(trainInstances);
 * evaluation.evaluateModel(scheme, testInstances);
 * System.out.println(evaluation.toSummaryString());
 * &lt;/pre&gt; &lt;/code&gt; 
 *
 *
 * @author   Eibe Frank (eibe@cs.waikato.ac.nz)
 * @author   Len Trigg (trigg@cs.waikato.ac.nz)
 * @version  $Revision: 9196 $
 */
<span class="fc" id="L187">public class Evaluation</span>
  implements Summarizable, RevisionHandler {

  /** The number of classes. */
  protected int m_NumClasses;

  /** The number of folds for a cross-validation. */
  protected int m_NumFolds;

  /** The weight of all incorrectly classified instances. */
  protected double m_Incorrect;

  /** The weight of all correctly classified instances. */
  protected double m_Correct;

  /** The weight of all unclassified instances. */
  protected double m_Unclassified;

  /*** The weight of all instances that had no class assigned to them. */
  protected double m_MissingClass;

  /** The weight of all instances that had a class assigned to them. */
  protected double m_WithClass;

  /** Array for storing the confusion matrix. */
  protected double [][] m_ConfusionMatrix;

  /** The names of the classes. */
  protected String [] m_ClassNames;

  /** Is the class nominal or numeric? */
  protected boolean m_ClassIsNominal;

  /** The prior probabilities of the classes */
  protected double [] m_ClassPriors;

  /** The sum of counts for priors */
  protected double m_ClassPriorsSum;

  /** The cost matrix (if given). */
  protected CostMatrix m_CostMatrix;

  /** The total cost of predictions (includes instance weights) */
  protected double m_TotalCost;

  /** Sum of errors. */
  protected double m_SumErr;

  /** Sum of absolute errors. */
  protected double m_SumAbsErr;

  /** Sum of squared errors. */
  protected double m_SumSqrErr;

  /** Sum of class values. */
  protected double m_SumClass;

  /** Sum of squared class values. */
  protected double m_SumSqrClass;

  /*** Sum of predicted values. */
  protected double m_SumPredicted;

  /** Sum of squared predicted values. */
  protected double m_SumSqrPredicted;

  /** Sum of predicted * class values. */
  protected double m_SumClassPredicted;

  /** Sum of absolute errors of the prior */
  protected double m_SumPriorAbsErr;

  /** Sum of absolute errors of the prior */
  protected double m_SumPriorSqrErr;

  /** Total Kononenko &amp; Bratko Information */
  protected double m_SumKBInfo;

  /*** Resolution of the margin histogram */
<span class="fc" id="L266">  protected static int k_MarginResolution = 500;</span>

  /** Cumulative margin distribution */
  protected double m_MarginCounts [];

  /** Number of non-missing class training instances seen */
  protected int m_NumTrainClassVals;

  /** Array containing all numeric training class values seen */
  protected double [] m_TrainClassVals;

  /** Array containing all numeric training class weights */
  protected double [] m_TrainClassWeights;

  /** Numeric class error estimator for prior */
  protected Estimator m_PriorErrorEstimator;

  /** Numeric class error estimator for scheme */
  protected Estimator m_ErrorEstimator;

  /**
   * The minimum probablility accepted from an estimator to avoid
   * taking log(0) in Sf calculations.
   */
  protected static final double MIN_SF_PROB = Double.MIN_VALUE;

  /** Total entropy of prior predictions */
  protected double m_SumPriorEntropy;

  /** Total entropy of scheme predictions */
  protected double m_SumSchemeEntropy;

  /** The list of predictions that have been generated (for computing AUC) */
  private FastVector m_Predictions;

  /** enables/disables the use of priors, e.g., if no training set is
   * present in case of de-serialized schemes */
<span class="fc" id="L303">  protected boolean m_NoPriors = false;</span>

  /**
   * Initializes all the counters for the evaluation. 
   * Use &lt;code&gt;useNoPriors()&lt;/code&gt; if the dataset is the test set and you
   * can't initialize with the priors from the training set via 
   * &lt;code&gt;setPriors(Instances)&lt;/code&gt;.
   *
   * @param data 	set of training instances, to get some header 
   * 			information and prior class distribution information
   * @throws Exception 	if the class is not defined
   * @see 		#useNoPriors()
   * @see 		#setPriors(Instances)
   */
  public Evaluation(Instances data) throws Exception {

<span class="fc" id="L319">    this(data, null);</span>
<span class="fc" id="L320">  }</span>

  /**
   * Initializes all the counters for the evaluation and also takes a
   * cost matrix as parameter.
   * Use &lt;code&gt;useNoPriors()&lt;/code&gt; if the dataset is the test set and you
   * can't initialize with the priors from the training set via 
   * &lt;code&gt;setPriors(Instances)&lt;/code&gt;.
   *
   * @param data 	set of training instances, to get some header 
   * 			information and prior class distribution information
   * @param costMatrix 	the cost matrix---if null, default costs will be used
   * @throws Exception 	if cost matrix is not compatible with 
   * 			data, the class is not defined or the class is numeric
   * @see 		#useNoPriors()
   * @see 		#setPriors(Instances)
   */
<span class="fc" id="L337">  public Evaluation(Instances data, CostMatrix costMatrix) </span>
  throws Exception {

<span class="fc" id="L340">    m_NumClasses = data.numClasses();</span>
<span class="fc" id="L341">    m_NumFolds = 1;</span>
<span class="fc" id="L342">    m_ClassIsNominal = data.classAttribute().isNominal();</span>

<span class="fc bfc" id="L344" title="All 2 branches covered.">    if (m_ClassIsNominal) {</span>
<span class="fc" id="L345">      m_ConfusionMatrix = new double [m_NumClasses][m_NumClasses];</span>
<span class="fc" id="L346">      m_ClassNames = new String [m_NumClasses];</span>
<span class="fc bfc" id="L347" title="All 2 branches covered.">      for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="fc" id="L348">	m_ClassNames[i] = data.classAttribute().value(i);</span>
      }
    }
<span class="fc" id="L351">    m_CostMatrix = costMatrix;</span>
<span class="pc bpc" id="L352" title="1 of 2 branches missed.">    if (m_CostMatrix != null) {</span>
<span class="nc bnc" id="L353" title="All 2 branches missed.">      if (!m_ClassIsNominal) {</span>
<span class="nc" id="L354">	throw new Exception(&quot;Class has to be nominal if cost matrix &quot; + </span>
	&quot;given!&quot;);
      }
<span class="nc bnc" id="L357" title="All 2 branches missed.">      if (m_CostMatrix.size() != m_NumClasses) {</span>
<span class="nc" id="L358">	throw new Exception(&quot;Cost matrix not compatible with data!&quot;);</span>
      }
    }
<span class="fc" id="L361">    m_ClassPriors = new double [m_NumClasses];</span>
<span class="fc" id="L362">    setPriors(data);</span>
<span class="fc" id="L363">    m_MarginCounts = new double [k_MarginResolution + 1];</span>
<span class="fc" id="L364">  }</span>

  /**
   * Returns the area under ROC for those predictions that have been collected
   * in the evaluateClassifier(Classifier, Instances) method. Returns 
   * Instance.missingValue() if the area is not available.
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the area under the ROC curve or not a number
   */
  public double areaUnderROC(int classIndex) {

    // Check if any predictions have been collected
<span class="nc bnc" id="L377" title="All 2 branches missed.">    if (m_Predictions == null) {</span>
<span class="nc" id="L378">      return Instance.missingValue();</span>
    } else {
<span class="nc" id="L380">      ThresholdCurve tc = new ThresholdCurve();</span>
<span class="nc" id="L381">      Instances result = tc.getCurve(m_Predictions, classIndex);</span>
<span class="nc" id="L382">      return ThresholdCurve.getROCArea(result);</span>
    }
  }

  /**
   * Calculates the weighted (by class size) AUC.
   *
   * @return the weighted AUC.
   */
  public double weightedAreaUnderROC() {
<span class="nc" id="L392">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L393">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L395" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L396" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L397">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L399">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L402">    double aucTotal = 0;</span>
<span class="nc bnc" id="L403" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L404">      double temp = areaUnderROC(i);</span>
<span class="nc bnc" id="L405" title="All 2 branches missed.">      if (!Instance.isMissingValue(temp)) {</span>
<span class="nc" id="L406">        aucTotal += (temp * classCounts[i]);</span>
      }
    }

<span class="nc" id="L410">    return aucTotal / classCountSum;</span>
  }

  /**
   * Returns a copy of the confusion matrix.
   *
   * @return a copy of the confusion matrix as a two-dimensional array
   */
  public double[][] confusionMatrix() {

<span class="nc" id="L420">    double[][] newMatrix = new double[m_ConfusionMatrix.length][0];</span>

<span class="nc bnc" id="L422" title="All 2 branches missed.">    for (int i = 0; i &lt; m_ConfusionMatrix.length; i++) {</span>
<span class="nc" id="L423">      newMatrix[i] = new double[m_ConfusionMatrix[i].length];</span>
<span class="nc" id="L424">      System.arraycopy(m_ConfusionMatrix[i], 0, newMatrix[i], 0,</span>
<span class="nc" id="L425">	  m_ConfusionMatrix[i].length);</span>
    }
<span class="nc" id="L427">    return newMatrix;</span>
  }

  /**
   * Performs a (stratified if class is nominal) cross-validation 
   * for a classifier on a set of instances. Now performs
   * a deep copy of the classifier before each call to 
   * buildClassifier() (just in case the classifier is not
   * initialized properly).
   *
   * @param classifier the classifier with any options set.
   * @param data the data on which the cross-validation is to be 
   * performed 
   * @param numFolds the number of folds for the cross-validation
   * @param random random number generator for randomization 
   * @param forPredictionsString varargs parameter that, if supplied, is
   * expected to hold a StringBuffer to print predictions to, 
   * a Range of attributes to output and a Boolean (true if the distribution
   * is to be printed)
   * @throws Exception if a classifier could not be generated 
   * successfully or the class is not defined
   */
  public void crossValidateModel(Classifier classifier,
                                 Instances data, int numFolds, Random random,
                                 Object... forPredictionsPrinting) 
  throws Exception {

    // Make a copy of the data we can reorder
<span class="fc" id="L455">    data = new Instances(data);</span>
<span class="fc" id="L456">    data.randomize(random);</span>
<span class="fc bfc" id="L457" title="All 2 branches covered.">    if (data.classAttribute().isNominal()) {</span>
<span class="fc" id="L458">      data.stratify(numFolds);</span>
    }

    // We assume that the first element is a StringBuffer, the second a Range (attributes
    // to output) and the third a Boolean (whether or not to output a distribution instead
    // of just a classification)
<span class="pc bpc" id="L464" title="1 of 2 branches missed.">    if (forPredictionsPrinting.length &gt; 0) {</span>
      // print the header first
<span class="nc" id="L466">      StringBuffer buff = (StringBuffer)forPredictionsPrinting[0];</span>
<span class="nc" id="L467">      Range attsToOutput = (Range)forPredictionsPrinting[1];</span>
<span class="nc" id="L468">      boolean printDist = ((Boolean)forPredictionsPrinting[2]).booleanValue();</span>
<span class="nc" id="L469">      printClassificationsHeader(data, attsToOutput, printDist, buff);</span>
    }

    // Do the folds
<span class="fc bfc" id="L473" title="All 2 branches covered.">    for (int i = 0; i &lt; numFolds; i++) {</span>
<span class="fc" id="L474">      Instances train = data.trainCV(numFolds, i, random);</span>
<span class="fc" id="L475">      setPriors(train);</span>
<span class="fc" id="L476">      Classifier copiedClassifier = Classifier.makeCopy(classifier);</span>
<span class="fc" id="L477">      copiedClassifier.buildClassifier(train);</span>
<span class="fc" id="L478">      Instances test = data.testCV(numFolds, i);</span>
<span class="fc" id="L479">      evaluateModel(copiedClassifier, test, forPredictionsPrinting);</span>
    }
<span class="fc" id="L481">    m_NumFolds = numFolds;</span>
<span class="fc" id="L482">  }</span>

  /**
   * Performs a (stratified if class is nominal) cross-validation 
   * for a classifier on a set of instances.
   *
   * @param classifierString a string naming the class of the classifier
   * @param data the data on which the cross-validation is to be 
   * performed 
   * @param numFolds the number of folds for the cross-validation
   * @param options the options to the classifier. Any options
   * @param random the random number generator for randomizing the data
   * accepted by the classifier will be removed from this array.
   * @throws Exception if a classifier could not be generated 
   * successfully or the class is not defined
   */
  public void crossValidateModel(String classifierString,
      Instances data, int numFolds,
      String[] options, Random random) 
  throws Exception {

<span class="nc" id="L503">    crossValidateModel(Classifier.forName(classifierString, options),</span>
<span class="nc" id="L504">	data, numFolds, random);</span>
<span class="nc" id="L505">  }</span>

  /**
   * Evaluates a classifier with the options given in an array of
   * strings. &lt;p/&gt;
   *
   * Valid options are: &lt;p/&gt;
   *
   * -t filename &lt;br/&gt;
   * Name of the file with the training data. (required) &lt;p/&gt;
   *
   * -T filename &lt;br/&gt;
   * Name of the file with the test data. If missing a cross-validation 
   * is performed. &lt;p/&gt;
   *
   * -c index &lt;br/&gt;
   * Index of the class attribute (1, 2, ...; default: last). &lt;p/&gt;
   *
   * -x number &lt;br/&gt;
   * The number of folds for the cross-validation (default: 10). &lt;p/&gt;
   *
   * -no-cv &lt;br/&gt;
   * No cross validation.  If no test file is provided, no evaluation
   * is done. &lt;p/&gt;
   * 
   * -split-percentage percentage &lt;br/&gt;
   * Sets the percentage for the train/test set split, e.g., 66. &lt;p/&gt;
   * 
   * -preserve-order &lt;br/&gt;
   * Preserves the order in the percentage split instead of randomizing
   * the data first with the seed value ('-s'). &lt;p/&gt;
   *
   * -s seed &lt;br/&gt;
   * Random number seed for the cross-validation and percentage split
   * (default: 1). &lt;p/&gt;
   *
   * -m filename &lt;br/&gt;
   * The name of a file containing a cost matrix. &lt;p/&gt;
   *
   * -l filename &lt;br/&gt;
   * Loads classifier from the given file. In case the filename ends with
   * &quot;.xml&quot;,a PMML file is loaded or, if that fails, options are loaded from XML. &lt;p/&gt;
   *
   * -d filename &lt;br/&gt;
   * Saves classifier built from the training data into the given file. In case 
   * the filename ends with &quot;.xml&quot; the options are saved XML, not the model. &lt;p/&gt;
   *
   * -v &lt;br/&gt;
   * Outputs no statistics for the training data. &lt;p/&gt;
   *
   * -o &lt;br/&gt;
   * Outputs statistics only, not the classifier. &lt;p/&gt;
   * 
   * -i &lt;br/&gt;
   * Outputs detailed information-retrieval statistics per class. &lt;p/&gt;
   *
   * -k &lt;br/&gt;
   * Outputs information-theoretic statistics. &lt;p/&gt;
   *
   * -p range &lt;br/&gt;
   * Outputs predictions for test instances (or the train instances if no test
   * instances provided  and -no-cv is used), along with the attributes in the specified range (and 
   *  nothing else). Use '-p 0' if no attributes are desired. &lt;p/&gt;
   *
   * -distribution &lt;br/&gt;
   * Outputs the distribution instead of only the prediction
   * in conjunction with the '-p' option (only nominal classes). &lt;p/&gt;
   *
   * -r &lt;br/&gt;
   * Outputs cumulative margin distribution (and nothing else). &lt;p/&gt;
   *
   * -g &lt;br/&gt; 
   * Only for classifiers that implement &quot;Graphable.&quot; Outputs
   * the graph representation of the classifier (and nothing
   * else). &lt;p/&gt;
   *
   * -xml filename | xml-string &lt;br/&gt;
   * Retrieves the options from the XML-data instead of the command line. &lt;p/&gt;
   * 
   * -threshold-file file &lt;br/&gt;
   * The file to save the threshold data to.
   * The format is determined by the extensions, e.g., '.arff' for ARFF
   * format or '.csv' for CSV. &lt;p/&gt;
   *         
   * -threshold-label label &lt;br/&gt;
   * The class label to determine the threshold data for
   * (default is the first label) &lt;p/&gt;
   *
   * @param classifierString class of machine learning classifier as a string
   * @param options the array of string containing the options
   * @throws Exception if model could not be evaluated successfully
   * @return a string describing the results 
   */
  public static String evaluateModel(String classifierString, 
      String [] options) throws Exception {

    Classifier classifier;	 

    // Create classifier
    try {
<span class="nc" id="L605">      classifier = </span>
<span class="nc" id="L606">	(Classifier)Class.forName(classifierString).newInstance();</span>
<span class="nc" id="L607">    } catch (Exception e) {</span>
<span class="nc" id="L608">      throw new Exception(&quot;Can't find class with name &quot; </span>
<span class="nc" id="L609">	  + classifierString + '.');</span>
    }
<span class="nc" id="L611">    return evaluateModel(classifier, options);</span>
  }

  /**
   * A test method for this class. Just extracts the first command line
   * argument as a classifier class name and calls evaluateModel.
   * @param args an array of command line arguments, the first of which
   * must be the class name of a classifier.
   */
  public static void main(String [] args) {

    try {
<span class="nc bnc" id="L623" title="All 2 branches missed.">      if (args.length == 0) {</span>
<span class="nc" id="L624">	throw new Exception(&quot;The first argument must be the class name&quot;</span>
	    + &quot; of a classifier&quot;);
      }
<span class="nc" id="L627">      String classifier = args[0];</span>
<span class="nc" id="L628">      args[0] = &quot;&quot;;</span>
<span class="nc" id="L629">      System.out.println(evaluateModel(classifier, args));</span>
<span class="nc" id="L630">    } catch (Exception ex) {</span>
<span class="nc" id="L631">      ex.printStackTrace();</span>
<span class="nc" id="L632">      System.err.println(ex.getMessage());</span>
    }
<span class="nc" id="L634">  }</span>

  /**
   * Evaluates a classifier with the options given in an array of
   * strings. &lt;p/&gt;
   *
   * Valid options are: &lt;p/&gt;
   *
   * -t name of training file &lt;br/&gt;
   * Name of the file with the training data. (required) &lt;p/&gt;
   *
   * -T name of test file &lt;br/&gt;
   * Name of the file with the test data. If missing a cross-validation 
   * is performed. &lt;p/&gt;
   *
   * -c class index &lt;br/&gt;
   * Index of the class attribute (1, 2, ...; default: last). &lt;p/&gt;
   *
   * -x number of folds &lt;br/&gt;
   * The number of folds for the cross-validation (default: 10). &lt;p/&gt;
   *
   * -no-cv &lt;br/&gt;
   * No cross validation.  If no test file is provided, no evaluation
   * is done. &lt;p/&gt;
   * 
   * -split-percentage percentage &lt;br/&gt;
   * Sets the percentage for the train/test set split, e.g., 66. &lt;p/&gt;
   * 
   * -preserve-order &lt;br/&gt;
   * Preserves the order in the percentage split instead of randomizing
   * the data first with the seed value ('-s'). &lt;p/&gt;
   *
   * -s seed &lt;br/&gt;
   * Random number seed for the cross-validation and percentage split
   * (default: 1). &lt;p/&gt;
   *
   * -m file with cost matrix &lt;br/&gt;
   * The name of a file containing a cost matrix. &lt;p/&gt;
   *
   * -l filename &lt;br/&gt;
   * Loads classifier from the given file. In case the filename ends with
   * &quot;.xml&quot;,a PMML file is loaded or, if that fails, options are loaded from XML. &lt;p/&gt;
   *
   * -d filename &lt;br/&gt;
   * Saves classifier built from the training data into the given file. In case 
   * the filename ends with &quot;.xml&quot; the options are saved XML, not the model. &lt;p/&gt;
   *
   * -v &lt;br/&gt;
   * Outputs no statistics for the training data. &lt;p/&gt;
   *
   * -o &lt;br/&gt;
   * Outputs statistics only, not the classifier. &lt;p/&gt;
   * 
   * -i &lt;br/&gt;
   * Outputs detailed information-retrieval statistics per class. &lt;p/&gt;
   *
   * -k &lt;br/&gt;
   * Outputs information-theoretic statistics. &lt;p/&gt;
   *
   * -p range &lt;br/&gt;
   * Outputs predictions for test instances (or the train instances if no test
   * instances provided and -no-cv is used), along with the attributes in the specified range 
   * (and nothing else). Use '-p 0' if no attributes are desired. &lt;p/&gt;
   *
   * -distribution &lt;br/&gt;
   * Outputs the distribution instead of only the prediction
   * in conjunction with the '-p' option (only nominal classes). &lt;p/&gt;
   *
   * -r &lt;br/&gt;
   * Outputs cumulative margin distribution (and nothing else). &lt;p/&gt;
   *
   * -g &lt;br/&gt; 
   * Only for classifiers that implement &quot;Graphable.&quot; Outputs
   * the graph representation of the classifier (and nothing
   * else). &lt;p/&gt;
   *
   * -xml filename | xml-string &lt;br/&gt;
   * Retrieves the options from the XML-data instead of the command line. &lt;p/&gt;
   *
   * @param classifier machine learning classifier
   * @param options the array of string containing the options
   * @throws Exception if model could not be evaluated successfully
   * @return a string describing the results 
   */
  public static String evaluateModel(Classifier classifier,
      String [] options) throws Exception {

<span class="nc" id="L721">    Instances train = null, tempTrain, test = null, template = null;</span>
<span class="nc" id="L722">    int seed = 1, folds = 10, classIndex = -1;</span>
<span class="nc" id="L723">    boolean noCrossValidation = false;</span>
    String trainFileName, testFileName, sourceClass, 
    classIndexString, seedString, foldsString, objectInputFileName, 
    objectOutputFileName, attributeRangeString;
<span class="nc" id="L727">    boolean noOutput = false,</span>
<span class="nc" id="L728">    printClassifications = false, trainStatistics = true,</span>
<span class="nc" id="L729">    printMargins = false, printComplexityStatistics = false,</span>
<span class="nc" id="L730">    printGraph = false, classStatistics = false, printSource = false;</span>
<span class="nc" id="L731">    StringBuffer text = new StringBuffer();</span>
<span class="nc" id="L732">    DataSource trainSource = null, testSource = null;</span>
<span class="nc" id="L733">    ObjectInputStream objectInputStream = null;</span>
<span class="nc" id="L734">    BufferedInputStream xmlInputStream = null;</span>
<span class="nc" id="L735">    CostMatrix costMatrix = null;</span>
<span class="nc" id="L736">    StringBuffer schemeOptionsText = null;</span>
<span class="nc" id="L737">    Range attributesToOutput = null;</span>
<span class="nc" id="L738">    long trainTimeStart = 0, trainTimeElapsed = 0,</span>
<span class="nc" id="L739">    testTimeStart = 0, testTimeElapsed = 0;</span>
<span class="nc" id="L740">    String xml = &quot;&quot;;</span>
<span class="nc" id="L741">    String[] optionsTmp = null;</span>
    Classifier classifierBackup;
<span class="nc" id="L743">    boolean printDistribution = false;</span>
<span class="nc" id="L744">    int actualClassIndex = -1;  // 0-based class index</span>
<span class="nc" id="L745">    String splitPercentageString = &quot;&quot;;</span>
<span class="nc" id="L746">    double splitPercentage = -1;</span>
<span class="nc" id="L747">    boolean preserveOrder = false;</span>
<span class="nc" id="L748">    boolean trainSetPresent = false;</span>
<span class="nc" id="L749">    boolean testSetPresent = false;</span>
    String thresholdFile;
    String thresholdLabel;
<span class="nc" id="L752">    StringBuffer predsBuff = null; // predictions from cross-validation</span>

    // help requested?
<span class="nc bnc" id="L755" title="All 4 branches missed.">    if (Utils.getFlag(&quot;h&quot;, options) || Utils.getFlag(&quot;help&quot;, options)) {</span>
      
      // global info requested as well?
<span class="nc bnc" id="L758" title="All 2 branches missed.">      boolean globalInfo = Utils.getFlag(&quot;synopsis&quot;, options) ||</span>
<span class="nc bnc" id="L759" title="All 2 branches missed.">        Utils.getFlag(&quot;info&quot;, options);</span>
      
<span class="nc" id="L761">      throw new Exception(&quot;\nHelp requested.&quot; </span>
<span class="nc" id="L762">          + makeOptionString(classifier, globalInfo));</span>
    }
    
    try {
      // do we get the input from XML instead of normal parameters?
<span class="nc" id="L767">      xml = Utils.getOption(&quot;xml&quot;, options);</span>
<span class="nc bnc" id="L768" title="All 2 branches missed.">      if (!xml.equals(&quot;&quot;))</span>
<span class="nc" id="L769">	options = new XMLOptions(xml).toArray();</span>

      // is the input model only the XML-Options, i.e. w/o built model?
<span class="nc" id="L772">      optionsTmp = new String[options.length];</span>
<span class="nc bnc" id="L773" title="All 2 branches missed.">      for (int i = 0; i &lt; options.length; i++)</span>
<span class="nc" id="L774">	optionsTmp[i] = options[i];</span>

<span class="nc" id="L776">      String tmpO = Utils.getOption('l', optionsTmp);</span>
      //if (Utils.getOption('l', optionsTmp).toLowerCase().endsWith(&quot;.xml&quot;)) {
<span class="nc bnc" id="L778" title="All 2 branches missed.">      if (tmpO.endsWith(&quot;.xml&quot;)) {</span>
	// try to load file as PMML first
<span class="nc" id="L780">	boolean success = false;</span>
	try {
<span class="nc" id="L782">	  PMMLModel pmmlModel = PMMLFactory.getPMMLModel(tmpO);</span>
<span class="nc bnc" id="L783" title="All 2 branches missed.">	  if (pmmlModel instanceof PMMLClassifier) {</span>
<span class="nc" id="L784">	    classifier = ((PMMLClassifier)pmmlModel);</span>
<span class="nc" id="L785">	    success = true;</span>
	  }
<span class="nc" id="L787">	} catch (IllegalArgumentException ex) {</span>
<span class="nc" id="L788">	  success = false;</span>
	}
<span class="nc bnc" id="L790" title="All 2 branches missed.">	if (!success) {</span>
	  // load options from serialized data  ('-l' is automatically erased!)
<span class="nc" id="L792">	  XMLClassifier xmlserial = new XMLClassifier();</span>
<span class="nc" id="L793">	  Classifier cl = (Classifier) xmlserial.read(Utils.getOption('l', options));</span>
	  
	  // merge options
<span class="nc" id="L796">	  optionsTmp = new String[options.length + cl.getOptions().length];</span>
<span class="nc" id="L797">	  System.arraycopy(cl.getOptions(), 0, optionsTmp, 0, cl.getOptions().length);</span>
<span class="nc" id="L798">	  System.arraycopy(options, 0, optionsTmp, cl.getOptions().length, options.length);</span>
<span class="nc" id="L799">	  options = optionsTmp;</span>
	}
      }

<span class="nc" id="L803">      noCrossValidation = Utils.getFlag(&quot;no-cv&quot;, options);</span>
      // Get basic options (options the same for all schemes)
<span class="nc" id="L805">      classIndexString = Utils.getOption('c', options);</span>
<span class="nc bnc" id="L806" title="All 2 branches missed.">      if (classIndexString.length() != 0) {</span>
<span class="nc bnc" id="L807" title="All 2 branches missed.">	if (classIndexString.equals(&quot;first&quot;))</span>
<span class="nc" id="L808">	  classIndex = 1;</span>
<span class="nc bnc" id="L809" title="All 2 branches missed.">	else if (classIndexString.equals(&quot;last&quot;))</span>
<span class="nc" id="L810">	  classIndex = -1;</span>
	else
<span class="nc" id="L812">	  classIndex = Integer.parseInt(classIndexString);</span>
      }
<span class="nc" id="L814">      trainFileName = Utils.getOption('t', options); </span>
<span class="nc" id="L815">      objectInputFileName = Utils.getOption('l', options);</span>
<span class="nc" id="L816">      objectOutputFileName = Utils.getOption('d', options);</span>
<span class="nc" id="L817">      testFileName = Utils.getOption('T', options);</span>
<span class="nc" id="L818">      foldsString = Utils.getOption('x', options);</span>
<span class="nc bnc" id="L819" title="All 2 branches missed.">      if (foldsString.length() != 0) {</span>
<span class="nc" id="L820">	folds = Integer.parseInt(foldsString);</span>
      }
<span class="nc" id="L822">      seedString = Utils.getOption('s', options);</span>
<span class="nc bnc" id="L823" title="All 2 branches missed.">      if (seedString.length() != 0) {</span>
<span class="nc" id="L824">	seed = Integer.parseInt(seedString);</span>
      }
<span class="nc bnc" id="L826" title="All 2 branches missed.">      if (trainFileName.length() == 0) {</span>
<span class="nc bnc" id="L827" title="All 2 branches missed.">	if (objectInputFileName.length() == 0) {</span>
<span class="nc" id="L828">	  throw new Exception(&quot;No training file and no object &quot;+</span>
	  &quot;input file given.&quot;);
	} 
<span class="nc bnc" id="L831" title="All 2 branches missed.">	if (testFileName.length() == 0) {</span>
<span class="nc" id="L832">	  throw new Exception(&quot;No training file and no test &quot;+</span>
	  &quot;file given.&quot;);
	}
<span class="nc bnc" id="L835" title="All 2 branches missed.">      } else if ((objectInputFileName.length() != 0) &amp;&amp;</span>
<span class="nc bnc" id="L836" title="All 2 branches missed.">	  ((!(classifier instanceof UpdateableClassifier)) ||</span>
<span class="nc bnc" id="L837" title="All 2 branches missed.">	      (testFileName.length() == 0))) {</span>
<span class="nc" id="L838">	throw new Exception(&quot;Classifier not incremental, or no &quot; +</span>
	    &quot;test file provided: can't &quot;+
	&quot;use both train and model file.&quot;);
      }
      try {
<span class="nc bnc" id="L843" title="All 2 branches missed.">	if (trainFileName.length() != 0) {</span>
<span class="nc" id="L844">	  trainSetPresent = true;</span>
<span class="nc" id="L845">	  trainSource = new DataSource(trainFileName);</span>
	}
<span class="nc bnc" id="L847" title="All 2 branches missed.">	if (testFileName.length() != 0) {</span>
<span class="nc" id="L848">	  testSetPresent = true;</span>
<span class="nc" id="L849">	  testSource = new DataSource(testFileName);</span>
	}
<span class="nc bnc" id="L851" title="All 2 branches missed.">	if (objectInputFileName.length() != 0) {</span>
<span class="nc bnc" id="L852" title="All 2 branches missed.">	  if (objectInputFileName.endsWith(&quot;.xml&quot;)) {</span>
	    // if this is the case then it means that a PMML classifier was
	    // successfully loaded earlier in the code
<span class="nc" id="L855">	    objectInputStream = null;</span>
<span class="nc" id="L856">	    xmlInputStream = null;</span>
	  } else {
<span class="nc" id="L858">	    InputStream is = new FileInputStream(objectInputFileName);</span>
<span class="nc bnc" id="L859" title="All 2 branches missed.">	    if (objectInputFileName.endsWith(&quot;.gz&quot;)) {</span>
<span class="nc" id="L860">	      is = new GZIPInputStream(is);</span>
	    }
	    // load from KOML?
<span class="nc bnc" id="L863" title="All 4 branches missed.">	    if (!(objectInputFileName.endsWith(&quot;.koml&quot;) &amp;&amp; KOML.isPresent()) ) {</span>
<span class="nc" id="L864">	      objectInputStream = new ObjectInputStream(is);</span>
<span class="nc" id="L865">	      xmlInputStream    = null;</span>
	    }
	    else {
<span class="nc" id="L868">	      objectInputStream = null;</span>
<span class="nc" id="L869">	      xmlInputStream    = new BufferedInputStream(is);</span>
	    }
	  }
	}
<span class="nc" id="L873">      } catch (Exception e) {</span>
<span class="nc" id="L874">	throw new Exception(&quot;Can't open file &quot; + e.getMessage() + '.');</span>
      }
<span class="nc bnc" id="L876" title="All 2 branches missed.">      if (testSetPresent) {</span>
<span class="nc" id="L877">	template = test = testSource.getStructure();</span>
<span class="nc bnc" id="L878" title="All 2 branches missed.">	if (classIndex != -1) {</span>
<span class="nc" id="L879">	  test.setClassIndex(classIndex - 1);</span>
	} else {
<span class="nc bnc" id="L881" title="All 4 branches missed.">	  if ( (test.classIndex() == -1) || (classIndexString.length() != 0) )</span>
<span class="nc" id="L882">	    test.setClassIndex(test.numAttributes() - 1);</span>
	}
<span class="nc" id="L884">	actualClassIndex = test.classIndex();</span>
      }
      else {
	// percentage split
<span class="nc" id="L888">	splitPercentageString = Utils.getOption(&quot;split-percentage&quot;, options);</span>
<span class="nc bnc" id="L889" title="All 2 branches missed.">	if (splitPercentageString.length() != 0) {</span>
<span class="nc bnc" id="L890" title="All 2 branches missed.">	  if (foldsString.length() != 0)</span>
<span class="nc" id="L891">	    throw new Exception(</span>
<span class="nc" id="L892">		&quot;Percentage split cannot be used in conjunction with &quot;</span>
		+ &quot;cross-validation ('-x').&quot;);
<span class="nc" id="L894">	  splitPercentage = Double.parseDouble(splitPercentageString);</span>
<span class="nc bnc" id="L895" title="All 4 branches missed.">	  if ((splitPercentage &lt;= 0) || (splitPercentage &gt;= 100))</span>
<span class="nc" id="L896">	    throw new Exception(&quot;Percentage split value needs be &gt;0 and &lt;100.&quot;);</span>
	}
	else {
<span class="nc" id="L899">	  splitPercentage = -1;</span>
	}
<span class="nc" id="L901">	preserveOrder = Utils.getFlag(&quot;preserve-order&quot;, options);</span>
<span class="nc bnc" id="L902" title="All 2 branches missed.">	if (preserveOrder) {</span>
<span class="nc bnc" id="L903" title="All 2 branches missed.">	  if (splitPercentage == -1)</span>
<span class="nc" id="L904">	    throw new Exception(&quot;Percentage split ('-percentage-split') is missing.&quot;);</span>
	}
	// create new train/test sources
<span class="nc bnc" id="L907" title="All 2 branches missed.">	if (splitPercentage &gt; 0) {</span>
<span class="nc" id="L908">	  testSetPresent = true;</span>
<span class="nc" id="L909">	  Instances tmpInst = trainSource.getDataSet(actualClassIndex);</span>
<span class="nc bnc" id="L910" title="All 2 branches missed.">	  if (!preserveOrder)</span>
<span class="nc" id="L911">	    tmpInst.randomize(new Random(seed));</span>
<span class="nc" id="L912">	  int trainSize = </span>
<span class="nc" id="L913">            (int) Math.round(tmpInst.numInstances() * splitPercentage / 100);</span>
<span class="nc" id="L914">	  int testSize  = tmpInst.numInstances() - trainSize;</span>
<span class="nc" id="L915">	  Instances trainInst = new Instances(tmpInst, 0, trainSize);</span>
<span class="nc" id="L916">	  Instances testInst  = new Instances(tmpInst, trainSize, testSize);</span>
<span class="nc" id="L917">	  trainSource = new DataSource(trainInst);</span>
<span class="nc" id="L918">	  testSource  = new DataSource(testInst);</span>
<span class="nc" id="L919">	  template = test = testSource.getStructure();</span>
<span class="nc bnc" id="L920" title="All 2 branches missed.">	  if (classIndex != -1) {</span>
<span class="nc" id="L921">	    test.setClassIndex(classIndex - 1);</span>
	  } else {
<span class="nc bnc" id="L923" title="All 4 branches missed.">	    if ( (test.classIndex() == -1) || (classIndexString.length() != 0) )</span>
<span class="nc" id="L924">	      test.setClassIndex(test.numAttributes() - 1);</span>
	  }
<span class="nc" id="L926">	  actualClassIndex = test.classIndex();</span>
	}
      }
<span class="nc bnc" id="L929" title="All 2 branches missed.">      if (trainSetPresent) {</span>
<span class="nc" id="L930">	template = train = trainSource.getStructure();</span>
<span class="nc bnc" id="L931" title="All 2 branches missed.">	if (classIndex != -1) {</span>
<span class="nc" id="L932">	  train.setClassIndex(classIndex - 1);</span>
	} else {
<span class="nc bnc" id="L934" title="All 4 branches missed.">	  if ( (train.classIndex() == -1) || (classIndexString.length() != 0) )</span>
<span class="nc" id="L935">	    train.setClassIndex(train.numAttributes() - 1);</span>
	}
<span class="nc" id="L937">	actualClassIndex = train.classIndex();</span>
<span class="nc bnc" id="L938" title="All 4 branches missed.">	if ((testSetPresent) &amp;&amp; !test.equalHeaders(train)) {</span>
<span class="nc" id="L939">	  throw new IllegalArgumentException(&quot;Train and test file not compatible!&quot;);</span>
	}
      }
<span class="nc bnc" id="L942" title="All 2 branches missed.">      if (template == null) {</span>
<span class="nc" id="L943">	throw new Exception(&quot;No actual dataset provided to use as template&quot;);</span>
      }
<span class="nc" id="L945">      costMatrix = handleCostOption(</span>
<span class="nc" id="L946">	  Utils.getOption('m', options), template.numClasses());</span>

<span class="nc" id="L948">      classStatistics = Utils.getFlag('i', options);</span>
<span class="nc" id="L949">      noOutput = Utils.getFlag('o', options);</span>
<span class="nc bnc" id="L950" title="All 2 branches missed.">      trainStatistics = !Utils.getFlag('v', options);</span>
<span class="nc" id="L951">      printComplexityStatistics = Utils.getFlag('k', options);</span>
<span class="nc" id="L952">      printMargins = Utils.getFlag('r', options);</span>
<span class="nc" id="L953">      printGraph = Utils.getFlag('g', options);</span>
<span class="nc" id="L954">      sourceClass = Utils.getOption('z', options);</span>
<span class="nc bnc" id="L955" title="All 2 branches missed.">      printSource = (sourceClass.length() != 0);</span>
<span class="nc" id="L956">      printDistribution = Utils.getFlag(&quot;distribution&quot;, options);</span>
<span class="nc" id="L957">      thresholdFile = Utils.getOption(&quot;threshold-file&quot;, options);</span>
<span class="nc" id="L958">      thresholdLabel = Utils.getOption(&quot;threshold-label&quot;, options);</span>

      // Check -p option
      try {
<span class="nc" id="L962">	attributeRangeString = Utils.getOption('p', options);</span>
      }
<span class="nc" id="L964">      catch (Exception e) {</span>
<span class="nc" id="L965">	throw new Exception(e.getMessage() + &quot;\nNOTE: the -p option has changed. &quot; +</span>
<span class="nc" id="L966">	    &quot;It now expects a parameter specifying a range of attributes &quot; +</span>
<span class="nc" id="L967">	&quot;to list with the predictions. Use '-p 0' for none.&quot;);</span>
      }
<span class="nc bnc" id="L969" title="All 2 branches missed.">      if (attributeRangeString.length() != 0) {</span>
<span class="nc" id="L970">	printClassifications = true;</span>
<span class="nc" id="L971">	noOutput = true;</span>
<span class="nc bnc" id="L972" title="All 2 branches missed.">	if (!attributeRangeString.equals(&quot;0&quot;)) </span>
<span class="nc" id="L973">	  attributesToOutput = new Range(attributeRangeString);</span>
      }

<span class="nc bnc" id="L976" title="All 4 branches missed.">      if (!printClassifications &amp;&amp; printDistribution)</span>
<span class="nc" id="L977">	throw new Exception(&quot;Cannot print distribution without '-p' option!&quot;);</span>

      // if no training file given, we don't have any priors
<span class="nc bnc" id="L980" title="All 4 branches missed.">      if ( (!trainSetPresent) &amp;&amp; (printComplexityStatistics) )</span>
<span class="nc" id="L981">	throw new Exception(&quot;Cannot print complexity statistics ('-k') without training file ('-t')!&quot;);</span>

      // If a model file is given, we can't process 
      // scheme-specific options
<span class="nc bnc" id="L985" title="All 2 branches missed.">      if (objectInputFileName.length() != 0) {</span>
<span class="nc" id="L986">	Utils.checkForRemainingOptions(options);</span>
      } else {

	// Set options for classifier
<span class="nc bnc" id="L990" title="All 2 branches missed.">	if (classifier instanceof OptionHandler) {</span>
<span class="nc bnc" id="L991" title="All 2 branches missed.">	  for (int i = 0; i &lt; options.length; i++) {</span>
<span class="nc bnc" id="L992" title="All 2 branches missed.">	    if (options[i].length() != 0) {</span>
<span class="nc bnc" id="L993" title="All 2 branches missed.">	      if (schemeOptionsText == null) {</span>
<span class="nc" id="L994">		schemeOptionsText = new StringBuffer();</span>
	      }
<span class="nc bnc" id="L996" title="All 2 branches missed.">	      if (options[i].indexOf(' ') != -1) {</span>
<span class="nc" id="L997">		schemeOptionsText.append('&quot;' + options[i] + &quot;\&quot; &quot;);</span>
	      } else {
<span class="nc" id="L999">		schemeOptionsText.append(options[i] + &quot; &quot;);</span>
	      }
	    }
	  }
<span class="nc" id="L1003">	  ((OptionHandler)classifier).setOptions(options);</span>
	}
      }
<span class="nc" id="L1006">      Utils.checkForRemainingOptions(options);</span>
<span class="nc" id="L1007">    } catch (Exception e) {</span>
<span class="nc" id="L1008">      throw new Exception(&quot;\nWeka exception: &quot; + e.getMessage()</span>
<span class="nc" id="L1009">	  + makeOptionString(classifier, false));</span>
    }

    // Setup up evaluation objects
<span class="nc" id="L1013">    Evaluation trainingEvaluation = new Evaluation(new Instances(template, 0), costMatrix);</span>
<span class="nc" id="L1014">    Evaluation testingEvaluation = new Evaluation(new Instances(template, 0), costMatrix);</span>

    // disable use of priors if no training file given
<span class="nc bnc" id="L1017" title="All 2 branches missed.">    if (!trainSetPresent)</span>
<span class="nc" id="L1018">      testingEvaluation.useNoPriors();</span>

<span class="nc bnc" id="L1020" title="All 2 branches missed.">    if (objectInputFileName.length() != 0) {</span>
      // Load classifier from file
<span class="nc bnc" id="L1022" title="All 2 branches missed.">      if (objectInputStream != null) {</span>
<span class="nc" id="L1023">	classifier = (Classifier) objectInputStream.readObject();</span>
        // try and read a header (if present)
<span class="nc" id="L1025">        Instances savedStructure = null;</span>
        try {
<span class="nc" id="L1027">          savedStructure = (Instances) objectInputStream.readObject();</span>
<span class="nc" id="L1028">        } catch (Exception ex) {</span>
          // don't make a fuss
        }
<span class="nc bnc" id="L1031" title="All 2 branches missed.">        if (savedStructure != null) {</span>
          // test for compatibility with template
<span class="nc bnc" id="L1033" title="All 2 branches missed.">          if (!template.equalHeaders(savedStructure)) {</span>
<span class="nc" id="L1034">            throw new Exception(&quot;training and test set are not compatible&quot;);</span>
          }
        }
<span class="nc" id="L1037">	objectInputStream.close();</span>
      }
<span class="nc bnc" id="L1039" title="All 2 branches missed.">      else if (xmlInputStream != null) {</span>
	// whether KOML is available has already been checked (objectInputStream would null otherwise)!
<span class="nc" id="L1041">	classifier = (Classifier) KOML.read(xmlInputStream);</span>
<span class="nc" id="L1042">	xmlInputStream.close();</span>
      }
    }

    // backup of fully setup classifier for cross-validation
<span class="nc" id="L1047">    classifierBackup = Classifier.makeCopy(classifier);</span>

    // Build the classifier if no object file provided
<span class="nc bnc" id="L1050" title="All 2 branches missed.">    if ((classifier instanceof UpdateableClassifier) &amp;&amp;</span>
<span class="nc bnc" id="L1051" title="All 4 branches missed.">	(testSetPresent || noCrossValidation) &amp;&amp;</span>
<span class="nc bnc" id="L1052" title="All 2 branches missed.">	(costMatrix == null) &amp;&amp;</span>
<span class="nc bnc" id="L1053" title="All 2 branches missed.">	(trainSetPresent)) {</span>
      // Build classifier incrementally
<span class="nc" id="L1055">      trainingEvaluation.setPriors(train);</span>
<span class="nc" id="L1056">      testingEvaluation.setPriors(train);</span>
<span class="nc" id="L1057">      trainTimeStart = System.currentTimeMillis();</span>
<span class="nc bnc" id="L1058" title="All 2 branches missed.">      if (objectInputFileName.length() == 0) {</span>
<span class="nc" id="L1059">	classifier.buildClassifier(train);</span>
      }
      Instance trainInst;
<span class="nc bnc" id="L1062" title="All 2 branches missed.">      while (trainSource.hasMoreElements(train)) {</span>
<span class="nc" id="L1063">	trainInst = trainSource.nextElement(train);</span>
<span class="nc" id="L1064">	trainingEvaluation.updatePriors(trainInst);</span>
<span class="nc" id="L1065">	testingEvaluation.updatePriors(trainInst);</span>
<span class="nc" id="L1066">	((UpdateableClassifier)classifier).updateClassifier(trainInst);</span>
      }
<span class="nc" id="L1068">      trainTimeElapsed = System.currentTimeMillis() - trainTimeStart;</span>
<span class="nc bnc" id="L1069" title="All 2 branches missed.">    } else if (objectInputFileName.length() == 0) {</span>
      // Build classifier in one go
<span class="nc" id="L1071">      tempTrain = trainSource.getDataSet(actualClassIndex);</span>
<span class="nc" id="L1072">      trainingEvaluation.setPriors(tempTrain);</span>
<span class="nc" id="L1073">      testingEvaluation.setPriors(tempTrain);</span>
<span class="nc" id="L1074">      trainTimeStart = System.currentTimeMillis();</span>
<span class="nc" id="L1075">      classifier.buildClassifier(tempTrain);</span>
<span class="nc" id="L1076">      trainTimeElapsed = System.currentTimeMillis() - trainTimeStart;</span>
    } 

    // Save the classifier if an object output file is provided
<span class="nc bnc" id="L1080" title="All 2 branches missed.">    if (objectOutputFileName.length() != 0) {</span>
<span class="nc" id="L1081">      OutputStream os = new FileOutputStream(objectOutputFileName);</span>
      // binary
<span class="nc bnc" id="L1083" title="All 6 branches missed.">      if (!(objectOutputFileName.endsWith(&quot;.xml&quot;) || (objectOutputFileName.endsWith(&quot;.koml&quot;) &amp;&amp; KOML.isPresent()))) {</span>
<span class="nc bnc" id="L1084" title="All 2 branches missed.">	if (objectOutputFileName.endsWith(&quot;.gz&quot;)) {</span>
<span class="nc" id="L1085">	  os = new GZIPOutputStream(os);</span>
	}
<span class="nc" id="L1087">	ObjectOutputStream objectOutputStream = new ObjectOutputStream(os);</span>
<span class="nc" id="L1088">	objectOutputStream.writeObject(classifier);</span>
        if (template != null) {
<span class="nc" id="L1090">          objectOutputStream.writeObject(template);</span>
        }
<span class="nc" id="L1092">	objectOutputStream.flush();</span>
<span class="nc" id="L1093">	objectOutputStream.close();</span>
      }
      // KOML/XML
      else {
<span class="nc" id="L1097">	BufferedOutputStream xmlOutputStream = new BufferedOutputStream(os);</span>
<span class="nc bnc" id="L1098" title="All 2 branches missed.">	if (objectOutputFileName.endsWith(&quot;.xml&quot;)) {</span>
<span class="nc" id="L1099">	  XMLSerialization xmlSerial = new XMLClassifier();</span>
<span class="nc" id="L1100">	  xmlSerial.write(xmlOutputStream, classifier);</span>
	}
	else
	  // whether KOML is present has already been checked
	  // if not present -&gt; &quot;.koml&quot; is interpreted as binary - see above
<span class="nc bnc" id="L1105" title="All 2 branches missed.">	  if (objectOutputFileName.endsWith(&quot;.koml&quot;)) {</span>
<span class="nc" id="L1106">	    KOML.write(xmlOutputStream, classifier);</span>
	  }
<span class="nc" id="L1108">	xmlOutputStream.close();</span>
      }
    }

    // If classifier is drawable output string describing graph
<span class="nc bnc" id="L1113" title="All 4 branches missed.">    if ((classifier instanceof Drawable) &amp;&amp; (printGraph)){</span>
<span class="nc" id="L1114">      return ((Drawable)classifier).graph();</span>
    }

    // Output the classifier as equivalent source
<span class="nc bnc" id="L1118" title="All 4 branches missed.">    if ((classifier instanceof Sourcable) &amp;&amp; (printSource)){</span>
<span class="nc" id="L1119">      return wekaStaticWrapper((Sourcable) classifier, sourceClass);</span>
    }

    // Output model
<span class="nc bnc" id="L1123" title="All 4 branches missed.">    if (!(noOutput || printMargins)) {</span>
<span class="nc bnc" id="L1124" title="All 2 branches missed.">      if (classifier instanceof OptionHandler) {</span>
<span class="nc bnc" id="L1125" title="All 2 branches missed.">	if (schemeOptionsText != null) {</span>
<span class="nc" id="L1126">	  text.append(&quot;\nOptions: &quot;+schemeOptionsText);</span>
<span class="nc" id="L1127">	  text.append(&quot;\n&quot;);</span>
	}
      }
<span class="nc" id="L1130">      text.append(&quot;\n&quot; + classifier.toString() + &quot;\n&quot;);</span>
    }

<span class="nc bnc" id="L1133" title="All 4 branches missed.">    if (!printMargins &amp;&amp; (costMatrix != null)) {</span>
<span class="nc" id="L1134">      text.append(&quot;\n=== Evaluation Cost Matrix ===\n\n&quot;);</span>
<span class="nc" id="L1135">      text.append(costMatrix.toString());</span>
    }

    // Output test instance predictions only
<span class="nc bnc" id="L1139" title="All 2 branches missed.">    if (printClassifications) {</span>
<span class="nc" id="L1140">      DataSource source = testSource;</span>
<span class="nc" id="L1141">      predsBuff = new StringBuffer();</span>
      // no test set -&gt; use train set
<span class="nc bnc" id="L1143" title="All 4 branches missed.">      if (source == null &amp;&amp; noCrossValidation) {</span>
<span class="nc" id="L1144">	source = trainSource;</span>
<span class="nc" id="L1145">        predsBuff.append(&quot;\n=== Predictions on training data ===\n\n&quot;);</span>
      } else {
<span class="nc" id="L1147">        predsBuff.append(&quot;\n=== Predictions on test data ===\n\n&quot;);</span>
      }
<span class="nc bnc" id="L1149" title="All 2 branches missed.">      if (source != null) {</span>
        /*      return printClassifications(classifierClassifications, new Instances(template, 0),
                source, actualClassIndex + 1, attributesToOutput,
                printDistribution); */
<span class="nc" id="L1153">        printClassifications(classifier, new Instances(template, 0),</span>
<span class="nc" id="L1154">                             source, actualClassIndex + 1, attributesToOutput,</span>
<span class="nc" id="L1155">                             printDistribution, predsBuff);</span>
        //        return predsText.toString();
      }
    }

    // Compute error estimate from training data
<span class="nc bnc" id="L1161" title="All 4 branches missed.">    if ((trainStatistics) &amp;&amp; (trainSetPresent)) {</span>

<span class="nc bnc" id="L1163" title="All 2 branches missed.">      if ((classifier instanceof UpdateableClassifier) &amp;&amp;</span>
<span class="nc bnc" id="L1164" title="All 2 branches missed.">	  (testSetPresent) &amp;&amp;</span>
<span class="nc bnc" id="L1165" title="All 2 branches missed.">	  (costMatrix == null)) {</span>

	// Classifier was trained incrementally, so we have to 
	// reset the source.
<span class="nc" id="L1169">	trainSource.reset();</span>

	// Incremental testing
<span class="nc" id="L1172">	train = trainSource.getStructure(actualClassIndex);</span>
<span class="nc" id="L1173">	testTimeStart = System.currentTimeMillis();</span>
	Instance trainInst;
<span class="nc bnc" id="L1175" title="All 2 branches missed.">	while (trainSource.hasMoreElements(train)) {</span>
<span class="nc" id="L1176">	  trainInst = trainSource.nextElement(train);</span>
<span class="nc" id="L1177">	  trainingEvaluation.evaluateModelOnce((Classifier)classifier, trainInst);</span>
	}
<span class="nc" id="L1179">	testTimeElapsed = System.currentTimeMillis() - testTimeStart;</span>
      } else {
<span class="nc" id="L1181">	testTimeStart = System.currentTimeMillis();</span>
<span class="nc" id="L1182">	trainingEvaluation.evaluateModel(</span>
<span class="nc" id="L1183">	    classifier, trainSource.getDataSet(actualClassIndex));</span>
<span class="nc" id="L1184">	testTimeElapsed = System.currentTimeMillis() - testTimeStart;</span>
      }

      // Print the results of the training evaluation
<span class="nc bnc" id="L1188" title="All 2 branches missed.">      if (printMargins) {</span>
<span class="nc" id="L1189">	return trainingEvaluation.toCumulativeMarginDistributionString();</span>
      } else {
<span class="nc bnc" id="L1191" title="All 2 branches missed.">        if (!printClassifications) {</span>
<span class="nc" id="L1192">          text.append(&quot;\nTime taken to build model: &quot;</span>
<span class="nc" id="L1193">              + Utils.doubleToString(trainTimeElapsed / 1000.0,2)</span>
<span class="nc" id="L1194">              + &quot; seconds&quot;);</span>

<span class="nc bnc" id="L1196" title="All 2 branches missed.">          if (splitPercentage &gt; 0)</span>
<span class="nc" id="L1197">            text.append(&quot;\nTime taken to test model on training split: &quot;);</span>
          else
<span class="nc" id="L1199">            text.append(&quot;\nTime taken to test model on training data: &quot;);</span>
<span class="nc" id="L1200">          text.append(Utils.doubleToString(testTimeElapsed / 1000.0,2) + &quot; seconds&quot;);</span>

<span class="nc bnc" id="L1202" title="All 2 branches missed.">          if (splitPercentage &gt; 0)</span>
<span class="nc" id="L1203">            text.append(trainingEvaluation.toSummaryString(&quot;\n\n=== Error on training&quot;</span>
<span class="nc" id="L1204">                + &quot; split ===\n&quot;, printComplexityStatistics));</span>
          else
<span class="nc" id="L1206">            text.append(trainingEvaluation.toSummaryString(&quot;\n\n=== Error on training&quot;</span>
<span class="nc" id="L1207">                + &quot; data ===\n&quot;, printComplexityStatistics));</span>

<span class="nc bnc" id="L1209" title="All 2 branches missed.">          if (template.classAttribute().isNominal()) {</span>
<span class="nc bnc" id="L1210" title="All 2 branches missed.">            if (classStatistics) {</span>
<span class="nc" id="L1211">              text.append(&quot;\n\n&quot; + trainingEvaluation.toClassDetailsString());</span>
            }
<span class="nc bnc" id="L1213" title="All 2 branches missed.">            if (!noCrossValidation)</span>
<span class="nc" id="L1214">              text.append(&quot;\n\n&quot; + trainingEvaluation.toMatrixString());</span>
          }
        }
      }
    }

    // Compute proper error estimates
<span class="nc bnc" id="L1221" title="All 2 branches missed.">    if (testSource != null) {</span>
      // Testing is on the supplied test data
<span class="nc" id="L1223">      testSource.reset();</span>
<span class="nc" id="L1224">      test = testSource.getStructure(test.classIndex());</span>
      Instance testInst;
<span class="nc bnc" id="L1226" title="All 2 branches missed.">      while (testSource.hasMoreElements(test)) {</span>
<span class="nc" id="L1227">	testInst = testSource.nextElement(test);</span>
<span class="nc" id="L1228">	testingEvaluation.evaluateModelOnceAndRecordPrediction(</span>
<span class="nc" id="L1229">            (Classifier)classifier, testInst);</span>
      }

<span class="nc bnc" id="L1232" title="All 2 branches missed.">      if (splitPercentage &gt; 0) {</span>
<span class="nc bnc" id="L1233" title="All 2 branches missed.">        if (!printClassifications) {</span>
<span class="nc" id="L1234">          text.append(&quot;\n\n&quot; + testingEvaluation.</span>
<span class="nc" id="L1235">              toSummaryString(&quot;=== Error on test split ===\n&quot;,</span>
<span class="nc" id="L1236">                  printComplexityStatistics));</span>
        }
      } else {
<span class="nc bnc" id="L1239" title="All 2 branches missed.">        if (!printClassifications) {</span>
<span class="nc" id="L1240">          text.append(&quot;\n\n&quot; + testingEvaluation.</span>
<span class="nc" id="L1241">              toSummaryString(&quot;=== Error on test data ===\n&quot;,</span>
<span class="nc" id="L1242">                  printComplexityStatistics));</span>
        }
      }

<span class="nc bnc" id="L1246" title="All 2 branches missed.">    } else if (trainSource != null) {</span>
<span class="nc bnc" id="L1247" title="All 2 branches missed.">      if (!noCrossValidation) {</span>
	// Testing is via cross-validation on training data
<span class="nc" id="L1249">	Random random = new Random(seed);</span>
	// use untrained (!) classifier for cross-validation
<span class="nc" id="L1251">	classifier = Classifier.makeCopy(classifierBackup);</span>
<span class="nc bnc" id="L1252" title="All 2 branches missed.">        if (!printClassifications) {</span>
<span class="nc" id="L1253">          testingEvaluation.crossValidateModel(classifier, </span>
<span class="nc" id="L1254">                                               trainSource.getDataSet(actualClassIndex), </span>
<span class="nc" id="L1255">                                               folds, random);</span>
<span class="nc bnc" id="L1256" title="All 2 branches missed.">          if (template.classAttribute().isNumeric()) {</span>
<span class="nc" id="L1257">            text.append(&quot;\n\n\n&quot; + testingEvaluation.</span>
<span class="nc" id="L1258">                        toSummaryString(&quot;=== Cross-validation ===\n&quot;,</span>
<span class="nc" id="L1259">                                        printComplexityStatistics));</span>
          } else {
<span class="nc" id="L1261">            text.append(&quot;\n\n\n&quot; + testingEvaluation.</span>
<span class="nc" id="L1262">                        toSummaryString(&quot;=== Stratified &quot; + </span>
                                        &quot;cross-validation ===\n&quot;,
<span class="nc" id="L1264">                                        printComplexityStatistics));</span>
          }
        } else {
<span class="nc" id="L1267">          predsBuff = new StringBuffer();</span>
<span class="nc" id="L1268">          predsBuff.append(&quot;\n=== Predictions under cross-validation ===\n\n&quot;);</span>
<span class="nc" id="L1269">          testingEvaluation.crossValidateModel(classifier,</span>
<span class="nc" id="L1270">                                               trainSource.getDataSet(actualClassIndex),</span>
<span class="nc" id="L1271">                                               folds, random, predsBuff, attributesToOutput, </span>
<span class="nc" id="L1272">                                               new Boolean(printDistribution));</span>
/*          if (template.classAttribute().isNumeric()) {
            text.append(&quot;\n\n\n&quot; + testingEvaluation.
                        toSummaryString(&quot;=== Cross-validation ===\n&quot;,
                                        printComplexityStatistics));
          } else {
            text.append(&quot;\n\n\n&quot; + testingEvaluation.
                        toSummaryString(&quot;=== Stratified &quot; + 
                                        &quot;cross-validation ===\n&quot;,
                                        printComplexityStatistics));
          } */
        }
      }
    }
<span class="nc bnc" id="L1286" title="All 2 branches missed.">    if (template.classAttribute().isNominal()) {</span>
<span class="nc bnc" id="L1287" title="All 6 branches missed.">      if (classStatistics &amp;&amp; !noCrossValidation &amp;&amp; !printClassifications) {</span>
<span class="nc" id="L1288">	text.append(&quot;\n\n&quot; + testingEvaluation.toClassDetailsString());</span>
      }
<span class="nc bnc" id="L1290" title="All 4 branches missed.">      if (!noCrossValidation &amp;&amp; !printClassifications)</span>
<span class="nc" id="L1291">        text.append(&quot;\n\n&quot; + testingEvaluation.toMatrixString());</span>
      
    }
    
    // predictions from cross-validation?
<span class="nc bnc" id="L1296" title="All 2 branches missed.">    if (predsBuff != null) {</span>
<span class="nc" id="L1297">      text.append(&quot;\n&quot; + predsBuff);</span>
    }

<span class="nc bnc" id="L1300" title="All 4 branches missed.">    if ((thresholdFile.length() != 0) &amp;&amp; template.classAttribute().isNominal()) {</span>
<span class="nc" id="L1301">      int labelIndex = 0;</span>
<span class="nc bnc" id="L1302" title="All 2 branches missed.">      if (thresholdLabel.length() != 0)</span>
<span class="nc" id="L1303">	labelIndex = template.classAttribute().indexOfValue(thresholdLabel);</span>
<span class="nc bnc" id="L1304" title="All 2 branches missed.">      if (labelIndex == -1)</span>
<span class="nc" id="L1305">	throw new IllegalArgumentException(</span>
<span class="nc" id="L1306">	    &quot;Class label '&quot; + thresholdLabel + &quot;' is unknown!&quot;);</span>
<span class="nc" id="L1307">      ThresholdCurve tc = new ThresholdCurve();</span>
<span class="nc" id="L1308">      Instances result = tc.getCurve(testingEvaluation.predictions(), labelIndex);</span>
<span class="nc" id="L1309">      DataSink.write(thresholdFile, result);</span>
    }
    
<span class="nc" id="L1312">    return text.toString();</span>
  }

  /**
   * Attempts to load a cost matrix.
   *
   * @param costFileName the filename of the cost matrix
   * @param numClasses the number of classes that should be in the cost matrix
   * (only used if the cost file is in old format).
   * @return a &lt;code&gt;CostMatrix&lt;/code&gt; value, or null if costFileName is empty
   * @throws Exception if an error occurs.
   */
  protected static CostMatrix handleCostOption(String costFileName, 
      int numClasses) 
  throws Exception {

<span class="nc bnc" id="L1328" title="All 4 branches missed.">    if ((costFileName != null) &amp;&amp; (costFileName.length() != 0)) {</span>
<span class="nc" id="L1329">      System.out.println(</span>
<span class="nc" id="L1330">	  &quot;NOTE: The behaviour of the -m option has changed between WEKA 3.0&quot;</span>
	  +&quot; and WEKA 3.1. -m now carries out cost-sensitive *evaluation*&quot;
	  +&quot; only. For cost-sensitive *prediction*, use one of the&quot;
	  +&quot; cost-sensitive metaschemes such as&quot;
	  +&quot; weka.classifiers.meta.CostSensitiveClassifier or&quot;
	  +&quot; weka.classifiers.meta.MetaCost&quot;);

<span class="nc" id="L1337">      Reader costReader = null;</span>
      try {
<span class="nc" id="L1339">	costReader = new BufferedReader(new FileReader(costFileName));</span>
<span class="nc" id="L1340">      } catch (Exception e) {</span>
<span class="nc" id="L1341">	throw new Exception(&quot;Can't open file &quot; + e.getMessage() + '.');</span>
      }
      try {
	// First try as a proper cost matrix format
<span class="nc" id="L1345">	return new CostMatrix(costReader);</span>
<span class="nc" id="L1346">      } catch (Exception ex) {</span>
	try {
	  // Now try as the poxy old format :-)
	  //System.err.println(&quot;Attempting to read old format cost file&quot;);
	  try {
<span class="nc" id="L1351">	    costReader.close(); // Close the old one</span>
<span class="nc" id="L1352">	    costReader = new BufferedReader(new FileReader(costFileName));</span>
<span class="nc" id="L1353">	  } catch (Exception e) {</span>
<span class="nc" id="L1354">	    throw new Exception(&quot;Can't open file &quot; + e.getMessage() + '.');</span>
	  }
<span class="nc" id="L1356">	  CostMatrix costMatrix = new CostMatrix(numClasses);</span>
	  //System.err.println(&quot;Created default cost matrix&quot;);
<span class="nc" id="L1358">	  costMatrix.readOldFormat(costReader);</span>
<span class="nc" id="L1359">	  return costMatrix;</span>
	  //System.err.println(&quot;Read old format&quot;);
<span class="nc" id="L1361">	} catch (Exception e2) {</span>
	  // re-throw the original exception
	  //System.err.println(&quot;Re-throwing original exception&quot;);
<span class="nc" id="L1364">	  throw ex;</span>
	}
      }
    } else {
<span class="nc" id="L1368">      return null;</span>
    }
  }
      
  /**
   * Evaluates the classifier on a given set of instances. Note that
   * the data must have exactly the same format (e.g. order of
   * attributes) as the data used to train the classifier! Otherwise
   * the results will generally be meaningless.
   *
   * @param classifier machine learning classifier
   * @param data set of test instances for evaluation
   * @param forPredictionsString varargs parameter that, if supplied, is
   * expected to hold a StringBuffer to print predictions to, 
   * a Range of attributes to output and a Boolean (true if the distribution
   * is to be printed)
   * @return the predictions
   * @throws Exception if model could not be evaluated 
   * successfully 
   */
  public double[] evaluateModel(Classifier classifier,
                                Instances data, 
                                Object... forPredictionsPrinting) throws Exception {
    // for predictions printing
<span class="fc" id="L1392">    StringBuffer buff = null;</span>
<span class="fc" id="L1393">    Range attsToOutput = null;</span>
<span class="fc" id="L1394">    boolean printDist = false;</span>

<span class="fc" id="L1396">    double predictions[] = new double[data.numInstances()];</span>

<span class="pc bpc" id="L1398" title="1 of 2 branches missed.">    if (forPredictionsPrinting.length &gt; 0) {</span>
<span class="nc" id="L1399">      buff = (StringBuffer)forPredictionsPrinting[0];</span>
<span class="nc" id="L1400">      attsToOutput = (Range)forPredictionsPrinting[1];</span>
<span class="nc" id="L1401">      printDist = ((Boolean)forPredictionsPrinting[2]).booleanValue();</span>
    }

    // Need to be able to collect predictions if appropriate (for AUC)

<span class="fc bfc" id="L1406" title="All 2 branches covered.">    for (int i = 0; i &lt; data.numInstances(); i++) {</span>
<span class="fc" id="L1407">      predictions[i] = evaluateModelOnceAndRecordPrediction((Classifier)classifier, </span>
<span class="fc" id="L1408">	  data.instance(i));</span>
<span class="pc bpc" id="L1409" title="1 of 2 branches missed.">      if (buff != null) {</span>
<span class="nc" id="L1410">        buff.append(predictionText(classifier, data.instance(i), i, </span>
<span class="nc" id="L1411">                                   attsToOutput, printDist));</span>
      }
    }

<span class="fc" id="L1415">    return predictions;</span>
  }

  /**
   * Evaluates the classifier on a single instance and records the
   * prediction (if the class is nominal).
   *
   * @param classifier machine learning classifier
   * @param instance the test instance to be classified
   * @return the prediction made by the clasifier
   * @throws Exception if model could not be evaluated 
   * successfully or the data contains string attributes
   */
  public double evaluateModelOnceAndRecordPrediction(Classifier classifier,
      Instance instance) throws Exception {

<span class="fc" id="L1431">    Instance classMissing = (Instance)instance.copy();</span>
<span class="fc" id="L1432">    double pred = 0;</span>
<span class="fc" id="L1433">    classMissing.setDataset(instance.dataset());</span>
<span class="fc" id="L1434">    classMissing.setClassMissing();</span>
<span class="fc bfc" id="L1435" title="All 2 branches covered.">    if (m_ClassIsNominal) {</span>
<span class="fc bfc" id="L1436" title="All 2 branches covered.">      if (m_Predictions == null) {</span>
<span class="fc" id="L1437">	m_Predictions = new FastVector();</span>
      }
<span class="fc" id="L1439">      double [] dist = classifier.distributionForInstance(classMissing);</span>
<span class="fc" id="L1440">      pred = Utils.maxIndex(dist);</span>
<span class="fc bfc" id="L1441" title="All 2 branches covered.">      if (dist[(int)pred] &lt;= 0) {</span>
<span class="fc" id="L1442">	pred = Instance.missingValue();</span>
      }
<span class="fc" id="L1444">      updateStatsForClassifier(dist, instance);</span>
<span class="fc" id="L1445">      m_Predictions.addElement(new NominalPrediction(instance.classValue(), dist, </span>
<span class="fc" id="L1446">	  instance.weight()));</span>
    } else {
<span class="fc" id="L1448">      pred = classifier.classifyInstance(classMissing);</span>
<span class="fc" id="L1449">      updateStatsForPredictor(pred, instance);</span>
    }
<span class="fc" id="L1451">    return pred;</span>
  }

  /**
   * Evaluates the classifier on a single instance.
   *
   * @param classifier machine learning classifier
   * @param instance the test instance to be classified
   * @return the prediction made by the clasifier
   * @throws Exception if model could not be evaluated 
   * successfully or the data contains string attributes
   */
  public double evaluateModelOnce(Classifier classifier,
      Instance instance) throws Exception {

<span class="nc" id="L1466">    Instance classMissing = (Instance)instance.copy();</span>
<span class="nc" id="L1467">    double pred = 0;</span>
<span class="nc" id="L1468">    classMissing.setDataset(instance.dataset());</span>
<span class="nc" id="L1469">    classMissing.setClassMissing();</span>
<span class="nc bnc" id="L1470" title="All 2 branches missed.">    if (m_ClassIsNominal) {</span>
<span class="nc" id="L1471">      double [] dist = classifier.distributionForInstance(classMissing);</span>
<span class="nc" id="L1472">      pred = Utils.maxIndex(dist);</span>
<span class="nc bnc" id="L1473" title="All 2 branches missed.">      if (dist[(int)pred] &lt;= 0) {</span>
<span class="nc" id="L1474">	pred = Instance.missingValue();</span>
      }
<span class="nc" id="L1476">      updateStatsForClassifier(dist, instance);</span>
    } else {
<span class="nc" id="L1478">      pred = classifier.classifyInstance(classMissing);</span>
<span class="nc" id="L1479">      updateStatsForPredictor(pred, instance);</span>
    }
<span class="nc" id="L1481">    return pred;</span>
  }

  /**
   * Evaluates the supplied distribution on a single instance.
   *
   * @param dist the supplied distribution
   * @param instance the test instance to be classified
   * @return the prediction
   * @throws Exception if model could not be evaluated 
   * successfully
   */
  public double evaluateModelOnce(double [] dist, 
      Instance instance) throws Exception {
    double pred;
<span class="fc bfc" id="L1496" title="All 2 branches covered.">    if (m_ClassIsNominal) {</span>
<span class="fc" id="L1497">      pred = Utils.maxIndex(dist);</span>
<span class="pc bpc" id="L1498" title="1 of 2 branches missed.">      if (dist[(int)pred] &lt;= 0) {</span>
<span class="nc" id="L1499">	pred = Instance.missingValue();</span>
      }
<span class="fc" id="L1501">      updateStatsForClassifier(dist, instance);</span>
    } else {
<span class="fc" id="L1503">      pred = dist[0];</span>
<span class="fc" id="L1504">      updateStatsForPredictor(pred, instance);</span>
    }
<span class="fc" id="L1506">    return pred;</span>
  }

  /**
   * Evaluates the supplied distribution on a single instance.
   *
   * @param dist the supplied distribution
   * @param instance the test instance to be classified
   * @return the prediction
   * @throws Exception if model could not be evaluated 
   * successfully
   */
  public double evaluateModelOnceAndRecordPrediction(double [] dist, 
      Instance instance) throws Exception {
    double pred;
<span class="nc bnc" id="L1521" title="All 2 branches missed.">    if (m_ClassIsNominal) {</span>
<span class="nc bnc" id="L1522" title="All 2 branches missed.">      if (m_Predictions == null) {</span>
<span class="nc" id="L1523">	m_Predictions = new FastVector();</span>
      }
<span class="nc" id="L1525">      pred = Utils.maxIndex(dist);</span>
<span class="nc bnc" id="L1526" title="All 2 branches missed.">      if (dist[(int)pred] &lt;= 0) {</span>
<span class="nc" id="L1527">	pred = Instance.missingValue();</span>
      }
<span class="nc" id="L1529">      updateStatsForClassifier(dist, instance);</span>
<span class="nc" id="L1530">      m_Predictions.addElement(new NominalPrediction(instance.classValue(), dist, </span>
<span class="nc" id="L1531">	  instance.weight()));</span>
    } else {
<span class="nc" id="L1533">      pred = dist[0];</span>
<span class="nc" id="L1534">      updateStatsForPredictor(pred, instance);</span>
    }
<span class="nc" id="L1536">    return pred;</span>
  }

  /**
   * Evaluates the supplied prediction on a single instance.
   *
   * @param prediction the supplied prediction
   * @param instance the test instance to be classified
   * @throws Exception if model could not be evaluated 
   * successfully
   */
  public void evaluateModelOnce(double prediction,
      Instance instance) throws Exception {

<span class="nc bnc" id="L1550" title="All 2 branches missed.">    if (m_ClassIsNominal) {</span>
<span class="nc" id="L1551">      updateStatsForClassifier(makeDistribution(prediction), </span>
<span class="nc" id="L1552">	  instance);</span>
    } else {
<span class="nc" id="L1554">      updateStatsForPredictor(prediction, instance);</span>
    }
<span class="nc" id="L1556">  }</span>

  /**
   * Returns the predictions that have been collected.
   *
   * @return a reference to the FastVector containing the predictions
   * that have been collected. This should be null if no predictions
   * have been collected (e.g. if the class is numeric).
   */
  public FastVector predictions() {

<span class="nc" id="L1567">    return m_Predictions;</span>
  }

  /**
   * Wraps a static classifier in enough source to test using the weka
   * class libraries.
   *
   * @param classifier a Sourcable Classifier
   * @param className the name to give to the source code class
   * @return the source for a static classifier that can be tested with
   * weka libraries.
   * @throws Exception if code-generation fails
   */
  public static String wekaStaticWrapper(Sourcable classifier, String className)     
    throws Exception {

<span class="nc" id="L1583">    StringBuffer result = new StringBuffer();</span>
<span class="nc" id="L1584">    String staticClassifier = classifier.toSource(className);</span>
    
<span class="nc" id="L1586">    result.append(&quot;// Generated with Weka &quot; + Version.VERSION + &quot;\n&quot;);</span>
<span class="nc" id="L1587">    result.append(&quot;//\n&quot;);</span>
<span class="nc" id="L1588">    result.append(&quot;// This code is public domain and comes with no warranty.\n&quot;);</span>
<span class="nc" id="L1589">    result.append(&quot;//\n&quot;);</span>
<span class="nc" id="L1590">    result.append(&quot;// Timestamp: &quot; + new Date() + &quot;\n&quot;);</span>
<span class="nc" id="L1591">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1592">    result.append(&quot;package weka.classifiers;\n&quot;);</span>
<span class="nc" id="L1593">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1594">    result.append(&quot;import weka.core.Attribute;\n&quot;);</span>
<span class="nc" id="L1595">    result.append(&quot;import weka.core.Capabilities;\n&quot;);</span>
<span class="nc" id="L1596">    result.append(&quot;import weka.core.Capabilities.Capability;\n&quot;);</span>
<span class="nc" id="L1597">    result.append(&quot;import weka.core.Instance;\n&quot;);</span>
<span class="nc" id="L1598">    result.append(&quot;import weka.core.Instances;\n&quot;);</span>
<span class="nc" id="L1599">    result.append(&quot;import weka.core.RevisionUtils;\n&quot;);</span>
<span class="nc" id="L1600">    result.append(&quot;import weka.classifiers.Classifier;\n&quot;);</span>
<span class="nc" id="L1601">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1602">    result.append(&quot;public class WekaWrapper\n&quot;);</span>
<span class="nc" id="L1603">    result.append(&quot;  extends Classifier {\n&quot;);</span>
    
    // globalInfo
<span class="nc" id="L1606">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1607">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1608">    result.append(&quot;   * Returns only the toString() method.\n&quot;);</span>
<span class="nc" id="L1609">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1610">    result.append(&quot;   * @return a string describing the classifier\n&quot;);</span>
<span class="nc" id="L1611">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1612">    result.append(&quot;  public String globalInfo() {\n&quot;);</span>
<span class="nc" id="L1613">    result.append(&quot;    return toString();\n&quot;);</span>
<span class="nc" id="L1614">    result.append(&quot;  }\n&quot;);</span>
    
    // getCapabilities
<span class="nc" id="L1617">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1618">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1619">    result.append(&quot;   * Returns the capabilities of this classifier.\n&quot;);</span>
<span class="nc" id="L1620">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1621">    result.append(&quot;   * @return the capabilities\n&quot;);</span>
<span class="nc" id="L1622">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1623">    result.append(&quot;  public Capabilities getCapabilities() {\n&quot;);</span>
<span class="nc" id="L1624">    result.append(((Classifier) classifier).getCapabilities().toSource(&quot;result&quot;, 4));</span>
<span class="nc" id="L1625">    result.append(&quot;    return result;\n&quot;);</span>
<span class="nc" id="L1626">    result.append(&quot;  }\n&quot;);</span>
    
    // buildClassifier
<span class="nc" id="L1629">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1630">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1631">    result.append(&quot;   * only checks the data against its capabilities.\n&quot;);</span>
<span class="nc" id="L1632">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1633">    result.append(&quot;   * @param i the training data\n&quot;);</span>
<span class="nc" id="L1634">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1635">    result.append(&quot;  public void buildClassifier(Instances i) throws Exception {\n&quot;);</span>
<span class="nc" id="L1636">    result.append(&quot;    // can classifier handle the data?\n&quot;);</span>
<span class="nc" id="L1637">    result.append(&quot;    getCapabilities().testWithFail(i);\n&quot;);</span>
<span class="nc" id="L1638">    result.append(&quot;  }\n&quot;);</span>
    
    // classifyInstance
<span class="nc" id="L1641">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1642">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1643">    result.append(&quot;   * Classifies the given instance.\n&quot;);</span>
<span class="nc" id="L1644">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1645">    result.append(&quot;   * @param i the instance to classify\n&quot;);</span>
<span class="nc" id="L1646">    result.append(&quot;   * @return the classification result\n&quot;);</span>
<span class="nc" id="L1647">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1648">    result.append(&quot;  public double classifyInstance(Instance i) throws Exception {\n&quot;);</span>
<span class="nc" id="L1649">    result.append(&quot;    Object[] s = new Object[i.numAttributes()];\n&quot;);</span>
<span class="nc" id="L1650">    result.append(&quot;    \n&quot;);</span>
<span class="nc" id="L1651">    result.append(&quot;    for (int j = 0; j &lt; s.length; j++) {\n&quot;);</span>
<span class="nc" id="L1652">    result.append(&quot;      if (!i.isMissing(j)) {\n&quot;);</span>
<span class="nc" id="L1653">    result.append(&quot;        if (i.attribute(j).isNominal())\n&quot;);</span>
<span class="nc" id="L1654">    result.append(&quot;          s[j] = new String(i.stringValue(j));\n&quot;);</span>
<span class="nc" id="L1655">    result.append(&quot;        else if (i.attribute(j).isNumeric())\n&quot;);</span>
<span class="nc" id="L1656">    result.append(&quot;          s[j] = new Double(i.value(j));\n&quot;);</span>
<span class="nc" id="L1657">    result.append(&quot;      }\n&quot;);</span>
<span class="nc" id="L1658">    result.append(&quot;    }\n&quot;);</span>
<span class="nc" id="L1659">    result.append(&quot;    \n&quot;);</span>
<span class="nc" id="L1660">    result.append(&quot;    // set class value to missing\n&quot;);</span>
<span class="nc" id="L1661">    result.append(&quot;    s[i.classIndex()] = null;\n&quot;);</span>
<span class="nc" id="L1662">    result.append(&quot;    \n&quot;);</span>
<span class="nc" id="L1663">    result.append(&quot;    return &quot; + className + &quot;.classify(s);\n&quot;);</span>
<span class="nc" id="L1664">    result.append(&quot;  }\n&quot;);</span>

    // getRevision
<span class="nc" id="L1667">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1668">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1669">    result.append(&quot;   * Returns the revision string.\n&quot;);</span>
<span class="nc" id="L1670">    result.append(&quot;   * \n&quot;);</span>
<span class="nc" id="L1671">    result.append(&quot;   * @return        the revision\n&quot;);</span>
<span class="nc" id="L1672">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1673">    result.append(&quot;  public String getRevision() {\n&quot;);</span>
<span class="nc" id="L1674">    result.append(&quot;    return RevisionUtils.extract(\&quot;1.0\&quot;);\n&quot;);</span>
<span class="nc" id="L1675">    result.append(&quot;  }\n&quot;);</span>

    // toString
<span class="nc" id="L1678">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1679">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1680">    result.append(&quot;   * Returns only the classnames and what classifier it is based on.\n&quot;);</span>
<span class="nc" id="L1681">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1682">    result.append(&quot;   * @return a short description\n&quot;);</span>
<span class="nc" id="L1683">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1684">    result.append(&quot;  public String toString() {\n&quot;);</span>
<span class="nc" id="L1685">    result.append(&quot;    return \&quot;Auto-generated classifier wrapper, based on &quot; </span>
<span class="nc" id="L1686">	+ classifier.getClass().getName() + &quot; (generated with Weka &quot; + Version.VERSION + &quot;).\\n&quot; </span>
<span class="nc" id="L1687">	+ &quot;\&quot; + this.getClass().getName() + \&quot;/&quot; + className + &quot;\&quot;;\n&quot;);</span>
<span class="nc" id="L1688">    result.append(&quot;  }\n&quot;);</span>
    
    // main
<span class="nc" id="L1691">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1692">    result.append(&quot;  /**\n&quot;);</span>
<span class="nc" id="L1693">    result.append(&quot;   * Runs the classfier from commandline.\n&quot;);</span>
<span class="nc" id="L1694">    result.append(&quot;   *\n&quot;);</span>
<span class="nc" id="L1695">    result.append(&quot;   * @param args the commandline arguments\n&quot;);</span>
<span class="nc" id="L1696">    result.append(&quot;   */\n&quot;);</span>
<span class="nc" id="L1697">    result.append(&quot;  public static void main(String args[]) {\n&quot;);</span>
<span class="nc" id="L1698">    result.append(&quot;    runClassifier(new WekaWrapper(), args);\n&quot;);</span>
<span class="nc" id="L1699">    result.append(&quot;  }\n&quot;);</span>
<span class="nc" id="L1700">    result.append(&quot;}\n&quot;);</span>
    
    // actual classifier code
<span class="nc" id="L1703">    result.append(&quot;\n&quot;);</span>
<span class="nc" id="L1704">    result.append(staticClassifier);</span>
    
<span class="nc" id="L1706">    return result.toString();</span>
  }

  /**
   * Gets the number of test instances that had a known class value
   * (actually the sum of the weights of test instances with known 
   * class value).
   *
   * @return the number of test instances with known class
   */
  public final double numInstances() {

<span class="nc" id="L1718">    return m_WithClass;</span>
  }

  /**
   * Gets the number of instances incorrectly classified (that is, for
   * which an incorrect prediction was made). (Actually the sum of the weights
   * of these instances)
   *
   * @return the number of incorrectly classified instances 
   */
  public final double incorrect() {

<span class="fc" id="L1730">    return m_Incorrect;</span>
  }

  /**
   * Gets the percentage of instances incorrectly classified (that is, for
   * which an incorrect prediction was made).
   *
   * @return the percent of incorrectly classified instances 
   * (between 0 and 100)
   */
  public final double pctIncorrect() {

<span class="nc" id="L1742">    return 100 * m_Incorrect / m_WithClass;</span>
  }

  /**
   * Gets the total cost, that is, the cost of each prediction times the
   * weight of the instance, summed over all instances.
   *
   * @return the total cost
   */
  public final double totalCost() {

<span class="nc" id="L1753">    return m_TotalCost;</span>
  }

  /**
   * Gets the average cost, that is, total cost of misclassifications
   * (incorrect plus unclassified) over the total number of instances.
   *
   * @return the average cost.  
   */
  public final double avgCost() {

<span class="nc" id="L1764">    return m_TotalCost / m_WithClass;</span>
  }

  /**
   * Gets the number of instances correctly classified (that is, for
   * which a correct prediction was made). (Actually the sum of the weights
   * of these instances)
   *
   * @return the number of correctly classified instances
   */
  public final double correct() {

<span class="nc" id="L1776">    return m_Correct;</span>
  }

  /**
   * Gets the percentage of instances correctly classified (that is, for
   * which a correct prediction was made).
   *
   * @return the percent of correctly classified instances (between 0 and 100)
   */
  public final double pctCorrect() {

<span class="fc" id="L1787">    return 100 * m_Correct / m_WithClass;</span>
  }

  /**
   * Gets the number of instances not classified (that is, for
   * which no prediction was made by the classifier). (Actually the sum
   * of the weights of these instances)
   *
   * @return the number of unclassified instances
   */
  public final double unclassified() {

<span class="nc" id="L1799">    return m_Unclassified;</span>
  }

  /**
   * Gets the percentage of instances not classified (that is, for
   * which no prediction was made by the classifier).
   *
   * @return the percent of unclassified instances (between 0 and 100)
   */
  public final double pctUnclassified() {

<span class="nc" id="L1810">    return 100 * m_Unclassified / m_WithClass;</span>
  }

  /**
   * Returns the estimated error rate or the root mean squared error
   * (if the class is numeric). If a cost matrix was given this
   * error rate gives the average cost.
   *
   * @return the estimated error rate (between 0 and 1, or between 0 and 
   * maximum cost)
   */
  public final double errorRate() {

<span class="fc bfc" id="L1823" title="All 2 branches covered.">    if (!m_ClassIsNominal) {</span>
<span class="fc" id="L1824">      return Math.sqrt(m_SumSqrErr / (m_WithClass - m_Unclassified));</span>
    }
<span class="pc bpc" id="L1826" title="1 of 2 branches missed.">    if (m_CostMatrix == null) {</span>
<span class="fc" id="L1827">      return m_Incorrect / m_WithClass;</span>
    } else {
<span class="nc" id="L1829">      return avgCost();</span>
    }
  }

  /**
   * Returns value of kappa statistic if class is nominal.
   *
   * @return the value of the kappa statistic
   */
  public final double kappa() {


<span class="fc" id="L1841">    double[] sumRows = new double[m_ConfusionMatrix.length];</span>
<span class="fc" id="L1842">    double[] sumColumns = new double[m_ConfusionMatrix.length];</span>
<span class="fc" id="L1843">    double sumOfWeights = 0;</span>
<span class="fc bfc" id="L1844" title="All 2 branches covered.">    for (int i = 0; i &lt; m_ConfusionMatrix.length; i++) {</span>
<span class="fc bfc" id="L1845" title="All 2 branches covered.">      for (int j = 0; j &lt; m_ConfusionMatrix.length; j++) {</span>
<span class="fc" id="L1846">	sumRows[i] += m_ConfusionMatrix[i][j];</span>
<span class="fc" id="L1847">	sumColumns[j] += m_ConfusionMatrix[i][j];</span>
<span class="fc" id="L1848">	sumOfWeights += m_ConfusionMatrix[i][j];</span>
      }
    }
<span class="fc" id="L1851">    double correct = 0, chanceAgreement = 0;</span>
<span class="fc bfc" id="L1852" title="All 2 branches covered.">    for (int i = 0; i &lt; m_ConfusionMatrix.length; i++) {</span>
<span class="fc" id="L1853">      chanceAgreement += (sumRows[i] * sumColumns[i]);</span>
<span class="fc" id="L1854">      correct += m_ConfusionMatrix[i][i];</span>
    }
<span class="fc" id="L1856">    chanceAgreement /= (sumOfWeights * sumOfWeights);</span>
<span class="fc" id="L1857">    correct /= sumOfWeights;</span>

<span class="pc bpc" id="L1859" title="1 of 2 branches missed.">    if (chanceAgreement &lt; 1) {</span>
<span class="fc" id="L1860">      return (correct - chanceAgreement) / (1 - chanceAgreement);</span>
    } else {
<span class="nc" id="L1862">      return 1;</span>
    }
  }

  /**
   * Returns the correlation coefficient if the class is numeric.
   *
   * @return the correlation coefficient
   * @throws Exception if class is not numeric
   */
  public final double correlationCoefficient() throws Exception {

<span class="pc bpc" id="L1874" title="1 of 2 branches missed.">    if (m_ClassIsNominal) {</span>
<span class="fc" id="L1875">      throw</span>
<span class="fc" id="L1876">      new Exception(&quot;Can't compute correlation coefficient: &quot; + </span>
      &quot;class is nominal!&quot;);
    }

<span class="nc" id="L1880">    double correlation = 0;</span>
<span class="nc" id="L1881">    double varActual = </span>
<span class="nc" id="L1882">      m_SumSqrClass - m_SumClass * m_SumClass / </span>
<span class="nc" id="L1883">      (m_WithClass - m_Unclassified);</span>
<span class="nc" id="L1884">    double varPredicted = </span>
<span class="nc" id="L1885">      m_SumSqrPredicted - m_SumPredicted * m_SumPredicted / </span>
<span class="nc" id="L1886">      (m_WithClass - m_Unclassified);</span>
<span class="nc" id="L1887">    double varProd = </span>
<span class="nc" id="L1888">      m_SumClassPredicted - m_SumClass * m_SumPredicted / </span>
<span class="nc" id="L1889">      (m_WithClass - m_Unclassified);</span>

<span class="nc bnc" id="L1891" title="All 2 branches missed.">    if (varActual * varPredicted &lt;= 0) {</span>
<span class="nc" id="L1892">      correlation = 0.0;</span>
    } else {
<span class="nc" id="L1894">      correlation = varProd / Math.sqrt(varActual * varPredicted);</span>
    }

<span class="nc" id="L1897">    return correlation;</span>
  }

  /**
   * Returns the mean absolute error. Refers to the error of the
   * predicted values for numeric classes, and the error of the 
   * predicted probability distribution for nominal classes.
   *
   * @return the mean absolute error 
   */
  public final double meanAbsoluteError() {

<span class="fc" id="L1909">    return m_SumAbsErr / (m_WithClass - m_Unclassified);</span>
  }

  /**
   * Returns the mean absolute error of the prior.
   *
   * @return the mean absolute error 
   */
  public final double meanPriorAbsoluteError() {

<span class="pc bpc" id="L1919" title="1 of 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L1920">      return Double.NaN;</span>

<span class="fc" id="L1922">    return m_SumPriorAbsErr / m_WithClass;</span>
  }

  /**
   * Returns the relative absolute error.
   *
   * @return the relative absolute error 
   * @throws Exception if it can't be computed
   */
  public final double relativeAbsoluteError() throws Exception {

<span class="pc bpc" id="L1933" title="1 of 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L1934">      return Double.NaN;</span>

<span class="fc" id="L1936">    return 100 * meanAbsoluteError() / meanPriorAbsoluteError();</span>
  }

  /**
   * Returns the root mean squared error.
   *
   * @return the root mean squared error 
   */
  public final double rootMeanSquaredError() {

<span class="fc" id="L1946">    return Math.sqrt(m_SumSqrErr / (m_WithClass - m_Unclassified));</span>
  }

  /**
   * Returns the root mean prior squared error.
   *
   * @return the root mean prior squared error 
   */
  public final double rootMeanPriorSquaredError() {

<span class="pc bpc" id="L1956" title="1 of 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L1957">      return Double.NaN;</span>

<span class="fc" id="L1959">    return Math.sqrt(m_SumPriorSqrErr / m_WithClass);</span>
  }

  /**
   * Returns the root relative squared error if the class is numeric.
   *
   * @return the root relative squared error 
   */
  public final double rootRelativeSquaredError() {

<span class="pc bpc" id="L1969" title="1 of 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L1970">      return Double.NaN;</span>

<span class="fc" id="L1972">    return 100.0 * rootMeanSquaredError() / </span>
<span class="fc" id="L1973">    rootMeanPriorSquaredError();</span>
  }

  /**
   * Calculate the entropy of the prior distribution
   *
   * @return the entropy of the prior distribution
   * @throws Exception if the class is not nominal
   */
  public final double priorEntropy() throws Exception {

<span class="nc bnc" id="L1984" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L1985">      throw</span>
<span class="nc" id="L1986">      new Exception(&quot;Can't compute entropy of class prior: &quot; + </span>
      &quot;class numeric!&quot;);
    }

<span class="nc bnc" id="L1990" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L1991">      return Double.NaN;</span>

<span class="nc" id="L1993">    double entropy = 0;</span>
<span class="nc bnc" id="L1994" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L1995">      entropy -= m_ClassPriors[i] / m_ClassPriorsSum </span>
<span class="nc" id="L1996">      * Utils.log2(m_ClassPriors[i] / m_ClassPriorsSum);</span>
    }
<span class="nc" id="L1998">    return entropy;</span>
  }

  /**
   * Return the total Kononenko &amp; Bratko Information score in bits
   *
   * @return the K&amp;B information score
   * @throws Exception if the class is not nominal
   */
  public final double KBInformation() throws Exception {

<span class="nc bnc" id="L2009" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2010">      throw</span>
<span class="nc" id="L2011">      new Exception(&quot;Can't compute K&amp;B Info score: &quot; + </span>
      &quot;class numeric!&quot;);
    }

<span class="nc bnc" id="L2015" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2016">      return Double.NaN;</span>

<span class="nc" id="L2018">    return m_SumKBInfo;</span>
  }

  /**
   * Return the Kononenko &amp; Bratko Information score in bits per 
   * instance.
   *
   * @return the K&amp;B information score
   * @throws Exception if the class is not nominal
   */
  public final double KBMeanInformation() throws Exception {

<span class="nc bnc" id="L2030" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2031">      throw</span>
<span class="nc" id="L2032">      new Exception(&quot;Can't compute K&amp;B Info score: &quot;</span>
	  + &quot;class numeric!&quot;);
    }

<span class="nc bnc" id="L2036" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2037">      return Double.NaN;</span>

<span class="nc" id="L2039">    return m_SumKBInfo / (m_WithClass - m_Unclassified);</span>
  }

  /**
   * Return the Kononenko &amp; Bratko Relative Information score
   *
   * @return the K&amp;B relative information score
   * @throws Exception if the class is not nominal
   */
  public final double KBRelativeInformation() throws Exception {

<span class="nc bnc" id="L2050" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2051">      throw</span>
<span class="nc" id="L2052">      new Exception(&quot;Can't compute K&amp;B Info score: &quot; + </span>
      &quot;class numeric!&quot;);
    }

<span class="nc bnc" id="L2056" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2057">      return Double.NaN;</span>

<span class="nc" id="L2059">    return 100.0 * KBInformation() / priorEntropy();</span>
  }

  /**
   * Returns the total entropy for the null model
   * 
   * @return the total null model entropy
   */
  public final double SFPriorEntropy() {

<span class="nc bnc" id="L2069" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2070">      return Double.NaN;</span>

<span class="nc" id="L2072">    return m_SumPriorEntropy;</span>
  }

  /**
   * Returns the entropy per instance for the null model
   * 
   * @return the null model entropy per instance
   */
  public final double SFMeanPriorEntropy() {

<span class="nc bnc" id="L2082" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2083">      return Double.NaN;</span>

<span class="nc" id="L2085">    return m_SumPriorEntropy / m_WithClass;</span>
  }

  /**
   * Returns the total entropy for the scheme
   * 
   * @return the total scheme entropy
   */
  public final double SFSchemeEntropy() {

<span class="nc bnc" id="L2095" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2096">      return Double.NaN;</span>

<span class="nc" id="L2098">    return m_SumSchemeEntropy;</span>
  }

  /**
   * Returns the entropy per instance for the scheme
   * 
   * @return the scheme entropy per instance
   */
  public final double SFMeanSchemeEntropy() {

<span class="nc bnc" id="L2108" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2109">      return Double.NaN;</span>

<span class="nc" id="L2111">    return m_SumSchemeEntropy / (m_WithClass - m_Unclassified);</span>
  }

  /**
   * Returns the total SF, which is the null model entropy minus
   * the scheme entropy.
   * 
   * @return the total SF
   */
  public final double SFEntropyGain() {

<span class="nc bnc" id="L2122" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2123">      return Double.NaN;</span>

<span class="nc" id="L2125">    return m_SumPriorEntropy - m_SumSchemeEntropy;</span>
  }

  /**
   * Returns the SF per instance, which is the null model entropy
   * minus the scheme entropy, per instance.
   * 
   * @return the SF per instance
   */
  public final double SFMeanEntropyGain() {

<span class="nc bnc" id="L2136" title="All 2 branches missed.">    if (m_NoPriors)</span>
<span class="nc" id="L2137">      return Double.NaN;</span>

<span class="nc" id="L2139">    return (m_SumPriorEntropy - m_SumSchemeEntropy) / </span>
<span class="nc" id="L2140">      (m_WithClass - m_Unclassified);</span>
  }

  /**
   * Output the cumulative margin distribution as a string suitable
   * for input for gnuplot or similar package.
   *
   * @return the cumulative margin distribution
   * @throws Exception if the class attribute is nominal
   */
  public String toCumulativeMarginDistributionString() throws Exception {

<span class="nc bnc" id="L2152" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2153">      throw new Exception(&quot;Class must be nominal for margin distributions&quot;);</span>
    }
<span class="nc" id="L2155">    String result = &quot;&quot;;</span>
<span class="nc" id="L2156">    double cumulativeCount = 0;</span>
    double margin;
<span class="nc bnc" id="L2158" title="All 2 branches missed.">    for(int i = 0; i &lt;= k_MarginResolution; i++) {</span>
<span class="nc bnc" id="L2159" title="All 2 branches missed.">      if (m_MarginCounts[i] != 0) {</span>
<span class="nc" id="L2160">	cumulativeCount += m_MarginCounts[i];</span>
<span class="nc" id="L2161">	margin = (double)i * 2.0 / k_MarginResolution - 1.0;</span>
<span class="nc" id="L2162">	result = result + Utils.doubleToString(margin, 7, 3) + ' ' </span>
<span class="nc" id="L2163">	+ Utils.doubleToString(cumulativeCount * 100 </span>
<span class="nc" id="L2164">	    / m_WithClass, 7, 3) + '\n';</span>
<span class="nc bnc" id="L2165" title="All 2 branches missed.">      } else if (i == 0) {</span>
<span class="nc" id="L2166">	result = Utils.doubleToString(-1.0, 7, 3) + ' ' </span>
<span class="nc" id="L2167">	+ Utils.doubleToString(0, 7, 3) + '\n';</span>
      }
    }
<span class="nc" id="L2170">    return result;</span>
  }


  /**
   * Calls toSummaryString() with no title and no complexity stats
   *
   * @return a summary description of the classifier evaluation
   */
  public String toSummaryString() {

<span class="nc" id="L2181">    return toSummaryString(&quot;&quot;, false);</span>
  }

  /**
   * Calls toSummaryString() with a default title.
   *
   * @param printComplexityStatistics if true, complexity statistics are
   * returned as well
   * @return the summary string
   */
  public String toSummaryString(boolean printComplexityStatistics) {

<span class="nc" id="L2193">    return toSummaryString(&quot;=== Summary ===\n&quot;, printComplexityStatistics);</span>
  }

  /**
   * Outputs the performance statistics in summary form. Lists 
   * number (and percentage) of instances classified correctly, 
   * incorrectly and unclassified. Outputs the total number of 
   * instances classified, and the number of instances (if any) 
   * that had no class value provided. 
   *
   * @param title the title for the statistics
   * @param printComplexityStatistics if true, complexity statistics are
   * returned as well
   * @return the summary as a String
   */
  public String toSummaryString(String title, 
      boolean printComplexityStatistics) { 

<span class="nc" id="L2211">    StringBuffer text = new StringBuffer();</span>

<span class="nc bnc" id="L2213" title="All 4 branches missed.">    if (printComplexityStatistics &amp;&amp; m_NoPriors) {</span>
<span class="nc" id="L2214">      printComplexityStatistics = false;</span>
<span class="nc" id="L2215">      System.err.println(&quot;Priors disabled, cannot print complexity statistics!&quot;);</span>
    }

<span class="nc" id="L2218">    text.append(title + &quot;\n&quot;);</span>
    try {
<span class="nc bnc" id="L2220" title="All 2 branches missed.">      if (m_WithClass &gt; 0) {</span>
<span class="nc bnc" id="L2221" title="All 2 branches missed.">	if (m_ClassIsNominal) {</span>

<span class="nc" id="L2223">	  text.append(&quot;Correctly Classified Instances     &quot;);</span>
<span class="nc" id="L2224">	  text.append(Utils.doubleToString(correct(), 12, 4) + &quot;     &quot; +</span>
<span class="nc" id="L2225">	      Utils.doubleToString(pctCorrect(),</span>
<span class="nc" id="L2226">		  12, 4) + &quot; %\n&quot;);</span>
<span class="nc" id="L2227">	  text.append(&quot;Incorrectly Classified Instances   &quot;);</span>
<span class="nc" id="L2228">	  text.append(Utils.doubleToString(incorrect(), 12, 4) + &quot;     &quot; +</span>
<span class="nc" id="L2229">	      Utils.doubleToString(pctIncorrect(),</span>
<span class="nc" id="L2230">		  12, 4) + &quot; %\n&quot;);</span>
<span class="nc" id="L2231">	  text.append(&quot;Kappa statistic                    &quot;);</span>
<span class="nc" id="L2232">	  text.append(Utils.doubleToString(kappa(), 12, 4) + &quot;\n&quot;);</span>

<span class="nc bnc" id="L2234" title="All 2 branches missed.">	  if (m_CostMatrix != null) {</span>
<span class="nc" id="L2235">	    text.append(&quot;Total Cost                         &quot;);</span>
<span class="nc" id="L2236">	    text.append(Utils.doubleToString(totalCost(), 12, 4) + &quot;\n&quot;);</span>
<span class="nc" id="L2237">	    text.append(&quot;Average Cost                       &quot;);</span>
<span class="nc" id="L2238">	    text.append(Utils.doubleToString(avgCost(), 12, 4) + &quot;\n&quot;);</span>
	  }
<span class="nc bnc" id="L2240" title="All 2 branches missed.">	  if (printComplexityStatistics) {</span>
<span class="nc" id="L2241">	    text.append(&quot;K&amp;B Relative Info Score            &quot;);</span>
<span class="nc" id="L2242">	    text.append(Utils.doubleToString(KBRelativeInformation(), 12, 4) </span>
<span class="nc" id="L2243">		+ &quot; %\n&quot;);</span>
<span class="nc" id="L2244">	    text.append(&quot;K&amp;B Information Score              &quot;);</span>
<span class="nc" id="L2245">	    text.append(Utils.doubleToString(KBInformation(), 12, 4) </span>
<span class="nc" id="L2246">		+ &quot; bits&quot;);</span>
<span class="nc" id="L2247">	    text.append(Utils.doubleToString(KBMeanInformation(), 12, 4) </span>
<span class="nc" id="L2248">		+ &quot; bits/instance\n&quot;);</span>
	  }
	} else {        
<span class="nc" id="L2251">	  text.append(&quot;Correlation coefficient            &quot;);</span>
<span class="nc" id="L2252">	  text.append(Utils.doubleToString(correlationCoefficient(), 12 , 4) +</span>
<span class="nc" id="L2253">	  &quot;\n&quot;);</span>
	}
<span class="nc bnc" id="L2255" title="All 2 branches missed.">	if (printComplexityStatistics) {</span>
<span class="nc" id="L2256">	  text.append(&quot;Class complexity | order 0         &quot;);</span>
<span class="nc" id="L2257">	  text.append(Utils.doubleToString(SFPriorEntropy(), 12, 4) </span>
<span class="nc" id="L2258">	      + &quot; bits&quot;);</span>
<span class="nc" id="L2259">	  text.append(Utils.doubleToString(SFMeanPriorEntropy(), 12, 4) </span>
<span class="nc" id="L2260">	      + &quot; bits/instance\n&quot;);</span>
<span class="nc" id="L2261">	  text.append(&quot;Class complexity | scheme          &quot;);</span>
<span class="nc" id="L2262">	  text.append(Utils.doubleToString(SFSchemeEntropy(), 12, 4) </span>
<span class="nc" id="L2263">	      + &quot; bits&quot;);</span>
<span class="nc" id="L2264">	  text.append(Utils.doubleToString(SFMeanSchemeEntropy(), 12, 4) </span>
<span class="nc" id="L2265">	      + &quot; bits/instance\n&quot;);</span>
<span class="nc" id="L2266">	  text.append(&quot;Complexity improvement     (Sf)    &quot;);</span>
<span class="nc" id="L2267">	  text.append(Utils.doubleToString(SFEntropyGain(), 12, 4) + &quot; bits&quot;);</span>
<span class="nc" id="L2268">	  text.append(Utils.doubleToString(SFMeanEntropyGain(), 12, 4) </span>
<span class="nc" id="L2269">	      + &quot; bits/instance\n&quot;);</span>
	}

<span class="nc" id="L2272">	text.append(&quot;Mean absolute error                &quot;);</span>
<span class="nc" id="L2273">	text.append(Utils.doubleToString(meanAbsoluteError(), 12, 4) </span>
<span class="nc" id="L2274">	    + &quot;\n&quot;);</span>
<span class="nc" id="L2275">	text.append(&quot;Root mean squared error            &quot;);</span>
<span class="nc" id="L2276">	text.append(Utils.</span>
<span class="nc" id="L2277">	    doubleToString(rootMeanSquaredError(), 12, 4) </span>
<span class="nc" id="L2278">	    + &quot;\n&quot;);</span>
<span class="nc bnc" id="L2279" title="All 2 branches missed.">	if (!m_NoPriors) {</span>
<span class="nc" id="L2280">	  text.append(&quot;Relative absolute error            &quot;);</span>
<span class="nc" id="L2281">	  text.append(Utils.doubleToString(relativeAbsoluteError(), </span>
<span class="nc" id="L2282">	      12, 4) + &quot; %\n&quot;);</span>
<span class="nc" id="L2283">	  text.append(&quot;Root relative squared error        &quot;);</span>
<span class="nc" id="L2284">	  text.append(Utils.doubleToString(rootRelativeSquaredError(), </span>
<span class="nc" id="L2285">	      12, 4) + &quot; %\n&quot;);</span>
	}
      }
<span class="nc bnc" id="L2288" title="All 2 branches missed.">      if (Utils.gr(unclassified(), 0)) {</span>
<span class="nc" id="L2289">	text.append(&quot;UnClassified Instances             &quot;);</span>
<span class="nc" id="L2290">	text.append(Utils.doubleToString(unclassified(), 12,4) +  &quot;     &quot; +</span>
<span class="nc" id="L2291">	    Utils.doubleToString(pctUnclassified(),</span>
<span class="nc" id="L2292">		12, 4) + &quot; %\n&quot;);</span>
      }
<span class="nc" id="L2294">      text.append(&quot;Total Number of Instances          &quot;);</span>
<span class="nc" id="L2295">      text.append(Utils.doubleToString(m_WithClass, 12, 4) + &quot;\n&quot;);</span>
<span class="nc bnc" id="L2296" title="All 2 branches missed.">      if (m_MissingClass &gt; 0) {</span>
<span class="nc" id="L2297">	text.append(&quot;Ignored Class Unknown Instances            &quot;);</span>
<span class="nc" id="L2298">	text.append(Utils.doubleToString(m_MissingClass, 12, 4) + &quot;\n&quot;);</span>
      }
<span class="nc" id="L2300">    } catch (Exception ex) {</span>
      // Should never occur since the class is known to be nominal 
      // here
<span class="nc" id="L2303">      System.err.println(&quot;Arggh - Must be a bug in Evaluation class&quot;);</span>
    }

<span class="nc" id="L2306">    return text.toString(); </span>
  }

  /**
   * Calls toMatrixString() with a default title.
   *
   * @return the confusion matrix as a string
   * @throws Exception if the class is numeric
   */
  public String toMatrixString() throws Exception {

<span class="nc" id="L2317">    return toMatrixString(&quot;=== Confusion Matrix ===\n&quot;);</span>
  }

  /**
   * Outputs the performance statistics as a classification confusion
   * matrix. For each class value, shows the distribution of 
   * predicted class values.
   *
   * @param title the title for the confusion matrix
   * @return the confusion matrix as a String
   * @throws Exception if the class is numeric
   */
  public String toMatrixString(String title) throws Exception {

<span class="nc" id="L2331">    StringBuffer text = new StringBuffer();</span>
<span class="nc" id="L2332">    char [] IDChars = {'a','b','c','d','e','f','g','h','i','j',</span>
<span class="nc" id="L2333">	'k','l','m','n','o','p','q','r','s','t',</span>
<span class="nc" id="L2334">	'u','v','w','x','y','z'};</span>
    int IDWidth;
<span class="nc" id="L2336">    boolean fractional = false;</span>

<span class="nc bnc" id="L2338" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2339">      throw new Exception(&quot;Evaluation: No confusion matrix possible!&quot;);</span>
    }

    // Find the maximum value in the matrix
    // and check for fractional display requirement 
<span class="nc" id="L2344">    double maxval = 0;</span>
<span class="nc bnc" id="L2345" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2346" title="All 2 branches missed.">      for(int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2347">	double current = m_ConfusionMatrix[i][j];</span>
<span class="nc bnc" id="L2348" title="All 2 branches missed.">	if (current &lt; 0) {</span>
<span class="nc" id="L2349">	  current *= -10;</span>
	}
<span class="nc bnc" id="L2351" title="All 2 branches missed.">	if (current &gt; maxval) {</span>
<span class="nc" id="L2352">	  maxval = current;</span>
	}
<span class="nc" id="L2354">	double fract = current - Math.rint(current);</span>
<span class="nc bnc" id="L2355" title="All 2 branches missed.">	if (!fractional</span>
<span class="nc bnc" id="L2356" title="All 2 branches missed.">	    &amp;&amp; ((Math.log(fract) / Math.log(10)) &gt;= -2)) {</span>
<span class="nc" id="L2357">	  fractional = true;</span>
	}
      }
    }

<span class="nc" id="L2362">    IDWidth = 1 + Math.max((int)(Math.log(maxval) / Math.log(10) </span>
<span class="nc bnc" id="L2363" title="All 2 branches missed.">	+ (fractional ? 3 : 0)),</span>
<span class="nc" id="L2364">	(int)(Math.log(m_NumClasses) / </span>
<span class="nc" id="L2365">	    Math.log(IDChars.length)));</span>
<span class="nc" id="L2366">    text.append(title).append(&quot;\n&quot;);</span>
<span class="nc bnc" id="L2367" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2368" title="All 2 branches missed.">      if (fractional) {</span>
<span class="nc" id="L2369">	text.append(&quot; &quot;).append(num2ShortID(i,IDChars,IDWidth - 3))</span>
<span class="nc" id="L2370">	.append(&quot;   &quot;);</span>
      } else {
<span class="nc" id="L2372">	text.append(&quot; &quot;).append(num2ShortID(i,IDChars,IDWidth));</span>
      }
    }
<span class="nc" id="L2375">    text.append(&quot;   &lt;-- classified as\n&quot;);</span>
<span class="nc bnc" id="L2376" title="All 2 branches missed.">    for(int i = 0; i&lt; m_NumClasses; i++) { </span>
<span class="nc bnc" id="L2377" title="All 2 branches missed.">      for(int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2378">	text.append(&quot; &quot;).append(</span>
<span class="nc" id="L2379">	    Utils.doubleToString(m_ConfusionMatrix[i][j],</span>
<span class="nc" id="L2380">		IDWidth,</span>
<span class="nc bnc" id="L2381" title="All 2 branches missed.">		(fractional ? 2 : 0)));</span>
      }
<span class="nc" id="L2383">      text.append(&quot; | &quot;).append(num2ShortID(i,IDChars,IDWidth))</span>
<span class="nc" id="L2384">      .append(&quot; = &quot;).append(m_ClassNames[i]).append(&quot;\n&quot;);</span>
    }
<span class="nc" id="L2386">    return text.toString();</span>
  }

  /**
   * Generates a breakdown of the accuracy for each class (with default title),
   * incorporating various information-retrieval statistics, such as
   * true/false positive rate, precision/recall/F-Measure.  Should be
   * useful for ROC curves, recall/precision curves.  
   * 
   * @return the statistics presented as a string
   * @throws Exception if class is not nominal
   */
  public String toClassDetailsString() throws Exception {

<span class="nc" id="L2400">    return toClassDetailsString(&quot;=== Detailed Accuracy By Class ===\n&quot;);</span>
  }

  /**
   * Generates a breakdown of the accuracy for each class,
   * incorporating various information-retrieval statistics, such as
   * true/false positive rate, precision/recall/F-Measure.  Should be
   * useful for ROC curves, recall/precision curves.  
   * 
   * @param title the title to prepend the stats string with 
   * @return the statistics presented as a string
   * @throws Exception if class is not nominal
   */
  public String toClassDetailsString(String title) throws Exception {

<span class="nc bnc" id="L2415" title="All 2 branches missed.">    if (!m_ClassIsNominal) {</span>
<span class="nc" id="L2416">      throw new Exception(&quot;Evaluation: No confusion matrix possible!&quot;);</span>
    }

<span class="nc" id="L2419">    StringBuffer text = new StringBuffer(title </span>
<span class="nc" id="L2420">	+ &quot;\n               TP Rate   FP Rate&quot;</span>
<span class="nc" id="L2421">	+ &quot;   Precision   Recall&quot;</span>
<span class="nc" id="L2422">	+ &quot;  F-Measure   ROC Area  Class\n&quot;);</span>
<span class="nc bnc" id="L2423" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2424">      text.append(&quot;               &quot; + Utils.doubleToString(truePositiveRate(i), 7, 3))</span>
<span class="nc" id="L2425">      .append(&quot;   &quot;);      </span>
<span class="nc" id="L2426">      text.append(Utils.doubleToString(falsePositiveRate(i), 7, 3))</span>
<span class="nc" id="L2427">      .append(&quot;    &quot;);</span>
<span class="nc" id="L2428">      text.append(Utils.doubleToString(precision(i), 7, 3))</span>
<span class="nc" id="L2429">      .append(&quot;   &quot;);</span>
<span class="nc" id="L2430">      text.append(Utils.doubleToString(recall(i), 7, 3))</span>
<span class="nc" id="L2431">      .append(&quot;   &quot;);</span>
<span class="nc" id="L2432">      text.append(Utils.doubleToString(fMeasure(i), 7, 3))</span>
<span class="nc" id="L2433">      .append(&quot;    &quot;);</span>

<span class="nc" id="L2435">      double rocVal = areaUnderROC(i);</span>
<span class="nc bnc" id="L2436" title="All 2 branches missed.">      if (Instance.isMissingValue(rocVal)) {</span>
<span class="nc" id="L2437">	text.append(&quot;  ?    &quot;)</span>
<span class="nc" id="L2438">	.append(&quot;    &quot;);</span>
      } else {
<span class="nc" id="L2440">	text.append(Utils.doubleToString(rocVal, 7, 3))</span>
<span class="nc" id="L2441">	.append(&quot;    &quot;);</span>
      }
<span class="nc" id="L2443">      text.append(m_ClassNames[i]).append('\n');</span>
    }

<span class="nc" id="L2446">    text.append(&quot;Weighted Avg.  &quot; + Utils.doubleToString(weightedTruePositiveRate(), 7, 3));</span>
<span class="nc" id="L2447">    text.append(&quot;   &quot; + Utils.doubleToString(weightedFalsePositiveRate(), 7 ,3));</span>
<span class="nc" id="L2448">    text.append(&quot;    &quot; + Utils.doubleToString(weightedPrecision(), 7 ,3));</span>
<span class="nc" id="L2449">    text.append(&quot;   &quot; + Utils.doubleToString(weightedRecall(), 7 ,3));</span>
<span class="nc" id="L2450">    text.append(&quot;   &quot; + Utils.doubleToString(weightedFMeasure(), 7 ,3));</span>
<span class="nc" id="L2451">    text.append(&quot;    &quot; + Utils.doubleToString(weightedAreaUnderROC(), 7 ,3));</span>
<span class="nc" id="L2452">    text.append(&quot;\n&quot;);</span>
    
<span class="nc" id="L2454">    return text.toString();</span>
  }

  /**
   * Calculate the number of true positives with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified positives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the true positive rate
   */
  public double numTruePositives(int classIndex) {

<span class="nc" id="L2469">    double correct = 0;</span>
<span class="nc bnc" id="L2470" title="All 2 branches missed.">    for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2471" title="All 2 branches missed.">      if (j == classIndex) {</span>
<span class="nc" id="L2472">	correct += m_ConfusionMatrix[classIndex][j];</span>
      }
    }
<span class="nc" id="L2475">    return correct;</span>
  }

  /**
   * Calculate the true positive rate with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified positives
   * ------------------------------
   *       total positives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the true positive rate
   */
  public double truePositiveRate(int classIndex) {

<span class="nc" id="L2492">    double correct = 0, total = 0;</span>
<span class="nc bnc" id="L2493" title="All 2 branches missed.">    for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2494" title="All 2 branches missed.">      if (j == classIndex) {</span>
<span class="nc" id="L2495">	correct += m_ConfusionMatrix[classIndex][j];</span>
      }
<span class="nc" id="L2497">      total += m_ConfusionMatrix[classIndex][j];</span>
    }
<span class="nc bnc" id="L2499" title="All 2 branches missed.">    if (total == 0) {</span>
<span class="nc" id="L2500">      return 0;</span>
    }
<span class="nc" id="L2502">    return correct / total;</span>
  }

  /**
   * Calculates the weighted (by class size) true positive rate.
   *
   * @return the weighted true positive rate.
   */
  public double weightedTruePositiveRate() {
<span class="nc" id="L2511">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2512">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2514" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2515" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2516">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2518">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2521">    double truePosTotal = 0;</span>
<span class="nc bnc" id="L2522" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2523">      double temp = truePositiveRate(i);</span>
<span class="nc" id="L2524">      truePosTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2527">    return truePosTotal / classCountSum;</span>
  }

  /**
   * Calculate the number of true negatives with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified negatives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the true positive rate
   */
  public double numTrueNegatives(int classIndex) {

<span class="nc" id="L2542">    double correct = 0;</span>
<span class="nc bnc" id="L2543" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2544" title="All 2 branches missed.">      if (i != classIndex) {</span>
<span class="nc bnc" id="L2545" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2546" title="All 2 branches missed.">	  if (j != classIndex) {</span>
<span class="nc" id="L2547">	    correct += m_ConfusionMatrix[i][j];</span>
	  }
	}
      }
    }
<span class="nc" id="L2552">    return correct;</span>
  }

  /**
   * Calculate the true negative rate with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified negatives
   * ------------------------------
   *       total negatives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the true positive rate
   */
  public double trueNegativeRate(int classIndex) {

<span class="nc" id="L2569">    double correct = 0, total = 0;</span>
<span class="nc bnc" id="L2570" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2571" title="All 2 branches missed.">      if (i != classIndex) {</span>
<span class="nc bnc" id="L2572" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2573" title="All 2 branches missed.">	  if (j != classIndex) {</span>
<span class="nc" id="L2574">	    correct += m_ConfusionMatrix[i][j];</span>
	  }
<span class="nc" id="L2576">	  total += m_ConfusionMatrix[i][j];</span>
	}
      }
    }
<span class="nc bnc" id="L2580" title="All 2 branches missed.">    if (total == 0) {</span>
<span class="nc" id="L2581">      return 0;</span>
    }
<span class="nc" id="L2583">    return correct / total;</span>
  }

  /**
   * Calculates the weighted (by class size) true negative rate.
   *
   * @return the weighted true negative rate.
   */
  public double weightedTrueNegativeRate() {
<span class="nc" id="L2592">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2593">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2595" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2596" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2597">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2599">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2602">    double trueNegTotal = 0;</span>
<span class="nc bnc" id="L2603" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2604">      double temp = trueNegativeRate(i);</span>
<span class="nc" id="L2605">      trueNegTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2608">    return trueNegTotal / classCountSum;</span>
  }

  /**
   * Calculate number of false positives with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * incorrectly classified negatives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the false positive rate
   */
  public double numFalsePositives(int classIndex) {

<span class="nc" id="L2623">    double incorrect = 0;</span>
<span class="nc bnc" id="L2624" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2625" title="All 2 branches missed.">      if (i != classIndex) {</span>
<span class="nc bnc" id="L2626" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2627" title="All 2 branches missed.">	  if (j == classIndex) {</span>
<span class="nc" id="L2628">	    incorrect += m_ConfusionMatrix[i][j];</span>
	  }
	}
      }
    }
<span class="nc" id="L2633">    return incorrect;</span>
  }

  /**
   * Calculate the false positive rate with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * incorrectly classified negatives
   * --------------------------------
   *        total negatives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the false positive rate
   */
  public double falsePositiveRate(int classIndex) {

<span class="nc" id="L2650">    double incorrect = 0, total = 0;</span>
<span class="nc bnc" id="L2651" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2652" title="All 2 branches missed.">      if (i != classIndex) {</span>
<span class="nc bnc" id="L2653" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2654" title="All 2 branches missed.">	  if (j == classIndex) {</span>
<span class="nc" id="L2655">	    incorrect += m_ConfusionMatrix[i][j];</span>
	  }
<span class="nc" id="L2657">	  total += m_ConfusionMatrix[i][j];</span>
	}
      }
    }
<span class="nc bnc" id="L2661" title="All 2 branches missed.">    if (total == 0) {</span>
<span class="nc" id="L2662">      return 0;</span>
    }
<span class="nc" id="L2664">    return incorrect / total;</span>
  }

  /**
   * Calculates the weighted (by class size) false positive rate.
   *
   * @return the weighted false positive rate.
   */
  public double weightedFalsePositiveRate() {
<span class="nc" id="L2673">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2674">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2676" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2677" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2678">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2680">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2683">    double falsePosTotal = 0;</span>
<span class="nc bnc" id="L2684" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2685">      double temp = falsePositiveRate(i);</span>
<span class="nc" id="L2686">      falsePosTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2689">    return falsePosTotal / classCountSum;</span>
  }



  /**
   * Calculate number of false negatives with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * incorrectly classified positives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the false positive rate
   */
  public double numFalseNegatives(int classIndex) {

<span class="nc" id="L2706">    double incorrect = 0;</span>
<span class="nc bnc" id="L2707" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2708" title="All 2 branches missed.">      if (i == classIndex) {</span>
<span class="nc bnc" id="L2709" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2710" title="All 2 branches missed.">	  if (j != classIndex) {</span>
<span class="nc" id="L2711">	    incorrect += m_ConfusionMatrix[i][j];</span>
	  }
	}
      }
    }
<span class="nc" id="L2716">    return incorrect;</span>
  }

  /**
   * Calculate the false negative rate with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * incorrectly classified positives
   * --------------------------------
   *        total positives
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the false positive rate
   */
  public double falseNegativeRate(int classIndex) {

<span class="nc" id="L2733">    double incorrect = 0, total = 0;</span>
<span class="nc bnc" id="L2734" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2735" title="All 2 branches missed.">      if (i == classIndex) {</span>
<span class="nc bnc" id="L2736" title="All 2 branches missed.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc bnc" id="L2737" title="All 2 branches missed.">	  if (j != classIndex) {</span>
<span class="nc" id="L2738">	    incorrect += m_ConfusionMatrix[i][j];</span>
	  }
<span class="nc" id="L2740">	  total += m_ConfusionMatrix[i][j];</span>
	}
      }
    }
<span class="nc bnc" id="L2744" title="All 2 branches missed.">    if (total == 0) {</span>
<span class="nc" id="L2745">      return 0;</span>
    }
<span class="nc" id="L2747">    return incorrect / total;</span>
  }

  /**
   * Calculates the weighted (by class size) false negative rate.
   *
   * @return the weighted false negative rate.
   */
  public double weightedFalseNegativeRate() {
<span class="nc" id="L2756">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2757">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2759" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2760" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2761">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2763">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2766">    double falseNegTotal = 0;</span>
<span class="nc bnc" id="L2767" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2768">      double temp = falseNegativeRate(i);</span>
<span class="nc" id="L2769">      falseNegTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2772">    return falseNegTotal / classCountSum;</span>
  }

  /**
   * Calculate the recall with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified positives
   * ------------------------------
   *       total positives
   * &lt;/pre&gt;&lt;p/&gt;
   * (Which is also the same as the truePositiveRate.)
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the recall
   */
  public double recall(int classIndex) {

<span class="nc" id="L2790">    return truePositiveRate(classIndex);</span>
  }

  /**
   * Calculates the weighted (by class size) recall.
   *
   * @return the weighted recall.
   */
  public double weightedRecall() {
<span class="nc" id="L2799">    return weightedTruePositiveRate();</span>
  }

  /**
   * Calculate the precision with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * correctly classified positives
   * ------------------------------
   *  total predicted as positive
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the precision
   */
  public double precision(int classIndex) {

<span class="nc" id="L2816">    double correct = 0, total = 0;</span>
<span class="nc bnc" id="L2817" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2818" title="All 2 branches missed.">      if (i == classIndex) {</span>
<span class="nc" id="L2819">	correct += m_ConfusionMatrix[i][classIndex];</span>
      }
<span class="nc" id="L2821">      total += m_ConfusionMatrix[i][classIndex];</span>
    }
<span class="nc bnc" id="L2823" title="All 2 branches missed.">    if (total == 0) {</span>
<span class="nc" id="L2824">      return 0;</span>
    }
<span class="nc" id="L2826">    return correct / total;</span>
  }

  /**
   * Calculates the weighted (by class size) false precision.
   *
   * @return the weighted precision.
   */
  public double weightedPrecision() {
<span class="nc" id="L2835">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2836">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2838" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2839" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2840">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2842">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2845">    double precisionTotal = 0;</span>
<span class="nc bnc" id="L2846" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2847">      double temp = precision(i);</span>
<span class="nc" id="L2848">      precisionTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2851">    return precisionTotal / classCountSum;</span>
  }

  /**
   * Calculate the F-Measure with respect to a particular class. 
   * This is defined as&lt;p/&gt;
   * &lt;pre&gt;
   * 2 * recall * precision
   * ----------------------
   *   recall + precision
   * &lt;/pre&gt;
   *
   * @param classIndex the index of the class to consider as &quot;positive&quot;
   * @return the F-Measure
   */
  public double fMeasure(int classIndex) {

<span class="nc" id="L2868">    double precision = precision(classIndex);</span>
<span class="nc" id="L2869">    double recall = recall(classIndex);</span>
<span class="nc bnc" id="L2870" title="All 2 branches missed.">    if ((precision + recall) == 0) {</span>
<span class="nc" id="L2871">      return 0;</span>
    }
<span class="nc" id="L2873">    return 2 * precision * recall / (precision + recall);</span>
  }

  /**
   * Calculates the weighted (by class size) F-Measure.
   *
   * @return the weighted F-Measure.
   */
  public double weightedFMeasure() {
<span class="nc" id="L2882">    double[] classCounts = new double[m_NumClasses];</span>
<span class="nc" id="L2883">    double classCountSum = 0;</span>
    
<span class="nc bnc" id="L2885" title="All 2 branches missed.">    for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc bnc" id="L2886" title="All 2 branches missed.">      for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="nc" id="L2887">        classCounts[i] += m_ConfusionMatrix[i][j];</span>
      }
<span class="nc" id="L2889">      classCountSum += classCounts[i];</span>
    }

<span class="nc" id="L2892">    double fMeasureTotal = 0;</span>
<span class="nc bnc" id="L2893" title="All 2 branches missed.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="nc" id="L2894">      double temp = fMeasure(i);</span>
<span class="nc" id="L2895">      fMeasureTotal += (temp * classCounts[i]);</span>
    }

<span class="nc" id="L2898">    return fMeasureTotal / classCountSum;</span>
  }

  /**
   * Sets the class prior probabilities
   *
   * @param train the training instances used to determine
   * the prior probabilities
   * @throws Exception if the class attribute of the instances is not
   * set
   */
  public void setPriors(Instances train) throws Exception {
<span class="fc" id="L2910">    m_NoPriors = false;</span>

<span class="fc bfc" id="L2912" title="All 2 branches covered.">    if (!m_ClassIsNominal) {</span>

<span class="fc" id="L2914">      m_NumTrainClassVals = 0;</span>
<span class="fc" id="L2915">      m_TrainClassVals = null;</span>
<span class="fc" id="L2916">      m_TrainClassWeights = null;</span>
<span class="fc" id="L2917">      m_PriorErrorEstimator = null;</span>
<span class="fc" id="L2918">      m_ErrorEstimator = null;</span>

<span class="fc bfc" id="L2920" title="All 2 branches covered.">      for (int i = 0; i &lt; train.numInstances(); i++) {</span>
<span class="fc" id="L2921">	Instance currentInst = train.instance(i);</span>
<span class="fc bfc" id="L2922" title="All 2 branches covered.">	if (!currentInst.classIsMissing()) {</span>
<span class="fc" id="L2923">	  addNumericTrainClass(currentInst.classValue(), </span>
<span class="fc" id="L2924">	      currentInst.weight());</span>
	}
      }

    } else {
<span class="fc bfc" id="L2929" title="All 2 branches covered.">      for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="fc" id="L2930">	m_ClassPriors[i] = 1;</span>
      }
<span class="fc" id="L2932">      m_ClassPriorsSum = m_NumClasses;</span>
<span class="fc bfc" id="L2933" title="All 2 branches covered.">      for (int i = 0; i &lt; train.numInstances(); i++) {</span>
<span class="fc bfc" id="L2934" title="All 2 branches covered.">	if (!train.instance(i).classIsMissing()) {</span>
<span class="fc" id="L2935">	  m_ClassPriors[(int)train.instance(i).classValue()] += </span>
<span class="fc" id="L2936">	    train.instance(i).weight();</span>
<span class="fc" id="L2937">	  m_ClassPriorsSum += train.instance(i).weight();</span>
	}
      }
    }
<span class="fc" id="L2941">  }</span>

  /**
   * Get the current weighted class counts
   * 
   * @return the weighted class counts
   */
  public double [] getClassPriors() {
<span class="nc" id="L2949">    return m_ClassPriors;</span>
  }

  /**
   * Updates the class prior probabilities (when incrementally 
   * training)
   *
   * @param instance the new training instance seen
   * @throws Exception if the class of the instance is not
   * set
   */
  public void updatePriors(Instance instance) throws Exception {
<span class="nc bnc" id="L2961" title="All 2 branches missed.">    if (!instance.classIsMissing()) {</span>
<span class="nc bnc" id="L2962" title="All 2 branches missed.">      if (!m_ClassIsNominal) {</span>
<span class="nc bnc" id="L2963" title="All 2 branches missed.">	if (!instance.classIsMissing()) {</span>
<span class="nc" id="L2964">	  addNumericTrainClass(instance.classValue(), </span>
<span class="nc" id="L2965">	      instance.weight());</span>
	}
      } else {
<span class="nc" id="L2968">	m_ClassPriors[(int)instance.classValue()] += </span>
<span class="nc" id="L2969">	  instance.weight();</span>
<span class="nc" id="L2970">	m_ClassPriorsSum += instance.weight();</span>
      }
    }    
<span class="nc" id="L2973">  }</span>

  /**
   * disables the use of priors, e.g., in case of de-serialized schemes
   * that have no access to the original training set, but are evaluated
   * on a set set.
   */
  public void useNoPriors() {
<span class="nc" id="L2981">    m_NoPriors = true;</span>
<span class="nc" id="L2982">  }</span>

  /**
   * Tests whether the current evaluation object is equal to another
   * evaluation object
   *
   * @param obj the object to compare against
   * @return true if the two objects are equal
   */
  public boolean equals(Object obj) {

<span class="pc bpc" id="L2993" title="2 of 4 branches missed.">    if ((obj == null) || !(obj.getClass().equals(this.getClass()))) {</span>
<span class="nc" id="L2994">      return false;</span>
    }
<span class="fc" id="L2996">    Evaluation cmp = (Evaluation) obj;</span>
<span class="pc bpc" id="L2997" title="1 of 2 branches missed.">    if (m_ClassIsNominal != cmp.m_ClassIsNominal) return false;</span>
<span class="pc bpc" id="L2998" title="1 of 2 branches missed.">    if (m_NumClasses != cmp.m_NumClasses) return false;</span>

<span class="fc bfc" id="L3000" title="All 2 branches covered.">    if (m_Incorrect != cmp.m_Incorrect) return false;</span>
<span class="pc bpc" id="L3001" title="1 of 2 branches missed.">    if (m_Correct != cmp.m_Correct) return false;</span>
<span class="pc bpc" id="L3002" title="1 of 2 branches missed.">    if (m_Unclassified != cmp.m_Unclassified) return false;</span>
<span class="pc bpc" id="L3003" title="1 of 2 branches missed.">    if (m_MissingClass != cmp.m_MissingClass) return false;</span>
<span class="pc bpc" id="L3004" title="1 of 2 branches missed.">    if (m_WithClass != cmp.m_WithClass) return false;</span>

<span class="fc bfc" id="L3006" title="All 2 branches covered.">    if (m_SumErr != cmp.m_SumErr) return false;</span>
<span class="fc bfc" id="L3007" title="All 2 branches covered.">    if (m_SumAbsErr != cmp.m_SumAbsErr) return false;</span>
<span class="pc bpc" id="L3008" title="1 of 2 branches missed.">    if (m_SumSqrErr != cmp.m_SumSqrErr) return false;</span>
<span class="pc bpc" id="L3009" title="1 of 2 branches missed.">    if (m_SumClass != cmp.m_SumClass) return false;</span>
<span class="pc bpc" id="L3010" title="1 of 2 branches missed.">    if (m_SumSqrClass != cmp.m_SumSqrClass) return false;</span>
<span class="pc bpc" id="L3011" title="1 of 2 branches missed.">    if (m_SumPredicted != cmp.m_SumPredicted) return false;</span>
<span class="pc bpc" id="L3012" title="1 of 2 branches missed.">    if (m_SumSqrPredicted != cmp.m_SumSqrPredicted) return false;</span>
<span class="pc bpc" id="L3013" title="1 of 2 branches missed.">    if (m_SumClassPredicted != cmp.m_SumClassPredicted) return false;</span>

<span class="fc bfc" id="L3015" title="All 2 branches covered.">    if (m_ClassIsNominal) {</span>
<span class="fc bfc" id="L3016" title="All 2 branches covered.">      for (int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="fc bfc" id="L3017" title="All 2 branches covered.">	for (int j = 0; j &lt; m_NumClasses; j++) {</span>
<span class="pc bpc" id="L3018" title="1 of 2 branches missed.">	  if (m_ConfusionMatrix[i][j] != cmp.m_ConfusionMatrix[i][j]) {</span>
<span class="nc" id="L3019">	    return false;</span>
	  }
	}
      }
    }

<span class="fc" id="L3025">    return true;</span>
  }

  /**
   * Prints the predictions for the given dataset into a String variable.
   * 
   * @param classifier		the classifier to use
   * @param train		the training data
   * @param testSource		the test set
   * @param classIndex		the class index (1-based), if -1 ot does not 
   * 				override the class index is stored in the data 
   * 				file (by using the last attribute)
   * @param attributesToOutput	the indices of the attributes to output
   * @return			the generated predictions for the attribute range
   * @throws Exception 		if test file cannot be opened
   */
  public static void printClassifications(Classifier classifier, 
                                            Instances train,
                                            DataSource testSource,
                                            int classIndex,
                                            Range attributesToOutput,
                                            StringBuffer predsText) throws Exception {
    
<span class="nc" id="L3048">    printClassifications(classifier, train, </span>
<span class="nc" id="L3049">                         testSource, classIndex, </span>
<span class="nc" id="L3050">                         attributesToOutput, false, predsText);</span>
<span class="nc" id="L3051">  }</span>

  /**
   * Prints the header for the predictions output into a supplied StringBuffer
   *
   * @param test structure of the test set to print predictions for
   * @param attributesToOutput indices of the attributes to output
   * @param printDistribution prints the complete distribution for nominal
   * attributes, not just the predicted value
   * @param text the StringBuffer to print to
   */
  protected static void printClassificationsHeader(Instances test, 
                                                   Range attributesToOutput, 
                                                   boolean printDistribution,
                                                   StringBuffer text) {
    // print header
<span class="nc bnc" id="L3067" title="All 2 branches missed.">    if (test.classAttribute().isNominal())</span>
<span class="nc bnc" id="L3068" title="All 2 branches missed.">      if (printDistribution)</span>
<span class="nc" id="L3069">        text.append(&quot; inst#     actual  predicted error distribution&quot;);</span>
      else
<span class="nc" id="L3071">        text.append(&quot; inst#     actual  predicted error prediction&quot;);</span>
    else
<span class="nc" id="L3073">      text.append(&quot; inst#     actual  predicted      error&quot;);</span>
<span class="nc bnc" id="L3074" title="All 2 branches missed.">    if (attributesToOutput != null) {</span>
<span class="nc" id="L3075">      attributesToOutput.setUpper(test.numAttributes() - 1);</span>
<span class="nc" id="L3076">      text.append(&quot; (&quot;);</span>
<span class="nc" id="L3077">      boolean first = true;</span>
<span class="nc bnc" id="L3078" title="All 2 branches missed.">      for (int i = 0; i &lt; test.numAttributes(); i++) {</span>
<span class="nc bnc" id="L3079" title="All 2 branches missed.">        if (i == test.classIndex())</span>
<span class="nc" id="L3080">          continue;</span>

<span class="nc bnc" id="L3082" title="All 2 branches missed.">        if (attributesToOutput.isInRange(i)) {</span>
<span class="nc bnc" id="L3083" title="All 2 branches missed.">          if (!first)</span>
<span class="nc" id="L3084">            text.append(&quot;,&quot;);</span>
<span class="nc" id="L3085">          text.append(test.attribute(i).name());</span>
<span class="nc" id="L3086">          first = false;</span>
        }
      }
<span class="nc" id="L3089">      text.append(&quot;)&quot;);</span>
    }
<span class="nc" id="L3091">    text.append(&quot;\n&quot;);</span>
<span class="nc" id="L3092">  }</span>

  /**
   * Prints the predictions for the given dataset into a supplied StringBuffer
   * 
   * @param classifier		the classifier to use
   * @param train		the training data
   * @param testSource		the test set
   * @param classIndex		the class index (1-based), if -1 ot does not 
   * 				override the class index is stored in the data 
   * 				file (by using the last attribute)
   * @param attributesToOutput	the indices of the attributes to output
   * @param printDistribution	prints the complete distribution for nominal 
   * 				classes, not just the predicted value
   * @param text                StringBuffer to hold the printed predictions
   * @throws Exception 		if test file cannot be opened
   */
  public static void printClassifications(Classifier classifier, 
                                          Instances train,
                                          DataSource testSource,
                                          int classIndex,
                                          Range attributesToOutput,
                                          boolean printDistribution,
                                          StringBuffer text) throws Exception {

<span class="nc bnc" id="L3117" title="All 2 branches missed.">    if (testSource != null) {</span>
<span class="nc" id="L3118">      Instances test = testSource.getStructure();</span>
<span class="nc bnc" id="L3119" title="All 2 branches missed.">      if (classIndex != -1) {</span>
<span class="nc" id="L3120">	test.setClassIndex(classIndex - 1);</span>
      } else {
<span class="nc bnc" id="L3122" title="All 2 branches missed.">	if (test.classIndex() == -1)</span>
<span class="nc" id="L3123">	  test.setClassIndex(test.numAttributes() - 1);</span>
      }

      // print the header
<span class="nc" id="L3127">      printClassificationsHeader(test, attributesToOutput, printDistribution, text);</span>

      // print predictions
<span class="nc" id="L3130">      int i = 0;</span>
<span class="nc" id="L3131">      testSource.reset();</span>
<span class="nc" id="L3132">      test = testSource.getStructure(test.classIndex());</span>
<span class="nc bnc" id="L3133" title="All 2 branches missed.">      while (testSource.hasMoreElements(test)) {</span>
<span class="nc" id="L3134">	Instance inst = testSource.nextElement(test);</span>
<span class="nc" id="L3135">        text.append(predictionText(classifier, inst, i, </span>
<span class="nc" id="L3136">                                   attributesToOutput, printDistribution));</span>
<span class="nc" id="L3137">	i++;</span>
      }
    }
    //    return text.toString();
<span class="nc" id="L3141">  }</span>

  /**
   * store the prediction made by the classifier as a string
   * 
   * @param classifier		the classifier to use
   * @param inst		the instance to generate text from
   * @param instNum		the index in the dataset
   * @param attributesToOutput	the indices of the attributes to output
   * @param printDistribution	prints the complete distribution for nominal 
   * 				classes, not just the predicted value
   * @return                    the prediction as a String
   * @throws Exception		if something goes wrong
   * @see			#printClassifications(Classifier, Instances, String, int, Range, boolean)
   */
  protected static String predictionText(Classifier classifier, 
                                         Instance inst, 
                                         int instNum,
                                         Range attributesToOutput,
                                         boolean printDistribution)
    
    throws Exception {

<span class="nc" id="L3164">    StringBuffer result = new StringBuffer();</span>
<span class="nc" id="L3165">    int width = 10;</span>
<span class="nc" id="L3166">    int prec = 3;</span>

<span class="nc" id="L3168">    Instance withMissing = (Instance)inst.copy();</span>
<span class="nc" id="L3169">    withMissing.setDataset(inst.dataset());</span>
<span class="nc" id="L3170">    withMissing.setMissing(withMissing.classIndex());</span>
<span class="nc" id="L3171">    double predValue = classifier.classifyInstance(withMissing);</span>

    // index
<span class="nc" id="L3174">    result.append(Utils.padLeft(&quot;&quot; + (instNum+1), 6));</span>

<span class="nc bnc" id="L3176" title="All 2 branches missed.">    if (inst.dataset().classAttribute().isNumeric()) {</span>
      // actual
<span class="nc bnc" id="L3178" title="All 2 branches missed.">      if (inst.classIsMissing())</span>
<span class="nc" id="L3179">	result.append(&quot; &quot; + Utils.padLeft(&quot;?&quot;, width));</span>
      else
<span class="nc" id="L3181">	result.append(&quot; &quot; + Utils.doubleToString(inst.classValue(), width, prec));</span>
      // predicted
<span class="nc bnc" id="L3183" title="All 2 branches missed.">      if (Instance.isMissingValue(predValue))</span>
<span class="nc" id="L3184">	result.append(&quot; &quot; + Utils.padLeft(&quot;?&quot;, width));</span>
      else
<span class="nc" id="L3186">	result.append(&quot; &quot; + Utils.doubleToString(predValue, width, prec));</span>
      // error
<span class="nc bnc" id="L3188" title="All 4 branches missed.">      if (Instance.isMissingValue(predValue) || inst.classIsMissing())</span>
<span class="nc" id="L3189">	result.append(&quot; &quot; + Utils.padLeft(&quot;?&quot;, width));</span>
      else
<span class="nc" id="L3191">	result.append(&quot; &quot; + Utils.doubleToString(predValue - inst.classValue(), width, prec));</span>
    } else {
      // actual
<span class="nc" id="L3194">      result.append(&quot; &quot; + Utils.padLeft(((int) inst.classValue()+1) + &quot;:&quot; + inst.toString(inst.classIndex()), width));</span>
      // predicted
<span class="nc bnc" id="L3196" title="All 2 branches missed.">      if (Instance.isMissingValue(predValue))</span>
<span class="nc" id="L3197">	result.append(&quot; &quot; + Utils.padLeft(&quot;?&quot;, width));</span>
      else
<span class="nc" id="L3199">	result.append(&quot; &quot; + Utils.padLeft(((int) predValue+1) + &quot;:&quot; + inst.dataset().classAttribute().value((int)predValue), width));</span>
      // error?
<span class="nc bnc" id="L3201" title="All 6 branches missed.">      if (!Instance.isMissingValue(predValue) &amp;&amp; !inst.classIsMissing() &amp;&amp; ((int) predValue+1 != (int) inst.classValue()+1))</span>
<span class="nc" id="L3202">	result.append(&quot; &quot; + &quot;  +  &quot;);</span>
      else
<span class="nc" id="L3204">	result.append(&quot; &quot; + &quot;     &quot;);</span>
      // prediction/distribution
<span class="nc bnc" id="L3206" title="All 2 branches missed.">      if (printDistribution) {</span>
<span class="nc bnc" id="L3207" title="All 2 branches missed.">	if (Instance.isMissingValue(predValue)) {</span>
<span class="nc" id="L3208">	  result.append(&quot; &quot; + &quot;?&quot;);</span>
	}
	else {
<span class="nc" id="L3211">	  result.append(&quot; &quot;);</span>
<span class="nc" id="L3212">	  double[] dist = classifier.distributionForInstance(withMissing);</span>
<span class="nc bnc" id="L3213" title="All 2 branches missed.">	  for (int n = 0; n &lt; dist.length; n++) {</span>
<span class="nc bnc" id="L3214" title="All 2 branches missed.">	    if (n &gt; 0)</span>
<span class="nc" id="L3215">	      result.append(&quot;,&quot;);</span>
<span class="nc bnc" id="L3216" title="All 2 branches missed.">	    if (n == (int) predValue)</span>
<span class="nc" id="L3217">	      result.append(&quot;*&quot;);</span>
<span class="nc" id="L3218">            result.append(Utils.doubleToString(dist[n], prec));</span>
	  }
	}
      }
      else {
<span class="nc bnc" id="L3223" title="All 2 branches missed.">	if (Instance.isMissingValue(predValue))</span>
<span class="nc" id="L3224">	  result.append(&quot; &quot; + &quot;?&quot;);</span>
	else
<span class="nc" id="L3226">	  result.append(&quot; &quot; + Utils.doubleToString(classifier.distributionForInstance(withMissing) [(int)predValue], prec));</span>
      }
    }

    // attributes
<span class="nc" id="L3231">    result.append(&quot; &quot; + attributeValuesString(withMissing, attributesToOutput) + &quot;\n&quot;);</span>

<span class="nc" id="L3233">    return result.toString();</span>
  }

  /**
   * Builds a string listing the attribute values in a specified range of indices,
   * separated by commas and enclosed in brackets.
   *
   * @param instance the instance to print the values from
   * @param attRange the range of the attributes to list
   * @return a string listing values of the attributes in the range
   */
  protected static String attributeValuesString(Instance instance, Range attRange) {
<span class="nc" id="L3245">    StringBuffer text = new StringBuffer();</span>
<span class="nc bnc" id="L3246" title="All 2 branches missed.">    if (attRange != null) {</span>
<span class="nc" id="L3247">      boolean firstOutput = true;</span>
<span class="nc" id="L3248">      attRange.setUpper(instance.numAttributes() - 1);</span>
<span class="nc bnc" id="L3249" title="All 2 branches missed.">      for (int i=0; i&lt;instance.numAttributes(); i++)</span>
<span class="nc bnc" id="L3250" title="All 4 branches missed.">	if (attRange.isInRange(i) &amp;&amp; i != instance.classIndex()) {</span>
<span class="nc bnc" id="L3251" title="All 2 branches missed.">	  if (firstOutput) text.append(&quot;(&quot;);</span>
<span class="nc" id="L3252">	  else text.append(&quot;,&quot;);</span>
<span class="nc" id="L3253">	  text.append(instance.toString(i));</span>
<span class="nc" id="L3254">	  firstOutput = false;</span>
	}
<span class="nc bnc" id="L3256" title="All 2 branches missed.">      if (!firstOutput) text.append(&quot;)&quot;);</span>
    }
<span class="nc" id="L3258">    return text.toString();</span>
  }

  /**
   * Make up the help string giving all the command line options
   *
   * @param classifier the classifier to include options for
   * @param globalInfo include the global information string
   * for the classifier (if available).
   * @return a string detailing the valid command line options
   */
  protected static String makeOptionString(Classifier classifier, 
                                           boolean globalInfo) {

<span class="nc" id="L3272">    StringBuffer optionsText = new StringBuffer(&quot;&quot;);</span>

    // General options
<span class="nc" id="L3275">    optionsText.append(&quot;\n\nGeneral options:\n\n&quot;);</span>
<span class="nc" id="L3276">    optionsText.append(&quot;-h or -help\n&quot;);</span>
<span class="nc" id="L3277">    optionsText.append(&quot;\tOutput help information.\n&quot;);</span>
<span class="nc" id="L3278">    optionsText.append(&quot;-synopsis or -info\n&quot;);</span>
<span class="nc" id="L3279">    optionsText.append(&quot;\tOutput synopsis for classifier (use in conjunction &quot;</span>
        + &quot; with -h)\n&quot;);
<span class="nc" id="L3281">    optionsText.append(&quot;-t &lt;name of training file&gt;\n&quot;);</span>
<span class="nc" id="L3282">    optionsText.append(&quot;\tSets training file.\n&quot;);</span>
<span class="nc" id="L3283">    optionsText.append(&quot;-T &lt;name of test file&gt;\n&quot;);</span>
<span class="nc" id="L3284">    optionsText.append(&quot;\tSets test file. If missing, a cross-validation will be performed\n&quot;);</span>
<span class="nc" id="L3285">    optionsText.append(&quot;\ton the training data.\n&quot;);</span>
<span class="nc" id="L3286">    optionsText.append(&quot;-c &lt;class index&gt;\n&quot;);</span>
<span class="nc" id="L3287">    optionsText.append(&quot;\tSets index of class attribute (default: last).\n&quot;);</span>
<span class="nc" id="L3288">    optionsText.append(&quot;-x &lt;number of folds&gt;\n&quot;);</span>
<span class="nc" id="L3289">    optionsText.append(&quot;\tSets number of folds for cross-validation (default: 10).\n&quot;);</span>
<span class="nc" id="L3290">    optionsText.append(&quot;-no-cv\n&quot;);</span>
<span class="nc" id="L3291">    optionsText.append(&quot;\tDo not perform any cross validation.\n&quot;);</span>
<span class="nc" id="L3292">    optionsText.append(&quot;-split-percentage &lt;percentage&gt;\n&quot;);</span>
<span class="nc" id="L3293">    optionsText.append(&quot;\tSets the percentage for the train/test set split, e.g., 66.\n&quot;);</span>
<span class="nc" id="L3294">    optionsText.append(&quot;-preserve-order\n&quot;);</span>
<span class="nc" id="L3295">    optionsText.append(&quot;\tPreserves the order in the percentage split.\n&quot;);</span>
<span class="nc" id="L3296">    optionsText.append(&quot;-s &lt;random number seed&gt;\n&quot;);</span>
<span class="nc" id="L3297">    optionsText.append(&quot;\tSets random number seed for cross-validation or percentage split\n&quot;);</span>
<span class="nc" id="L3298">    optionsText.append(&quot;\t(default: 1).\n&quot;);</span>
<span class="nc" id="L3299">    optionsText.append(&quot;-m &lt;name of file with cost matrix&gt;\n&quot;);</span>
<span class="nc" id="L3300">    optionsText.append(&quot;\tSets file with cost matrix.\n&quot;);</span>
<span class="nc" id="L3301">    optionsText.append(&quot;-l &lt;name of input file&gt;\n&quot;);</span>
<span class="nc" id="L3302">    optionsText.append(&quot;\tSets model input file. In case the filename ends with '.xml',\n&quot;);</span>
<span class="nc" id="L3303">    optionsText.append(&quot;\ta PMML file is loaded or, if that fails, options are loaded\n&quot;);</span>
<span class="nc" id="L3304">    optionsText.append(&quot;\tfrom the XML file.\n&quot;);</span>
<span class="nc" id="L3305">    optionsText.append(&quot;-d &lt;name of output file&gt;\n&quot;);</span>
<span class="nc" id="L3306">    optionsText.append(&quot;\tSets model output file. In case the filename ends with '.xml',\n&quot;);</span>
<span class="nc" id="L3307">    optionsText.append(&quot;\tonly the options are saved to the XML file, not the model.\n&quot;);</span>
<span class="nc" id="L3308">    optionsText.append(&quot;-v\n&quot;);</span>
<span class="nc" id="L3309">    optionsText.append(&quot;\tOutputs no statistics for training data.\n&quot;);</span>
<span class="nc" id="L3310">    optionsText.append(&quot;-o\n&quot;);</span>
<span class="nc" id="L3311">    optionsText.append(&quot;\tOutputs statistics only, not the classifier.\n&quot;);</span>
<span class="nc" id="L3312">    optionsText.append(&quot;-i\n&quot;);</span>
<span class="nc" id="L3313">    optionsText.append(&quot;\tOutputs detailed information-retrieval&quot;);</span>
<span class="nc" id="L3314">    optionsText.append(&quot; statistics for each class.\n&quot;);</span>
<span class="nc" id="L3315">    optionsText.append(&quot;-k\n&quot;);</span>
<span class="nc" id="L3316">    optionsText.append(&quot;\tOutputs information-theoretic statistics.\n&quot;);</span>
<span class="nc" id="L3317">    optionsText.append(&quot;-p &lt;attribute range&gt;\n&quot;);</span>
<span class="nc" id="L3318">    optionsText.append(&quot;\tOnly outputs predictions for test instances (or the train\n&quot;</span>
	+ &quot;\tinstances if no test instances provided and -no-cv is used),\n&quot;
	+ &quot;\talong with attributes (0 for none).\n&quot;);
<span class="nc" id="L3321">    optionsText.append(&quot;-distribution\n&quot;);</span>
<span class="nc" id="L3322">    optionsText.append(&quot;\tOutputs the distribution instead of only the prediction\n&quot;);</span>
<span class="nc" id="L3323">    optionsText.append(&quot;\tin conjunction with the '-p' option (only nominal classes).\n&quot;);</span>
<span class="nc" id="L3324">    optionsText.append(&quot;-r\n&quot;);</span>
<span class="nc" id="L3325">    optionsText.append(&quot;\tOnly outputs cumulative margin distribution.\n&quot;);</span>
<span class="nc bnc" id="L3326" title="All 2 branches missed.">    if (classifier instanceof Sourcable) {</span>
<span class="nc" id="L3327">      optionsText.append(&quot;-z &lt;class name&gt;\n&quot;);</span>
<span class="nc" id="L3328">      optionsText.append(&quot;\tOnly outputs the source representation&quot;</span>
	  + &quot; of the classifier,\n\tgiving it the supplied&quot;
	  + &quot; name.\n&quot;);
    }
<span class="nc bnc" id="L3332" title="All 2 branches missed.">    if (classifier instanceof Drawable) {</span>
<span class="nc" id="L3333">      optionsText.append(&quot;-g\n&quot;);</span>
<span class="nc" id="L3334">      optionsText.append(&quot;\tOnly outputs the graph representation&quot;</span>
	  + &quot; of the classifier.\n&quot;);
    }
<span class="nc" id="L3337">    optionsText.append(&quot;-xml filename | xml-string\n&quot;);</span>
<span class="nc" id="L3338">    optionsText.append(&quot;\tRetrieves the options from the XML-data instead of the &quot; </span>
	+ &quot;command line.\n&quot;);
<span class="nc" id="L3340">    optionsText.append(&quot;-threshold-file &lt;file&gt;\n&quot;);</span>
<span class="nc" id="L3341">    optionsText.append(&quot;\tThe file to save the threshold data to.\n&quot;</span>
	+ &quot;\tThe format is determined by the extensions, e.g., '.arff' for ARFF \n&quot;
	+ &quot;\tformat or '.csv' for CSV.\n&quot;);
<span class="nc" id="L3344">    optionsText.append(&quot;-threshold-label &lt;label&gt;\n&quot;);</span>
<span class="nc" id="L3345">    optionsText.append(&quot;\tThe class label to determine the threshold data for\n&quot;</span>
	+ &quot;\t(default is the first label)\n&quot;);

    // Get scheme-specific options
<span class="nc bnc" id="L3349" title="All 2 branches missed.">    if (classifier instanceof OptionHandler) {</span>
<span class="nc" id="L3350">      optionsText.append(&quot;\nOptions specific to &quot;</span>
<span class="nc" id="L3351">	  + classifier.getClass().getName()</span>
<span class="nc" id="L3352">	  + &quot;:\n\n&quot;);</span>
<span class="nc" id="L3353">      Enumeration enu = ((OptionHandler)classifier).listOptions();</span>
<span class="nc bnc" id="L3354" title="All 2 branches missed.">      while (enu.hasMoreElements()) {</span>
<span class="nc" id="L3355">	Option option = (Option) enu.nextElement();</span>
<span class="nc" id="L3356">	optionsText.append(option.synopsis() + '\n');</span>
<span class="nc" id="L3357">	optionsText.append(option.description() + &quot;\n&quot;);</span>
      }
    }
    
    // Get global information (if available)
<span class="nc bnc" id="L3362" title="All 2 branches missed.">    if (globalInfo) {</span>
      try {
<span class="nc" id="L3364">        String gi = getGlobalInfo(classifier);</span>
<span class="nc" id="L3365">        optionsText.append(gi);</span>
<span class="nc" id="L3366">      } catch (Exception ex) {</span>
        // quietly ignore
      }
    }
<span class="nc" id="L3370">    return optionsText.toString();</span>
  }
  
  /**
   * Return the global info (if it exists) for the supplied classifier
   * 
   * @param classifier the classifier to get the global info for
   * @return the global info (synopsis) for the classifier
   * @throws Exception if there is a problem reflecting on the classifier
   */
  protected static String getGlobalInfo(Classifier classifier) throws Exception {
<span class="nc" id="L3381">    BeanInfo bi = Introspector.getBeanInfo(classifier.getClass());</span>
    MethodDescriptor[] methods;
<span class="nc" id="L3383">    methods = bi.getMethodDescriptors();</span>
<span class="nc" id="L3384">    Object[] args = {};</span>
<span class="nc" id="L3385">    String result = &quot;\nSynopsis for &quot; + classifier.getClass().getName()</span>
<span class="nc" id="L3386">      + &quot;:\n\n&quot;;</span>
    
<span class="nc bnc" id="L3388" title="All 2 branches missed.">    for (int i = 0; i &lt; methods.length; i++) {</span>
<span class="nc" id="L3389">      String name = methods[i].getDisplayName();</span>
<span class="nc" id="L3390">      Method meth = methods[i].getMethod();</span>
<span class="nc bnc" id="L3391" title="All 2 branches missed.">      if (name.equals(&quot;globalInfo&quot;)) {</span>
<span class="nc" id="L3392">        String globalInfo = (String)(meth.invoke(classifier, args));</span>
<span class="nc" id="L3393">        result += globalInfo;</span>
<span class="nc" id="L3394">        break;</span>
      }
    }
    
<span class="nc" id="L3398">    return result;</span>
  }

  /**
   * Method for generating indices for the confusion matrix.
   *
   * @param num 	integer to format
   * @param IDChars	the characters to use
   * @param IDWidth	the width of the entry
   * @return 		the formatted integer as a string
   */
  protected String num2ShortID(int num, char[] IDChars, int IDWidth) {

<span class="nc" id="L3411">    char ID [] = new char [IDWidth];</span>
    int i;

<span class="nc bnc" id="L3414" title="All 2 branches missed.">    for(i = IDWidth - 1; i &gt;=0; i--) {</span>
<span class="nc" id="L3415">      ID[i] = IDChars[num % IDChars.length];</span>
<span class="nc" id="L3416">      num = num / IDChars.length - 1;</span>
<span class="nc bnc" id="L3417" title="All 2 branches missed.">      if (num &lt; 0) {</span>
<span class="nc" id="L3418">	break;</span>
      }
    }
<span class="nc bnc" id="L3421" title="All 2 branches missed.">    for(i--; i &gt;= 0; i--) {</span>
<span class="nc" id="L3422">      ID[i] = ' ';</span>
    }

<span class="nc" id="L3425">    return new String(ID);</span>
  }

  /**
   * Convert a single prediction into a probability distribution
   * with all zero probabilities except the predicted value which
   * has probability 1.0;
   *
   * @param predictedClass the index of the predicted class
   * @return the probability distribution
   */
  protected double [] makeDistribution(double predictedClass) {

<span class="fc" id="L3438">    double [] result = new double [m_NumClasses];</span>
<span class="pc bpc" id="L3439" title="1 of 2 branches missed.">    if (Instance.isMissingValue(predictedClass)) {</span>
<span class="nc" id="L3440">      return result;</span>
    }
<span class="fc bfc" id="L3442" title="All 2 branches covered.">    if (m_ClassIsNominal) {</span>
<span class="fc" id="L3443">      result[(int)predictedClass] = 1.0;</span>
    } else {
<span class="fc" id="L3445">      result[0] = predictedClass;</span>
    }
<span class="fc" id="L3447">    return result;</span>
  } 

  /**
   * Updates all the statistics about a classifiers performance for 
   * the current test instance.
   *
   * @param predictedDistribution the probabilities assigned to 
   * each class
   * @param instance the instance to be classified
   * @throws Exception if the class of the instance is not
   * set
   */
  protected void updateStatsForClassifier(double [] predictedDistribution,
      Instance instance)
  throws Exception {

<span class="fc" id="L3464">    int actualClass = (int)instance.classValue();</span>

<span class="fc bfc" id="L3466" title="All 2 branches covered.">    if (!instance.classIsMissing()) {</span>
<span class="fc" id="L3467">      updateMargins(predictedDistribution, actualClass, instance.weight());</span>

      // Determine the predicted class (doesn't detect multiple 
      // classifications)
<span class="fc" id="L3471">      int predictedClass = -1;</span>
<span class="fc" id="L3472">      double bestProb = 0.0;</span>
<span class="fc bfc" id="L3473" title="All 2 branches covered.">      for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="fc bfc" id="L3474" title="All 2 branches covered.">	if (predictedDistribution[i] &gt; bestProb) {</span>
<span class="fc" id="L3475">	  predictedClass = i;</span>
<span class="fc" id="L3476">	  bestProb = predictedDistribution[i];</span>
	}
      }

<span class="fc" id="L3480">      m_WithClass += instance.weight();</span>

      // Determine misclassification cost
<span class="pc bpc" id="L3483" title="1 of 2 branches missed.">      if (m_CostMatrix != null) {</span>
<span class="nc bnc" id="L3484" title="All 2 branches missed.">	if (predictedClass &lt; 0) {</span>
	  // For missing predictions, we assume the worst possible cost.
	  // This is pretty harsh.
	  // Perhaps we could take the negative of the cost of a correct
	  // prediction (-m_CostMatrix.getElement(actualClass,actualClass)),
	  // although often this will be zero
<span class="nc" id="L3490">	  m_TotalCost += instance.weight()</span>
<span class="nc" id="L3491">	  * m_CostMatrix.getMaxCost(actualClass, instance);</span>
	} else {
<span class="nc" id="L3493">	  m_TotalCost += instance.weight() </span>
<span class="nc" id="L3494">	  * m_CostMatrix.getElement(actualClass, predictedClass,</span>
<span class="nc" id="L3495">	      instance);</span>
	}
      }

      // Update counts when no class was predicted
<span class="fc bfc" id="L3500" title="All 2 branches covered.">      if (predictedClass &lt; 0) {</span>
<span class="fc" id="L3501">	m_Unclassified += instance.weight();</span>
<span class="fc" id="L3502">	return;</span>
      }

<span class="fc" id="L3505">      double predictedProb = Math.max(MIN_SF_PROB,</span>
<span class="fc" id="L3506">	  predictedDistribution[actualClass]);</span>
<span class="fc" id="L3507">      double priorProb = Math.max(MIN_SF_PROB,</span>
<span class="fc" id="L3508">	  m_ClassPriors[actualClass]</span>
<span class="fc" id="L3509">	                / m_ClassPriorsSum);</span>
<span class="fc bfc" id="L3510" title="All 2 branches covered.">      if (predictedProb &gt;= priorProb) {</span>
<span class="fc" id="L3511">	m_SumKBInfo += (Utils.log2(predictedProb) - </span>
<span class="fc" id="L3512">	    Utils.log2(priorProb))</span>
<span class="fc" id="L3513">	    * instance.weight();</span>
      } else {
<span class="fc" id="L3515">	m_SumKBInfo -= (Utils.log2(1.0-predictedProb) - </span>
<span class="fc" id="L3516">	    Utils.log2(1.0-priorProb))</span>
<span class="fc" id="L3517">	    * instance.weight();</span>
      }

<span class="fc" id="L3520">      m_SumSchemeEntropy -= Utils.log2(predictedProb) * instance.weight();</span>
<span class="fc" id="L3521">      m_SumPriorEntropy -= Utils.log2(priorProb) * instance.weight();</span>

<span class="fc" id="L3523">      updateNumericScores(predictedDistribution, </span>
<span class="fc" id="L3524">	  makeDistribution(instance.classValue()), </span>
<span class="fc" id="L3525">	  instance.weight());</span>

      // Update other stats
<span class="fc" id="L3528">      m_ConfusionMatrix[actualClass][predictedClass] += instance.weight();</span>
<span class="fc bfc" id="L3529" title="All 2 branches covered.">      if (predictedClass != actualClass) {</span>
<span class="fc" id="L3530">	m_Incorrect += instance.weight();</span>
      } else {
<span class="fc" id="L3532">	m_Correct += instance.weight();</span>
      }
    } else {
<span class="fc" id="L3535">      m_MissingClass += instance.weight();</span>
    }
<span class="fc" id="L3537">  }</span>

  /**
   * Updates all the statistics about a predictors performance for 
   * the current test instance.
   *
   * @param predictedValue the numeric value the classifier predicts
   * @param instance the instance to be classified
   * @throws Exception if the class of the instance is not
   * set
   */
  protected void updateStatsForPredictor(double predictedValue,
      Instance instance) 
  throws Exception {

<span class="fc bfc" id="L3552" title="All 2 branches covered.">    if (!instance.classIsMissing()){</span>

      // Update stats
<span class="fc" id="L3555">      m_WithClass += instance.weight();</span>
<span class="fc bfc" id="L3556" title="All 2 branches covered.">      if (Instance.isMissingValue(predictedValue)) {</span>
<span class="fc" id="L3557">	m_Unclassified += instance.weight();</span>
<span class="fc" id="L3558">	return;</span>
      }
<span class="fc" id="L3560">      m_SumClass += instance.weight() * instance.classValue();</span>
<span class="fc" id="L3561">      m_SumSqrClass += instance.weight() * instance.classValue()</span>
<span class="fc" id="L3562">      *	instance.classValue();</span>
<span class="fc" id="L3563">      m_SumClassPredicted += instance.weight() </span>
<span class="fc" id="L3564">      * instance.classValue() * predictedValue;</span>
<span class="fc" id="L3565">      m_SumPredicted += instance.weight() * predictedValue;</span>
<span class="fc" id="L3566">      m_SumSqrPredicted += instance.weight() * predictedValue * predictedValue;</span>

<span class="fc bfc" id="L3568" title="All 2 branches covered.">      if (m_ErrorEstimator == null) {</span>
<span class="fc" id="L3569">	setNumericPriorsFromBuffer();</span>
      }
<span class="fc" id="L3571">      double predictedProb = Math.max(m_ErrorEstimator.getProbability(</span>
<span class="fc" id="L3572">	  predictedValue </span>
<span class="fc" id="L3573">	  - instance.classValue()),</span>
<span class="fc" id="L3574">	  MIN_SF_PROB);</span>
<span class="fc" id="L3575">      double priorProb = Math.max(m_PriorErrorEstimator.getProbability(</span>
<span class="fc" id="L3576">	  instance.classValue()),</span>
<span class="fc" id="L3577">	  MIN_SF_PROB);</span>

<span class="fc" id="L3579">      m_SumSchemeEntropy -= Utils.log2(predictedProb) * instance.weight();</span>
<span class="fc" id="L3580">      m_SumPriorEntropy -= Utils.log2(priorProb) * instance.weight();</span>
<span class="fc" id="L3581">      m_ErrorEstimator.addValue(predictedValue - instance.classValue(), </span>
<span class="fc" id="L3582">	  instance.weight());</span>

<span class="fc" id="L3584">      updateNumericScores(makeDistribution(predictedValue),</span>
<span class="fc" id="L3585">	  makeDistribution(instance.classValue()),</span>
<span class="fc" id="L3586">	  instance.weight());</span>

    } else
<span class="fc" id="L3589">      m_MissingClass += instance.weight();</span>
<span class="fc" id="L3590">  }</span>

  /**
   * Update the cumulative record of classification margins
   *
   * @param predictedDistribution the probability distribution predicted for
   * the current instance
   * @param actualClass the index of the actual instance class
   * @param weight the weight assigned to the instance
   */
  protected void updateMargins(double [] predictedDistribution, 
      int actualClass, double weight) {

<span class="fc" id="L3603">    double probActual = predictedDistribution[actualClass];</span>
<span class="fc" id="L3604">    double probNext = 0;</span>

<span class="fc bfc" id="L3606" title="All 2 branches covered.">    for(int i = 0; i &lt; m_NumClasses; i++)</span>
<span class="fc bfc" id="L3607" title="All 2 branches covered.">      if ((i != actualClass) &amp;&amp;</span>
<span class="fc bfc" id="L3608" title="All 2 branches covered.">	  (predictedDistribution[i] &gt; probNext))</span>
<span class="fc" id="L3609">	probNext = predictedDistribution[i];</span>

<span class="fc" id="L3611">    double margin = probActual - probNext;</span>
<span class="fc" id="L3612">    int bin = (int)((margin + 1.0) / 2.0 * k_MarginResolution);</span>
<span class="fc" id="L3613">    m_MarginCounts[bin] += weight;</span>
<span class="fc" id="L3614">  }</span>

  /**
   * Update the numeric accuracy measures. For numeric classes, the
   * accuracy is between the actual and predicted class values. For 
   * nominal classes, the accuracy is between the actual and 
   * predicted class probabilities.
   *
   * @param predicted the predicted values
   * @param actual the actual value
   * @param weight the weight associated with this prediction
   */
  protected void updateNumericScores(double [] predicted, 
      double [] actual, double weight) {

    double diff;
<span class="fc" id="L3630">    double sumErr = 0, sumAbsErr = 0, sumSqrErr = 0;</span>
<span class="fc" id="L3631">    double sumPriorAbsErr = 0, sumPriorSqrErr = 0;</span>
<span class="fc bfc" id="L3632" title="All 2 branches covered.">    for(int i = 0; i &lt; m_NumClasses; i++) {</span>
<span class="fc" id="L3633">      diff = predicted[i] - actual[i];</span>
<span class="fc" id="L3634">      sumErr += diff;</span>
<span class="fc" id="L3635">      sumAbsErr += Math.abs(diff);</span>
<span class="fc" id="L3636">      sumSqrErr += diff * diff;</span>
<span class="fc" id="L3637">      diff = (m_ClassPriors[i] / m_ClassPriorsSum) - actual[i];</span>
<span class="fc" id="L3638">      sumPriorAbsErr += Math.abs(diff);</span>
<span class="fc" id="L3639">      sumPriorSqrErr += diff * diff;</span>
    }
<span class="fc" id="L3641">    m_SumErr += weight * sumErr / m_NumClasses;</span>
<span class="fc" id="L3642">    m_SumAbsErr += weight * sumAbsErr / m_NumClasses;</span>
<span class="fc" id="L3643">    m_SumSqrErr += weight * sumSqrErr / m_NumClasses;</span>
<span class="fc" id="L3644">    m_SumPriorAbsErr += weight * sumPriorAbsErr / m_NumClasses;</span>
<span class="fc" id="L3645">    m_SumPriorSqrErr += weight * sumPriorSqrErr / m_NumClasses;</span>
<span class="fc" id="L3646">  }</span>

  /**
   * Adds a numeric (non-missing) training class value and weight to 
   * the buffer of stored values.
   *
   * @param classValue the class value
   * @param weight the instance weight
   */
  protected void addNumericTrainClass(double classValue, double weight) {

<span class="fc bfc" id="L3657" title="All 2 branches covered.">    if (m_TrainClassVals == null) {</span>
<span class="fc" id="L3658">      m_TrainClassVals = new double [100];</span>
<span class="fc" id="L3659">      m_TrainClassWeights = new double [100];</span>
    }
<span class="fc bfc" id="L3661" title="All 2 branches covered.">    if (m_NumTrainClassVals == m_TrainClassVals.length) {</span>
<span class="fc" id="L3662">      double [] temp = new double [m_TrainClassVals.length * 2];</span>
<span class="fc" id="L3663">      System.arraycopy(m_TrainClassVals, 0, </span>
<span class="fc" id="L3664">	  temp, 0, m_TrainClassVals.length);</span>
<span class="fc" id="L3665">      m_TrainClassVals = temp;</span>

<span class="fc" id="L3667">      temp = new double [m_TrainClassWeights.length * 2];</span>
<span class="fc" id="L3668">      System.arraycopy(m_TrainClassWeights, 0, </span>
<span class="fc" id="L3669">	  temp, 0, m_TrainClassWeights.length);</span>
<span class="fc" id="L3670">      m_TrainClassWeights = temp;</span>
    }
<span class="fc" id="L3672">    m_TrainClassVals[m_NumTrainClassVals] = classValue;</span>
<span class="fc" id="L3673">    m_TrainClassWeights[m_NumTrainClassVals] = weight;</span>
<span class="fc" id="L3674">    m_NumTrainClassVals++;</span>
<span class="fc" id="L3675">  }</span>

  /**
   * Sets up the priors for numeric class attributes from the 
   * training class values that have been seen so far.
   */
  protected void setNumericPriorsFromBuffer() {

<span class="fc" id="L3683">    double numPrecision = 0.01; // Default value</span>
<span class="fc bfc" id="L3684" title="All 2 branches covered.">    if (m_NumTrainClassVals &gt; 1) {</span>
<span class="fc" id="L3685">      double [] temp = new double [m_NumTrainClassVals];</span>
<span class="fc" id="L3686">      System.arraycopy(m_TrainClassVals, 0, temp, 0, m_NumTrainClassVals);</span>
<span class="fc" id="L3687">      int [] index = Utils.sort(temp);</span>
<span class="fc" id="L3688">      double lastVal = temp[index[0]];</span>
<span class="fc" id="L3689">      double deltaSum = 0;</span>
<span class="fc" id="L3690">      int distinct = 0;</span>
<span class="fc bfc" id="L3691" title="All 2 branches covered.">      for (int i = 1; i &lt; temp.length; i++) {</span>
<span class="fc" id="L3692">	double current = temp[index[i]];</span>
<span class="fc bfc" id="L3693" title="All 2 branches covered.">	if (current != lastVal) {</span>
<span class="fc" id="L3694">	  deltaSum += current - lastVal;</span>
<span class="fc" id="L3695">	  lastVal = current;</span>
<span class="fc" id="L3696">	  distinct++;</span>
	}
      }
<span class="fc bfc" id="L3699" title="All 2 branches covered.">      if (distinct &gt; 0) {</span>
<span class="fc" id="L3700">	numPrecision = deltaSum / distinct;</span>
      }
    }
<span class="fc" id="L3703">    m_PriorErrorEstimator = new KernelEstimator(numPrecision);</span>
<span class="fc" id="L3704">    m_ErrorEstimator = new KernelEstimator(numPrecision);</span>
<span class="fc" id="L3705">    m_ClassPriors[0] = m_ClassPriorsSum = 0;</span>
<span class="fc bfc" id="L3706" title="All 2 branches covered.">    for (int i = 0; i &lt; m_NumTrainClassVals; i++) {</span>
<span class="fc" id="L3707">      m_ClassPriors[0] += m_TrainClassVals[i] * m_TrainClassWeights[i];</span>
<span class="fc" id="L3708">      m_ClassPriorsSum += m_TrainClassWeights[i];</span>
<span class="fc" id="L3709">      m_PriorErrorEstimator.addValue(m_TrainClassVals[i],</span>
<span class="fc" id="L3710">	  m_TrainClassWeights[i]);</span>
    }
<span class="fc" id="L3712">  }</span>
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L3720">    return RevisionUtils.extract(&quot;$Revision: 9196 $&quot;);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>