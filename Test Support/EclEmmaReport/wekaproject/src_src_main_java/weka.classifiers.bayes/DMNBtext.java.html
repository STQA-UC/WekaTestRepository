<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>DMNBtext.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.bayes</a> &gt; <span class="el_source">DMNBtext.java</span></div><h1>DMNBtext.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    Discriminative Multinomial Naive Bayes for Text Classification
 *    Copyright (C) 2008 Jiang Su
 */

package weka.classifiers.bayes;


import weka.classifiers.Classifier;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.WeightedInstancesHandler;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;
import weka.classifiers.UpdateableClassifier;
import java.util.*;
import java.io.Serializable;
import weka.core.Capabilities;
import weka.core.OptionHandler;


/**
 &lt;!-- globalinfo-start --&gt;
 * Class for building and using a Discriminative Multinomial Naive Bayes classifier. For more information see,&lt;br/&gt;
 * &lt;br/&gt;
 * Jiang Su,Harry Zhang,Charles X. Ling,Stan Matwin: Discriminative Parameter Learning for Bayesian Networks. In: ICML 2008', 2008.&lt;br/&gt;
 * &lt;br/&gt;
 * The core equation for this classifier:&lt;br/&gt;
 * &lt;br/&gt;
 * P[Ci|D] = (P[D|Ci] x P[Ci]) / P[D] (Bayes rule)&lt;br/&gt;
 * &lt;br/&gt;
 * where Ci is class i and D is a document.
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;inproceedings{JiangSu2008,
 *    author = {Jiang Su,Harry Zhang,Charles X. Ling,Stan Matwin},
 *    booktitle = {ICML 2008'},
 *    title = {Discriminative Parameter Learning for Bayesian Networks},
 *    year = {2008}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -I &amp;lt;iterations&amp;gt;
 *  The number of iterations that the classifier 
 *  will scan the training data (default = 1)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -M
 *  Use the frequency information in data&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 * 
 * @author Jiang Su (Jiang.Su@unb.ca) 2008
 * @version $Revision: 6363 $
 */
<span class="fc" id="L85">public class DMNBtext extends Classifier</span>
    implements OptionHandler, WeightedInstancesHandler, 
               TechnicalInformationHandler, UpdateableClassifier {

  /** for serialization */
  static final long serialVersionUID = 5932177450183457085L;
  /** The number of iterations. */
<span class="fc" id="L92">  protected int m_NumIterations = 1;</span>
<span class="fc" id="L93">  protected boolean m_MultinomialWord = false;</span>
<span class="fc" id="L94">  int m_numClasses=-1;</span>
  protected Instances m_headerInfo;
<span class="fc" id="L96">  DNBBinary[] m_binaryClassifiers = null;</span>

  /**
   * Returns a string describing this classifier
   * @return a description of the classifier suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L104">    return</span>
<span class="nc" id="L105">      &quot;Class for building and using a Discriminative Multinomial Naive Bayes classifier. &quot;</span>
      + &quot;For more information see,\n\n&quot;
<span class="nc" id="L107">      + getTechnicalInformation().toString() + &quot;\n\n&quot;</span>
<span class="nc" id="L108">      + &quot;The core equation for this classifier:\n\n&quot;</span>
<span class="nc" id="L109">      + &quot;P[Ci|D] = (P[D|Ci] x P[Ci]) / P[D] (Bayes rule)\n\n&quot;</span>
<span class="nc" id="L110">      + &quot;where Ci is class i and D is a document.&quot;;</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   *
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;

<span class="nc" id="L123">    result = new TechnicalInformation(Type.INPROCEEDINGS);</span>
<span class="nc" id="L124">    result.setValue(Field.AUTHOR, &quot;Jiang Su,Harry Zhang,Charles X. Ling,Stan Matwin&quot;);</span>
<span class="nc" id="L125">    result.setValue(Field.YEAR, &quot;2008&quot;);</span>
<span class="nc" id="L126">    result.setValue(Field.TITLE, &quot;Discriminative Parameter Learning for Bayesian Networks&quot;);</span>
<span class="nc" id="L127">    result.setValue(Field.BOOKTITLE, &quot;ICML 2008'&quot;);</span>

<span class="nc" id="L129">    return result;</span>
  }

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L138">    Capabilities result = super.getCapabilities();</span>
<span class="fc" id="L139">    result.disableAll();</span>

    // attributes
<span class="fc" id="L142">    result.enable(Capability.NUMERIC_ATTRIBUTES);</span>

    // class
<span class="fc" id="L145">    result.enable(Capability.NOMINAL_CLASS);</span>
<span class="fc" id="L146">    result.enable(Capability.MISSING_CLASS_VALUES);</span>
    
    // instances
<span class="fc" id="L149">    result.setMinimumNumberInstances(0);</span>

<span class="fc" id="L151">    return result;</span>
  }

  /**
   * Generates the classifier.
   *
   * @param instances set of instances serving as training data
   * @exception Exception if the classifier has not been generated successfully
   */
  public void buildClassifier(Instances data) throws Exception {
    // can classifier handle the data?
<span class="fc" id="L162">    getCapabilities().testWithFail(data);</span>
    // remove instances with missing class
<span class="fc" id="L164">    Instances instances =  new Instances(data);</span>
<span class="fc" id="L165">    instances.deleteWithMissingClass();</span>

<span class="fc" id="L167">    m_binaryClassifiers = new DNBBinary[instances.numClasses()];</span>
<span class="fc" id="L168">    m_numClasses=instances.numClasses();</span>
<span class="fc" id="L169">    m_headerInfo = new Instances(instances, 0);</span>
<span class="fc bfc" id="L170" title="All 2 branches covered.">    for (int i = 0; i &lt; instances.numClasses(); i++) {</span>
<span class="fc" id="L171">      m_binaryClassifiers[i] = new DNBBinary();</span>
<span class="fc" id="L172">      m_binaryClassifiers[i].setTargetClass(i);</span>
<span class="fc" id="L173">      m_binaryClassifiers[i].initClassifier(instances);</span>
    }

<span class="fc bfc" id="L176" title="All 2 branches covered.">    if (instances.numInstances() == 0)</span>
<span class="fc" id="L177">      return;</span>
    //Iterative update
<span class="fc" id="L179">    Random random = new Random();</span>
<span class="fc bfc" id="L180" title="All 2 branches covered.">    for (int it = 0; it &lt; m_NumIterations; it++) {</span>
<span class="fc bfc" id="L181" title="All 2 branches covered.">      for (int i = 0; i &lt; instances.numInstances(); i++) {</span>
<span class="fc" id="L182">        updateClassifier(instances.instance(i));</span>
      }
    }

    //  Utils.normalize(m_oldClassDis);
    // Utils.normalize(m_ClassDis);
    // m_originalPositive = m_oldClassDis[0];
    //   m_positive = m_ClassDis[0];

<span class="fc" id="L191">  }</span>

  /**
   * Updates the classifier with the given instance.
   *
   * @param instance the new training instance to include in the model
   * @exception Exception if the instance could not be incorporated in
   * the model.
   */

  public void updateClassifier(Instance instance) throws Exception {

<span class="fc bfc" id="L203" title="All 2 branches covered.">    if (m_numClasses == 2) {</span>
<span class="fc" id="L204">      m_binaryClassifiers[0].updateClassifier(instance);</span>
    } else {
<span class="fc bfc" id="L206" title="All 2 branches covered.">      for (int i = 0; i &lt; instance.numClasses(); i++)</span>
<span class="fc" id="L207">        m_binaryClassifiers[i].updateClassifier(instance);</span>
    }
<span class="fc" id="L209">  }</span>

  /**
   * Calculates the class membership probabilities for the given test
   * instance.
   *
   * @param instance the instance to be classified
   * @return predicted class probability distribution
   * @exception Exception if there is a problem generating the prediction
   */
  public double[] distributionForInstance(Instance instance) throws Exception {
<span class="fc bfc" id="L220" title="All 2 branches covered.">    if (m_numClasses == 2) {</span>
      // System.out.println(m_binaryClassifiers[0].getProbForTargetClass(instance));
<span class="fc" id="L222">      return m_binaryClassifiers[0].distributionForInstance(instance);</span>
    }
<span class="fc" id="L224">    double[] logDocGivenClass = new double[instance.numClasses()];</span>
<span class="fc bfc" id="L225" title="All 2 branches covered.">    for (int i = 0; i &lt; m_numClasses; i++)</span>
<span class="fc" id="L226">      logDocGivenClass[i] = m_binaryClassifiers[i].getLogProbForTargetClass(instance);</span>


<span class="fc" id="L229">    double max = logDocGivenClass[Utils.maxIndex(logDocGivenClass)];</span>
<span class="fc bfc" id="L230" title="All 2 branches covered.">    for(int i = 0; i&lt;m_numClasses; i++)</span>
<span class="fc" id="L231">      logDocGivenClass[i] = Math.exp(logDocGivenClass[i] - max);</span>


    try {
<span class="fc" id="L235">      Utils.normalize(logDocGivenClass);</span>
<span class="nc" id="L236">    } catch (Exception e) {</span>
<span class="nc" id="L237">      e.printStackTrace();</span>


    }

<span class="fc" id="L242">    return logDocGivenClass;</span>
  }
  /**
   * Returns a string representation of the classifier.
   *
   * @return a string representation of the classifier
   */
  public String toString() {
<span class="fc" id="L250">    StringBuffer result = new StringBuffer(&quot;&quot;);</span>
<span class="fc" id="L251">    result.append(&quot;The log ratio of two conditional probabilities of a word w_i: log(p(w_i)|+)/p(w_i)|-)) in decent order based on their absolute values\n&quot;);</span>
<span class="fc" id="L252">    result.append(&quot;Can be used to measure the discriminative power of each word.\n&quot;);</span>
<span class="pc bpc" id="L253" title="1 of 2 branches missed.">    if (m_numClasses == 2) {</span>
      // System.out.println(m_binaryClassifiers[0].getProbForTargetClass(instance));
<span class="nc" id="L255">      return result.append(m_binaryClassifiers[0].toString()).toString();</span>
    }
<span class="pc bpc" id="L257" title="1 of 2 branches missed.">    for (int i = 0; i &lt; m_numClasses; i++)</span>
<span class="nc" id="L258">      { result.append(i+&quot; against the rest classes\n&quot;);</span>
<span class="nc" id="L259">        result.append(m_binaryClassifiers[i].toString()+&quot;\n&quot;);</span>
      }
<span class="fc" id="L261">    return result.toString();</span>
  }
  
  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration&lt;Option&gt; listOptions() {
<span class="fc" id="L270">    Vector&lt;Option&gt; newVector = new Vector&lt;Option&gt;();</span>
    
<span class="fc" id="L272">    newVector.add(new Option(&quot;\tThe number of iterations that the classifier &quot; +</span>
    		&quot;\n\twill scan the training data (default = 1)&quot;, 
<span class="fc" id="L274">    		&quot;I&quot;, 1, &quot;-I &lt;iterations&gt;&quot;));</span>
    
<span class="fc" id="L276">    newVector.add(new Option(&quot;\tUse the frequency information in data&quot;</span>
<span class="fc" id="L277">        , &quot;M&quot;, 0, &quot;-M&quot;));</span>
    
<span class="fc" id="L279">    return newVector.elements();</span>
  }

  /*
   * Options after -- are passed to the designated classifier.&lt;p&gt;
   *
   * @param options the list of options as an array of strings
   * @exception Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {

<span class="fc" id="L290">    String iterations = Utils.getOption('I', options);</span>
<span class="fc bfc" id="L291" title="All 2 branches covered.">    if (iterations.length() != 0) {</span>
<span class="fc" id="L292">      setNumIterations(Integer.parseInt(iterations));</span>
    }
    
<span class="fc" id="L295">    setMultinomialWord(Utils.getFlag('M', options));    </span>
<span class="fc" id="L296">  }</span>

  /**
   * Gets the current settings of the classifier.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String[] getOptions() {
    
<span class="fc" id="L305">    ArrayList&lt;String&gt; options = new ArrayList&lt;String&gt;();</span>

<span class="fc" id="L307">    options.add(&quot;-I&quot;);</span>
<span class="fc" id="L308">    options.add(&quot;&quot; + getNumIterations());</span>

<span class="pc bpc" id="L310" title="1 of 2 branches missed.">    if (getMultinomialWord()) {</span>
<span class="nc" id="L311">      options.add(&quot;-M&quot;);</span>
    }

<span class="fc" id="L314">    return options.toArray(new String[1]);</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String numIterationsTipText() {
<span class="nc" id="L323">    return &quot;The number of iterations that the classifier will scan the training data&quot;;</span>
  }

  /**
   * Sets the number of iterations to be performed
   */
  public void setNumIterations(int numIterations) {

<span class="fc" id="L331">    m_NumIterations = numIterations;</span>
<span class="fc" id="L332">  }</span>

  /**
   * Gets the number of iterations to be performed
   *
   * @return the iterations to be performed
   */
  public int getNumIterations() {

<span class="fc" id="L341">    return m_NumIterations;</span>
  }
  
  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String multinomialWordTipText() {
<span class="nc" id="L350">    return &quot;Make use of frequency information in data&quot;;</span>
  }
  
  /**
   * Sets whether use binary text representation
   */
  public void setMultinomialWord(boolean val) {

<span class="fc" id="L358">    m_MultinomialWord = val;</span>
<span class="fc" id="L359">  }</span>

  /**
   * Gets whether use binary text representation
   *
   * @return whether use binary text representation
   */
  public boolean getMultinomialWord() {

<span class="fc" id="L368">    return m_MultinomialWord;</span>
  }

  /**
   * Returns the revision string.
   *
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L377">    return &quot;$Revision: 1.0&quot;;</span>
  }

<span class="fc" id="L380">  public class DNBBinary implements Serializable {</span>

    /** The number of iterations. */
    private double[][] m_perWordPerClass;
    private double[] m_wordsPerClass;
<span class="fc" id="L385">    int m_classIndex = -1;</span>
    private double[] m_classDistribution;
    /** number of unique words */
    private int m_numAttributes;
    //set the target class
<span class="fc" id="L390">    private int m_targetClass = -1;</span>

<span class="fc" id="L392">    private double m_WordLaplace=1;</span>

    private double[] m_coefficient;
    private double m_classRatio;
    private double m_wordRatio;

    public void initClassifier(Instances instances) throws Exception {
<span class="fc" id="L399">      m_numAttributes = instances.numAttributes();</span>
<span class="fc" id="L400">      m_perWordPerClass = new double[2][m_numAttributes];</span>
<span class="fc" id="L401">      m_coefficient = new double[m_numAttributes];</span>
<span class="fc" id="L402">      m_wordsPerClass = new double[2];</span>
<span class="fc" id="L403">      m_classDistribution = new double[2];</span>
<span class="fc" id="L404">      m_WordLaplace = Math.log(m_numAttributes);</span>
<span class="fc" id="L405">      m_classIndex = instances.classIndex();</span>

      //Laplace
<span class="fc bfc" id="L408" title="All 2 branches covered.">      for (int c = 0; c &lt; 2; c++) {</span>
<span class="fc" id="L409">        m_classDistribution[c] = 1;</span>
<span class="fc" id="L410">        m_wordsPerClass[c] = m_WordLaplace * m_numAttributes;</span>
<span class="fc" id="L411">        java.util.Arrays.fill(m_perWordPerClass[c], m_WordLaplace);</span>
      }

<span class="fc" id="L414">    }</span>

    public void updateClassifier(Instance ins) throws
      Exception {
      //c=0 is 1, which is the target class, and c=1 is the rest
<span class="fc" id="L419">      int classIndex = 0;</span>
<span class="fc bfc" id="L420" title="All 2 branches covered.">      if (ins.value(ins.classIndex()) != m_targetClass)</span>
<span class="fc" id="L421">        classIndex = 1;</span>
<span class="fc" id="L422">      double prob = 1 -</span>
<span class="fc" id="L423">        distributionForInstance(ins)[classIndex];</span>


<span class="fc" id="L426">      double weight = prob * ins.weight();</span>

<span class="fc bfc" id="L428" title="All 2 branches covered.">      for (int a = 0; a &lt; ins.numValues(); a++) {</span>
<span class="fc bfc" id="L429" title="All 2 branches covered.">        if (ins.index(a) != m_classIndex )</span>
          {

<span class="pc bpc" id="L432" title="1 of 2 branches missed.">            if (!m_MultinomialWord) {</span>
<span class="fc bfc" id="L433" title="All 2 branches covered.">              if (ins.valueSparse(a) &gt; 0) {</span>
<span class="fc" id="L434">                m_wordsPerClass[classIndex] +=</span>
<span class="fc" id="L435">                  weight;</span>
<span class="fc" id="L436">                m_perWordPerClass[classIndex][ins.</span>
<span class="fc" id="L437">                                              index(a)] +=</span>
<span class="fc" id="L438">                  weight;</span>
              }
            } else {
<span class="nc" id="L441">              double t = ins.valueSparse(a) * weight;</span>
<span class="nc" id="L442">              m_wordsPerClass[classIndex] += t;</span>
<span class="nc" id="L443">              m_perWordPerClass[classIndex][ins.index(a)] += t;</span>
            }
            //update coefficient
<span class="fc" id="L446">            m_coefficient[ins.index(a)] = Math.log(m_perWordPerClass[0][</span>
<span class="fc" id="L447">                                                                        ins.index(a)] /</span>
<span class="fc" id="L448">                                                   m_perWordPerClass[1][ins.index(a)]);</span>
          }
      }
<span class="fc" id="L451">      m_wordRatio = Math.log(m_wordsPerClass[0] / m_wordsPerClass[1]);</span>
<span class="fc" id="L452">      m_classDistribution[classIndex] += weight;</span>
<span class="fc" id="L453">      m_classRatio = Math.log(m_classDistribution[0] /</span>
<span class="fc" id="L454">                              m_classDistribution[1]);</span>
<span class="fc" id="L455">    }</span>


    /**
     * Calculates the class membership probabilities for the given test
     * instance.
     *
     * @param instance the instance to be classified
     * @return predicted class probability distribution
     * @exception Exception if there is a problem generating the prediction
     */
    public double getLogProbForTargetClass(Instance ins) throws Exception {

<span class="fc" id="L468">      double probLog = m_classRatio;</span>
<span class="fc bfc" id="L469" title="All 2 branches covered.">      for (int a = 0; a &lt; ins.numValues(); a++) {</span>
<span class="fc bfc" id="L470" title="All 2 branches covered.">        if (ins.index(a) != m_classIndex )</span>
          {

<span class="pc bpc" id="L473" title="1 of 2 branches missed.">            if (!m_MultinomialWord) {</span>
<span class="fc bfc" id="L474" title="All 2 branches covered.">              if (ins.valueSparse(a) &gt; 0) {</span>
<span class="fc" id="L475">                probLog += m_coefficient[ins.index(a)] -</span>
<span class="fc" id="L476">                  m_wordRatio;</span>
              }
            } else {
<span class="nc" id="L479">              probLog += ins.valueSparse(a) *</span>
<span class="nc" id="L480">                (m_coefficient[ins.index(a)] - m_wordRatio);</span>
            }
          }
      }
<span class="fc" id="L484">      return probLog;</span>
    }

    /**
     * Calculates the class membership probabilities for the given test
     * instance.
     *
     * @param instance the instance to be classified
     * @return predicted class probability distribution
     * @exception Exception if there is a problem generating the prediction
     */
    public double[] distributionForInstance(Instance instance) throws
      Exception {
<span class="fc" id="L497">      double[] probOfClassGivenDoc = new double[2];</span>
<span class="fc" id="L498">      double ratio=getLogProbForTargetClass(instance);</span>
<span class="pc bpc" id="L499" title="1 of 2 branches missed.">      if (ratio &gt; 709)</span>
<span class="nc" id="L500">        probOfClassGivenDoc[0]=1;</span>
      else
        {
<span class="fc" id="L503">          ratio = Math.exp(ratio);</span>
<span class="fc" id="L504">          probOfClassGivenDoc[0]=ratio / (1 + ratio);</span>
        }

<span class="fc" id="L507">      probOfClassGivenDoc[1] = 1 - probOfClassGivenDoc[0];</span>
<span class="fc" id="L508">      return probOfClassGivenDoc;</span>
    }

    /**
     * Returns a string representation of the classifier.
     *
     * @return a string representation of the classifier
     */
    public String toString() {
      //            StringBuffer result = new StringBuffer(&quot;The cofficiency of a naive Bayes classifier, can be considered as the discriminative power of a word\n--------------------------------------\n&quot;);
<span class="nc" id="L518">      StringBuffer result = new StringBuffer();</span>

<span class="nc" id="L520">      result.append(&quot;\n&quot;);</span>
<span class="nc" id="L521">      TreeMap sort=new TreeMap();</span>
<span class="nc" id="L522">      double[] absCoeff=new double[m_numAttributes];</span>
<span class="nc bnc" id="L523" title="All 2 branches missed.">      for(int w = 0; w&lt;m_numAttributes; w++)</span>
        {
<span class="nc bnc" id="L525" title="All 2 branches missed.">          if(w==m_headerInfo.classIndex())continue;</span>
<span class="nc" id="L526">          String val= m_headerInfo.attribute(w).name()+&quot;: &quot;+m_coefficient[w];</span>
<span class="nc" id="L527">          sort.put((-1)*Math.abs(m_coefficient[w]),val);</span>
        }
<span class="nc" id="L529">      Iterator it=sort.values().iterator();</span>
<span class="nc bnc" id="L530" title="All 2 branches missed.">      while(it.hasNext())</span>
        {
<span class="nc" id="L532">          result.append((String)it.next());</span>
<span class="nc" id="L533">          result.append(&quot;\n&quot;);</span>
        }

<span class="nc" id="L536">      return result.toString();</span>
    }

    /**
     * Sets the Target Class
     */
    public void setTargetClass(int targetClass) {

<span class="fc" id="L544">      m_targetClass = targetClass;</span>
<span class="fc" id="L545">    }</span>

    /**
     * Gets the Target Class
     *
     * @return the Target Class Index
     */
    public int getTargetClass() {

<span class="nc" id="L554">      return m_targetClass;</span>
    }

  }


  /**
   * Main method for testing this class.
   *
   * @param argv the options
   */
  public static void main(String[] argv) {

<span class="nc" id="L567">    DMNBtext c = new DMNBtext();</span>

<span class="nc" id="L569">    runClassifier(c, argv);</span>
<span class="nc" id="L570">  }</span>
}

</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>