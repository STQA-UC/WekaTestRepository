<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>NaiveBayesMultinomial.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.bayes</a> &gt; <span class="el_source">NaiveBayesMultinomial.java</span></div><h1>NaiveBayesMultinomial.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 * NaiveBayesMultinomial.java
 * Copyright (C) 2003 University of Waikato, Hamilton, New Zealand
 */

package weka.classifiers.bayes;

import weka.classifiers.Classifier;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.RevisionUtils;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.WeightedInstancesHandler;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;

/**
 &lt;!-- globalinfo-start --&gt;
 * Class for building and using a multinomial Naive Bayes classifier. For more information see,&lt;br/&gt;
 * &lt;br/&gt;
 * Andrew Mccallum, Kamal Nigam: A Comparison of Event Models for Naive Bayes Text Classification. In: AAAI-98 Workshop on 'Learning for Text Categorization', 1998.&lt;br/&gt;
 * &lt;br/&gt;
 * The core equation for this classifier:&lt;br/&gt;
 * &lt;br/&gt;
 * P[Ci|D] = (P[D|Ci] x P[Ci]) / P[D] (Bayes rule)&lt;br/&gt;
 * &lt;br/&gt;
 * where Ci is class i and D is a document.
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;inproceedings{Mccallum1998,
 *    author = {Andrew Mccallum and Kamal Nigam},
 *    booktitle = {AAAI-98 Workshop on 'Learning for Text Categorization'},
 *    title = {A Comparison of Event Models for Naive Bayes Text Classification},
 *    year = {1998}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Andrew Golightly (acg4@cs.waikato.ac.nz)
 * @author Bernhard Pfahringer (bernhard@cs.waikato.ac.nz)
 * @version $Revision: 6303 $ 
 */
<span class="fc" id="L77">public class NaiveBayesMultinomial </span>
  extends Classifier 
  implements WeightedInstancesHandler,TechnicalInformationHandler {
  
  /** for serialization */
  static final long serialVersionUID = 5932177440181257085L;
  
  /**
   * probability that a word (w) exists in a class (H) (i.e. Pr[w|H])
   * The matrix is in the this format: probOfWordGivenClass[class][wordAttribute]
   * NOTE: the values are actually the log of Pr[w|H]
   */
  protected double[][] m_probOfWordGivenClass;
    
  /** the probability of a class (i.e. Pr[H]) */
  protected double[] m_probOfClass;
    
  /** number of unique words */
  protected int m_numAttributes;
    
  /** number of class values */
  protected int m_numClasses;
    
  /** cache lnFactorial computations */
<span class="fc" id="L101">  protected double[] m_lnFactorialCache = new double[]{0.0,0.0};</span>
    
  /** copy of header information for use in toString method */
  protected Instances m_headerInfo;

  /**
   * Returns a string describing this classifier
   * @return a description of the classifier suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L112">    return </span>
<span class="nc" id="L113">        &quot;Class for building and using a multinomial Naive Bayes classifier. &quot;</span>
      + &quot;For more information see,\n\n&quot;
<span class="nc" id="L115">      + getTechnicalInformation().toString() + &quot;\n\n&quot;</span>
<span class="nc" id="L116">      + &quot;The core equation for this classifier:\n\n&quot;</span>
<span class="nc" id="L117">      + &quot;P[Ci|D] = (P[D|Ci] x P[Ci]) / P[D] (Bayes rule)\n\n&quot;</span>
<span class="nc" id="L118">      + &quot;where Ci is class i and D is a document.&quot;;</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;
    
<span class="nc" id="L131">    result = new TechnicalInformation(Type.INPROCEEDINGS);</span>
<span class="nc" id="L132">    result.setValue(Field.AUTHOR, &quot;Andrew Mccallum and Kamal Nigam&quot;);</span>
<span class="nc" id="L133">    result.setValue(Field.YEAR, &quot;1998&quot;);</span>
<span class="nc" id="L134">    result.setValue(Field.TITLE, &quot;A Comparison of Event Models for Naive Bayes Text Classification&quot;);</span>
<span class="nc" id="L135">    result.setValue(Field.BOOKTITLE, &quot;AAAI-98 Workshop on 'Learning for Text Categorization'&quot;);</span>
    
<span class="nc" id="L137">    return result;</span>
  }

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L146">    Capabilities result = super.getCapabilities();</span>
<span class="fc" id="L147">    result.disableAll();</span>

    // attributes
<span class="fc" id="L150">    result.enable(Capability.NUMERIC_ATTRIBUTES);</span>

    // class
<span class="fc" id="L153">    result.enable(Capability.NOMINAL_CLASS);</span>
<span class="fc" id="L154">    result.enable(Capability.MISSING_CLASS_VALUES);</span>
    
<span class="fc" id="L156">    return result;</span>
  }

  /**
   * Generates the classifier.
   *
   * @param instances set of instances serving as training data 
   * @throws Exception if the classifier has not been generated successfully
   */
  public void buildClassifier(Instances instances) throws Exception 
  {
    // can classifier handle the data?
<span class="fc" id="L168">    getCapabilities().testWithFail(instances);</span>

    // remove instances with missing class
<span class="fc" id="L171">    instances = new Instances(instances);</span>
<span class="fc" id="L172">    instances.deleteWithMissingClass();</span>
    
<span class="fc" id="L174">    m_headerInfo = new Instances(instances, 0);</span>
<span class="fc" id="L175">    m_numClasses = instances.numClasses();</span>
<span class="fc" id="L176">    m_numAttributes = instances.numAttributes();</span>
<span class="fc" id="L177">    m_probOfWordGivenClass = new double[m_numClasses][];</span>
	
    /*
      initialising the matrix of word counts
      NOTE: Laplace estimator introduced in case a word that does not appear for a class in the 
      training set does so for the test set
    */
<span class="fc bfc" id="L184" title="All 2 branches covered.">    for(int c = 0; c&lt;m_numClasses; c++)</span>
      {
<span class="fc" id="L186">	m_probOfWordGivenClass[c] = new double[m_numAttributes];</span>
<span class="fc bfc" id="L187" title="All 2 branches covered.">	for(int att = 0; att&lt;m_numAttributes; att++)</span>
	  {
<span class="fc" id="L189">	    m_probOfWordGivenClass[c][att] = 1;</span>
	  }
      }
	
    //enumerate through the instances 
    Instance instance;
    int classIndex;
    double numOccurences;
<span class="fc" id="L197">    double[] docsPerClass = new double[m_numClasses];</span>
<span class="fc" id="L198">    double[] wordsPerClass = new double[m_numClasses];</span>
	
<span class="fc" id="L200">    java.util.Enumeration enumInsts = instances.enumerateInstances();</span>
<span class="fc bfc" id="L201" title="All 2 branches covered.">    while (enumInsts.hasMoreElements()) </span>
      {
<span class="fc" id="L203">	instance = (Instance) enumInsts.nextElement();</span>
<span class="fc" id="L204">	classIndex = (int)instance.value(instance.classIndex());</span>
<span class="fc" id="L205">	docsPerClass[classIndex] += instance.weight();</span>
		
<span class="fc bfc" id="L207" title="All 2 branches covered.">	for(int a = 0; a&lt;instance.numValues(); a++)</span>
<span class="fc bfc" id="L208" title="All 2 branches covered.">	  if(instance.index(a) != instance.classIndex())</span>
	    {
<span class="pc bpc" id="L210" title="1 of 2 branches missed.">	      if(!instance.isMissing(a))</span>
		{
<span class="fc" id="L212">		  numOccurences = instance.valueSparse(a) * instance.weight();</span>
<span class="pc bpc" id="L213" title="1 of 2 branches missed.">		  if(numOccurences &lt; 0)</span>
<span class="nc" id="L214">		    throw new Exception(&quot;Numeric attribute values must all be greater or equal to zero.&quot;);</span>
<span class="fc" id="L215">		  wordsPerClass[classIndex] += numOccurences;</span>
<span class="fc" id="L216">		  m_probOfWordGivenClass[classIndex][instance.index(a)] += numOccurences;</span>
		}
	    } 
      }
	
    /*
      normalising probOfWordGivenClass values
      and saving each value as the log of each value
    */
<span class="fc bfc" id="L225" title="All 2 branches covered.">    for(int c = 0; c&lt;m_numClasses; c++)</span>
<span class="fc bfc" id="L226" title="All 2 branches covered.">      for(int v = 0; v&lt;m_numAttributes; v++) </span>
<span class="fc" id="L227">	m_probOfWordGivenClass[c][v] = Math.log(m_probOfWordGivenClass[c][v] / (wordsPerClass[c] + m_numAttributes - 1));</span>
	
    /*
      calculating Pr(H)
      NOTE: Laplace estimator introduced in case a class does not get mentioned in the set of 
      training instances
    */
<span class="fc" id="L234">    final double numDocs = instances.sumOfWeights() + m_numClasses;</span>
<span class="fc" id="L235">    m_probOfClass = new double[m_numClasses];</span>
<span class="fc bfc" id="L236" title="All 2 branches covered.">    for(int h=0; h&lt;m_numClasses; h++)</span>
<span class="fc" id="L237">      m_probOfClass[h] = (double)(docsPerClass[h] + 1)/numDocs; </span>
<span class="fc" id="L238">  }</span>
    
  /**
   * Calculates the class membership probabilities for the given test 
   * instance.
   *
   * @param instance the instance to be classified
   * @return predicted class probability distribution
   * @throws Exception if there is a problem generating the prediction
   */
  public double [] distributionForInstance(Instance instance) throws Exception 
  {
<span class="fc" id="L250">    double[] probOfClassGivenDoc = new double[m_numClasses];</span>
	
    //calculate the array of log(Pr[D|C])
<span class="fc" id="L253">    double[] logDocGivenClass = new double[m_numClasses];</span>
<span class="fc bfc" id="L254" title="All 2 branches covered.">    for(int h = 0; h&lt;m_numClasses; h++)</span>
<span class="fc" id="L255">      logDocGivenClass[h] = probOfDocGivenClass(instance, h);</span>
	
<span class="fc" id="L257">    double max = logDocGivenClass[Utils.maxIndex(logDocGivenClass)];</span>
<span class="fc" id="L258">    double probOfDoc = 0.0;</span>
	
<span class="fc bfc" id="L260" title="All 2 branches covered.">    for(int i = 0; i&lt;m_numClasses; i++) </span>
      {
<span class="fc" id="L262">	probOfClassGivenDoc[i] = Math.exp(logDocGivenClass[i] - max) * m_probOfClass[i];</span>
<span class="fc" id="L263">	probOfDoc += probOfClassGivenDoc[i];</span>
      }
	
<span class="fc" id="L266">    Utils.normalize(probOfClassGivenDoc,probOfDoc);</span>
	
<span class="fc" id="L268">    return probOfClassGivenDoc;</span>
  }
    
  /**
   * log(N!) + (for all the words)(log(Pi^ni) - log(ni!))
   *  
   *  where 
   *      N is the total number of words
   *      Pi is the probability of obtaining word i
   *      ni is the number of times the word at index i occurs in the document
   *
   * @param inst       The instance to be classified
   * @param classIndex The index of the class we are calculating the probability with respect to
   *
   * @return The log of the probability of the document occuring given the class
   */
    
  private double probOfDocGivenClass(Instance inst, int classIndex)
  {
<span class="fc" id="L287">    double answer = 0;</span>
    //double totalWords = 0; //no need as we are not calculating the factorial at all.
	
    double freqOfWordInDoc;  //should be double
<span class="fc bfc" id="L291" title="All 2 branches covered.">    for(int i = 0; i&lt;inst.numValues(); i++)</span>
<span class="fc bfc" id="L292" title="All 2 branches covered.">      if(inst.index(i) != inst.classIndex())</span>
	{
<span class="fc" id="L294">	  freqOfWordInDoc = inst.valueSparse(i);</span>
	  //totalWords += freqOfWordInDoc;
<span class="fc" id="L296">	  answer += (freqOfWordInDoc * m_probOfWordGivenClass[classIndex][inst.index(i)] </span>
		     ); //- lnFactorial(freqOfWordInDoc));
	}
	
    //answer += lnFactorial(totalWords);//The factorial terms don't make 
    //any difference to the classifier's
    //accuracy, so not needed.
	
<span class="fc" id="L304">    return answer;</span>
  }
    
  /**
   * Fast computation of ln(n!) for non-negative ints
   *
   * negative ints are passed on to the general gamma-function
   * based version in weka.core.SpecialFunctions
   *
   * if the current n value is higher than any previous one,
   * the cache is extended and filled to cover it
   *
   * the common case is reduced to a simple array lookup
   *
   * @param  n the integer 
   * @return ln(n!)
   */
    
  public double lnFactorial(int n) 
  {
<span class="nc bnc" id="L324" title="All 2 branches missed.">    if (n &lt; 0) return weka.core.SpecialFunctions.lnFactorial(n);</span>
	
<span class="nc bnc" id="L326" title="All 2 branches missed.">    if (m_lnFactorialCache.length &lt;= n) {</span>
<span class="nc" id="L327">      double[] tmp = new double[n+1];</span>
<span class="nc" id="L328">      System.arraycopy(m_lnFactorialCache,0,tmp,0,m_lnFactorialCache.length);</span>
<span class="nc bnc" id="L329" title="All 2 branches missed.">      for(int i = m_lnFactorialCache.length; i &lt; tmp.length; i++) </span>
<span class="nc" id="L330">	tmp[i] = tmp[i-1] + Math.log(i);</span>
<span class="nc" id="L331">      m_lnFactorialCache = tmp;</span>
    }
	
<span class="nc" id="L334">    return m_lnFactorialCache[n];</span>
  }
    
  /**
   * Returns a string representation of the classifier.
   * 
   * @return a string representation of the classifier
   */
  public String toString()
  {
<span class="fc" id="L344">    StringBuffer result = new StringBuffer(&quot;The independent probability of a class\n--------------------------------------\n&quot;);</span>
	
<span class="pc bpc" id="L346" title="1 of 2 branches missed.">    for(int c = 0; c&lt;m_numClasses; c++)</span>
<span class="nc" id="L347">      result.append(m_headerInfo.classAttribute().value(c)).append(&quot;\t&quot;).append(Double.toString(m_probOfClass[c])).append(&quot;\n&quot;);</span>
	
<span class="fc" id="L349">    result.append(&quot;\nThe probability of a word given the class\n-----------------------------------------\n\t&quot;);</span>

<span class="pc bpc" id="L351" title="1 of 2 branches missed.">    for(int c = 0; c&lt;m_numClasses; c++)</span>
<span class="nc" id="L352">      result.append(m_headerInfo.classAttribute().value(c)).append(&quot;\t&quot;);</span>
	
<span class="fc" id="L354">    result.append(&quot;\n&quot;);</span>

<span class="pc bpc" id="L356" title="1 of 2 branches missed.">    for(int w = 0; w&lt;m_numAttributes; w++)</span>
    {
<span class="nc bnc" id="L358" title="All 2 branches missed.">      if (w != m_headerInfo.classIndex()) {</span>
<span class="nc" id="L359">        result.append(m_headerInfo.attribute(w).name()).append(&quot;\t&quot;);</span>
<span class="nc bnc" id="L360" title="All 2 branches missed.">        for(int c = 0; c&lt;m_numClasses; c++)</span>
<span class="nc" id="L361">          result.append(Double.toString(Math.exp(m_probOfWordGivenClass[c][w]))).append(&quot;\t&quot;);</span>
<span class="nc" id="L362">        result.append(&quot;\n&quot;);</span>
      }
    }

<span class="fc" id="L366">    return result.toString();</span>
  }
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L375">    return RevisionUtils.extract(&quot;$Revision: 6303 $&quot;);</span>
  }
    
  /**
   * Main method for testing this class.
   *
   * @param argv the options
   */
  public static void main(String [] argv) {
<span class="nc" id="L384">    runClassifier(new NaiveBayesMultinomial(), argv);</span>
<span class="nc" id="L385">  }</span>
}

</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>