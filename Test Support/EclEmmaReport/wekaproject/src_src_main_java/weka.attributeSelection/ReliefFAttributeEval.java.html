<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>ReliefFAttributeEval.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.attributeSelection</a> &gt; <span class="el_source">ReliefFAttributeEval.java</span></div><h1>ReliefFAttributeEval.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    ReliefFAttributeEval.java
 *    Copyright (C) 1999 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.attributeSelection;

import weka.core.Attribute;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.OptionHandler;
import weka.core.RevisionUtils;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;

import java.util.Enumeration;
import java.util.Random;
import java.util.Vector;

/** 
 &lt;!-- globalinfo-start --&gt;
 * ReliefFAttributeEval :&lt;br/&gt;
 * &lt;br/&gt;
 * Evaluates the worth of an attribute by repeatedly sampling an instance and considering the value of the given attribute for the nearest instance of the same and different class. Can operate on both discrete and continuous class data.&lt;br/&gt;
 * &lt;br/&gt;
 * For more information see:&lt;br/&gt;
 * &lt;br/&gt;
 * Kenji Kira, Larry A. Rendell: A Practical Approach to Feature Selection. In: Ninth International Workshop on Machine Learning, 249-256, 1992.&lt;br/&gt;
 * &lt;br/&gt;
 * Igor Kononenko: Estimating Attributes: Analysis and Extensions of RELIEF. In: European Conference on Machine Learning, 171-182, 1994.&lt;br/&gt;
 * &lt;br/&gt;
 * Marko Robnik-Sikonja, Igor Kononenko: An adaptation of Relief for attribute estimation in regression. In: Fourteenth International Conference on Machine Learning, 296-304, 1997.
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;inproceedings{Kira1992,
 *    author = {Kenji Kira and Larry A. Rendell},
 *    booktitle = {Ninth International Workshop on Machine Learning},
 *    editor = {Derek H. Sleeman and Peter Edwards},
 *    pages = {249-256},
 *    publisher = {Morgan Kaufmann},
 *    title = {A Practical Approach to Feature Selection},
 *    year = {1992}
 * }
 * 
 * &amp;#64;inproceedings{Kononenko1994,
 *    author = {Igor Kononenko},
 *    booktitle = {European Conference on Machine Learning},
 *    editor = {Francesco Bergadano and Luc De Raedt},
 *    pages = {171-182},
 *    publisher = {Springer},
 *    title = {Estimating Attributes: Analysis and Extensions of RELIEF},
 *    year = {1994}
 * }
 * 
 * &amp;#64;inproceedings{Robnik-Sikonja1997,
 *    author = {Marko Robnik-Sikonja and Igor Kononenko},
 *    booktitle = {Fourteenth International Conference on Machine Learning},
 *    editor = {Douglas H. Fisher},
 *    pages = {296-304},
 *    publisher = {Morgan Kaufmann},
 *    title = {An adaptation of Relief for attribute estimation in regression},
 *    year = {1997}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -M &amp;lt;num instances&amp;gt;
 *  Specify the number of instances to
 *  sample when estimating attributes.
 *  If not specified, then all instances
 *  will be used.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -D &amp;lt;seed&amp;gt;
 *  Seed for randomly sampling instances.
 *  (Default = 1)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -K &amp;lt;number of neighbours&amp;gt;
 *  Number of nearest neighbours (k) used
 *  to estimate attribute relevances
 *  (Default = 10).&lt;/pre&gt;
 * 
 * &lt;pre&gt; -W
 *  Weight nearest neighbours by distance&lt;/pre&gt;
 * 
 * &lt;pre&gt; -A &amp;lt;num&amp;gt;
 *  Specify sigma value (used in an exp
 *  function to control how quickly
 *  weights for more distant instances
 *  decrease. Use in conjunction with -W.
 *  Sensible value=1/5 to 1/10 of the
 *  number of nearest neighbours.
 *  (Default = 2)&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Mark Hall (mhall@cs.waikato.ac.nz)
 * @version $Revision: 5511 $
 */
public class ReliefFAttributeEval
  extends ASEvaluation
  implements AttributeEvaluator,
             OptionHandler, 
             TechnicalInformationHandler {
  
  /** for serialization */
  static final long serialVersionUID = -8422186665795839379L;

  /** The training instances */
  private Instances m_trainInstances;

  /** The class index */
  private int m_classIndex;

  /** The number of attributes */
  private int m_numAttribs;

  /** The number of instances */
  private int m_numInstances;

  /** Numeric class */
  private boolean m_numericClass;

  /** The number of classes if class is nominal */
  private int m_numClasses;

  /** 
   * Used to hold the probability of a different class val given nearest
   * instances (numeric class)
   */
  private double m_ndc;

  /** 
   * Used to hold the prob of different value of an attribute given
   * nearest instances (numeric class case)
   */
  private double[] m_nda;

  /**
   * Used to hold the prob of a different class val and different att
   * val given nearest instances (numeric class case)
   */
  private double[] m_ndcda;

  /** Holds the weights that relief assigns to attributes */
  private double[] m_weights;

  /** Prior class probabilities (discrete class case) */
  private double[] m_classProbs;

  /** 
   * The number of instances to sample when estimating attributes
   * default == -1, use all instances
   */
  private int m_sampleM;

  /** The number of nearest hits/misses */
  private int m_Knn;

  /** k nearest scores + instance indexes for n classes */
  private double[][][] m_karray;

  /** Upper bound for numeric attributes */
  private double[] m_maxArray;

  /** Lower bound for numeric attributes */
  private double[] m_minArray;

  /** Keep track of the farthest instance for each class */
  private double[] m_worst;

  /** Index in the m_karray of the farthest instance for each class */
  private int[] m_index;

  /** Number of nearest neighbours stored of each class */
  private int[] m_stored;
 
  /** Random number seed used for sampling instances */
  private int m_seed;

  /**
   *  used to (optionally) weight nearest neighbours by their distance
   *  from the instance in question. Each entry holds 
   *  exp(-((rank(r_i, i_j)/sigma)^2)) where rank(r_i,i_j) is the rank of
   *  instance i_j in a sequence of instances ordered by the distance
   *  from r_i. sigma is a user defined parameter, default=20
   **/
  private double[] m_weightsByRank;
  private int m_sigma;
  
  /** Weight by distance rather than equal weights */
  private boolean m_weightByDistance;

  /**
   * Constructor
   */
<span class="nc" id="L227">  public ReliefFAttributeEval () {</span>
<span class="nc" id="L228">    resetOptions();</span>
<span class="nc" id="L229">  }</span>

  /**
   * Returns a string describing this attribute evaluator
   * @return a description of the evaluator suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L237">    return &quot;ReliefFAttributeEval :\n\nEvaluates the worth of an attribute by &quot;</span>
      +&quot;repeatedly sampling an instance and considering the value of the &quot;
      +&quot;given attribute for the nearest instance of the same and different &quot;
      +&quot;class. Can operate on both discrete and continuous class data.\n\n&quot;
      + &quot;For more information see:\n\n&quot;
<span class="nc" id="L242">      + getTechnicalInformation().toString();</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation        result;
    TechnicalInformation        additional;
    
<span class="nc" id="L256">    result = new TechnicalInformation(Type.INPROCEEDINGS);</span>
<span class="nc" id="L257">    result.setValue(Field.AUTHOR, &quot;Kenji Kira and Larry A. Rendell&quot;);</span>
<span class="nc" id="L258">    result.setValue(Field.TITLE, &quot;A Practical Approach to Feature Selection&quot;);</span>
<span class="nc" id="L259">    result.setValue(Field.BOOKTITLE, &quot;Ninth International Workshop on Machine Learning&quot;);</span>
<span class="nc" id="L260">    result.setValue(Field.EDITOR, &quot;Derek H. Sleeman and Peter Edwards&quot;);</span>
<span class="nc" id="L261">    result.setValue(Field.YEAR, &quot;1992&quot;);</span>
<span class="nc" id="L262">    result.setValue(Field.PAGES, &quot;249-256&quot;);</span>
<span class="nc" id="L263">    result.setValue(Field.PUBLISHER, &quot;Morgan Kaufmann&quot;);</span>
    
<span class="nc" id="L265">    additional = result.add(Type.INPROCEEDINGS);</span>
<span class="nc" id="L266">    additional.setValue(Field.AUTHOR, &quot;Igor Kononenko&quot;);</span>
<span class="nc" id="L267">    additional.setValue(Field.TITLE, &quot;Estimating Attributes: Analysis and Extensions of RELIEF&quot;);</span>
<span class="nc" id="L268">    additional.setValue(Field.BOOKTITLE, &quot;European Conference on Machine Learning&quot;);</span>
<span class="nc" id="L269">    additional.setValue(Field.EDITOR, &quot;Francesco Bergadano and Luc De Raedt&quot;);</span>
<span class="nc" id="L270">    additional.setValue(Field.YEAR, &quot;1994&quot;);</span>
<span class="nc" id="L271">    additional.setValue(Field.PAGES, &quot;171-182&quot;);</span>
<span class="nc" id="L272">    additional.setValue(Field.PUBLISHER, &quot;Springer&quot;);</span>
    
<span class="nc" id="L274">    additional = result.add(Type.INPROCEEDINGS);</span>
<span class="nc" id="L275">    additional.setValue(Field.AUTHOR, &quot;Marko Robnik-Sikonja and Igor Kononenko&quot;);</span>
<span class="nc" id="L276">    additional.setValue(Field.TITLE, &quot;An adaptation of Relief for attribute estimation in regression&quot;);</span>
<span class="nc" id="L277">    additional.setValue(Field.BOOKTITLE, &quot;Fourteenth International Conference on Machine Learning&quot;);</span>
<span class="nc" id="L278">    additional.setValue(Field.EDITOR, &quot;Douglas H. Fisher&quot;);</span>
<span class="nc" id="L279">    additional.setValue(Field.YEAR, &quot;1997&quot;);</span>
<span class="nc" id="L280">    additional.setValue(Field.PAGES, &quot;296-304&quot;);</span>
<span class="nc" id="L281">    additional.setValue(Field.PUBLISHER, &quot;Morgan Kaufmann&quot;);</span>
    
<span class="nc" id="L283">    return result;</span>
  }

  /**
   * Returns an enumeration describing the available options.
   * @return an enumeration of all the available options.
   **/
  public Enumeration listOptions () {
<span class="nc" id="L291">    Vector newVector = new Vector(4);</span>
<span class="nc" id="L292">    newVector</span>
<span class="nc" id="L293">      .addElement(new Option(&quot;\tSpecify the number of instances to\n&quot; </span>
                             + &quot;\tsample when estimating attributes.\n&quot; 
                             + &quot;\tIf not specified, then all instances\n&quot; 
<span class="nc" id="L296">                             + &quot;\twill be used.&quot;, &quot;M&quot;, 1</span>
<span class="nc" id="L297">                             , &quot;-M &lt;num instances&gt;&quot;));</span>
<span class="nc" id="L298">    newVector.</span>
<span class="nc" id="L299">      addElement(new Option(&quot;\tSeed for randomly sampling instances.\n&quot; </span>
<span class="nc" id="L300">                            + &quot;\t(Default = 1)&quot;, &quot;D&quot;, 1</span>
<span class="nc" id="L301">                            , &quot;-D &lt;seed&gt;&quot;));</span>
<span class="nc" id="L302">    newVector.</span>
<span class="nc" id="L303">      addElement(new Option(&quot;\tNumber of nearest neighbours (k) used\n&quot; </span>
                            + &quot;\tto estimate attribute relevances\n&quot; 
<span class="nc" id="L305">                            + &quot;\t(Default = 10).&quot;, &quot;K&quot;, 1</span>
<span class="nc" id="L306">                            , &quot;-K &lt;number of neighbours&gt;&quot;));</span>
<span class="nc" id="L307">    newVector.</span>
<span class="nc" id="L308">      addElement(new Option(&quot;\tWeight nearest neighbours by distance&quot;, &quot;W&quot;</span>
<span class="nc" id="L309">                            , 0, &quot;-W&quot;));</span>
<span class="nc" id="L310">    newVector.</span>
<span class="nc" id="L311">      addElement(new Option(&quot;\tSpecify sigma value (used in an exp\n&quot; </span>
                            + &quot;\tfunction to control how quickly\n&quot; 
                            + &quot;\tweights for more distant instances\n&quot; 
                            + &quot;\tdecrease. Use in conjunction with -W.\n&quot; 
                            + &quot;\tSensible value=1/5 to 1/10 of the\n&quot; 
                            + &quot;\tnumber of nearest neighbours.\n&quot; 
<span class="nc" id="L317">                            + &quot;\t(Default = 2)&quot;, &quot;A&quot;, 1, &quot;-A &lt;num&gt;&quot;));</span>
<span class="nc" id="L318">    return  newVector.elements();</span>
  }


  /**
   * Parses a given list of options. &lt;p/&gt;
   *
   &lt;!-- options-start --&gt;
   * Valid options are: &lt;p/&gt;
   * 
   * &lt;pre&gt; -M &amp;lt;num instances&amp;gt;
   *  Specify the number of instances to
   *  sample when estimating attributes.
   *  If not specified, then all instances
   *  will be used.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -D &amp;lt;seed&amp;gt;
   *  Seed for randomly sampling instances.
   *  (Default = 1)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -K &amp;lt;number of neighbours&amp;gt;
   *  Number of nearest neighbours (k) used
   *  to estimate attribute relevances
   *  (Default = 10).&lt;/pre&gt;
   * 
   * &lt;pre&gt; -W
   *  Weight nearest neighbours by distance&lt;/pre&gt;
   * 
   * &lt;pre&gt; -A &amp;lt;num&amp;gt;
   *  Specify sigma value (used in an exp
   *  function to control how quickly
   *  weights for more distant instances
   *  decrease. Use in conjunction with -W.
   *  Sensible value=1/5 to 1/10 of the
   *  number of nearest neighbours.
   *  (Default = 2)&lt;/pre&gt;
   * 
   &lt;!-- options-end --&gt;
   *
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions (String[] options)
    throws Exception {
    String optionString;
<span class="nc" id="L363">    resetOptions();</span>
<span class="nc" id="L364">    setWeightByDistance(Utils.getFlag('W', options));</span>
<span class="nc" id="L365">    optionString = Utils.getOption('M', options);</span>

<span class="nc bnc" id="L367" title="All 2 branches missed.">    if (optionString.length() != 0) {</span>
<span class="nc" id="L368">      setSampleSize(Integer.parseInt(optionString));</span>
    }

<span class="nc" id="L371">    optionString = Utils.getOption('D', options);</span>

<span class="nc bnc" id="L373" title="All 2 branches missed.">    if (optionString.length() != 0) {</span>
<span class="nc" id="L374">      setSeed(Integer.parseInt(optionString));</span>
    }

<span class="nc" id="L377">    optionString = Utils.getOption('K', options);</span>

<span class="nc bnc" id="L379" title="All 2 branches missed.">    if (optionString.length() != 0) {</span>
<span class="nc" id="L380">      setNumNeighbours(Integer.parseInt(optionString));</span>
    }

<span class="nc" id="L383">    optionString = Utils.getOption('A', options);</span>

<span class="nc bnc" id="L385" title="All 2 branches missed.">    if (optionString.length() != 0) {</span>
<span class="nc" id="L386">      setWeightByDistance(true); // turn on weighting by distance</span>
<span class="nc" id="L387">      setSigma(Integer.parseInt(optionString));</span>
    }
<span class="nc" id="L389">  }</span>

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String sigmaTipText() {
<span class="nc" id="L397">    return &quot;Set influence of nearest neighbours. Used in an exp function to &quot;</span>
      +&quot;control how quickly weights decrease for more distant instances. &quot;
      +&quot;Use in conjunction with weightByDistance. Sensible values = 1/5 to &quot;
      +&quot;1/10 the number of nearest neighbours.&quot;;
  }

  /**
   * Sets the sigma value.
   *
   * @param s the value of sigma (&gt; 0)
   * @throws Exception if s is not positive
   */
  public void setSigma (int s)
    throws Exception {
<span class="nc bnc" id="L411" title="All 2 branches missed.">    if (s &lt;= 0) {</span>
<span class="nc" id="L412">      throw  new Exception(&quot;value of sigma must be &gt; 0!&quot;);</span>
    }

<span class="nc" id="L415">    m_sigma = s;</span>
<span class="nc" id="L416">  }</span>


  /**
   * Get the value of sigma.
   *
   * @return the sigma value.
   */
  public int getSigma () {
<span class="nc" id="L425">    return  m_sigma;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String numNeighboursTipText() {
<span class="nc" id="L434">    return &quot;Number of nearest neighbours for attribute estimation.&quot;;</span>
  }

  /**
   * Set the number of nearest neighbours
   *
   * @param n the number of nearest neighbours.
   */
  public void setNumNeighbours (int n) {
<span class="nc" id="L443">    m_Knn = n;</span>
<span class="nc" id="L444">  }</span>


  /**
   * Get the number of nearest neighbours
   *
   * @return the number of nearest neighbours
   */
  public int getNumNeighbours () {
<span class="nc" id="L453">    return  m_Knn;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String seedTipText() {
<span class="nc" id="L462">    return &quot;Random seed for sampling instances.&quot;;</span>
  }

  /**
   * Set the random number seed for randomly sampling instances.
   *
   * @param s the random number seed.
   */
  public void setSeed (int s) {
<span class="nc" id="L471">    m_seed = s;</span>
<span class="nc" id="L472">  }</span>


  /**
   * Get the seed used for randomly sampling instances.
   *
   * @return the random number seed.
   */
  public int getSeed () {
<span class="nc" id="L481">    return  m_seed;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String sampleSizeTipText() {
<span class="nc" id="L490">    return &quot;Number of instances to sample. Default (-1) indicates that all &quot;</span>
      +&quot;instances will be used for attribute estimation.&quot;;
  }

  /**
   * Set the number of instances to sample for attribute estimation
   *
   * @param s the number of instances to sample.
   */
  public void setSampleSize (int s) {
<span class="nc" id="L500">    m_sampleM = s;</span>
<span class="nc" id="L501">  }</span>


  /**
   * Get the number of instances used for estimating attributes
   *
   * @return the number of instances.
   */
  public int getSampleSize () {
<span class="nc" id="L510">    return  m_sampleM;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String weightByDistanceTipText() {
<span class="nc" id="L519">    return &quot;Weight nearest neighbours by their distance.&quot;;</span>
  }

  /**
   * Set the nearest neighbour weighting method
   *
   * @param b true nearest neighbours are to be weighted by distance.
   */
  public void setWeightByDistance (boolean b) {
<span class="nc" id="L528">    m_weightByDistance = b;</span>
<span class="nc" id="L529">  }</span>


  /**
   * Get whether nearest neighbours are being weighted by distance
   *
   * @return m_weightByDiffernce
   */
  public boolean getWeightByDistance () {
<span class="nc" id="L538">    return  m_weightByDistance;</span>
  }


  /**
   * Gets the current settings of ReliefFAttributeEval.
   *
   * @return an array of strings suitable for passing to setOptions()
   */
  public String[] getOptions () {
<span class="nc" id="L548">    String[] options = new String[9];</span>
<span class="nc" id="L549">    int current = 0;</span>

<span class="nc bnc" id="L551" title="All 2 branches missed.">    if (getWeightByDistance()) {</span>
<span class="nc" id="L552">      options[current++] = &quot;-W&quot;;</span>
    }

<span class="nc" id="L555">    options[current++] = &quot;-M&quot;;</span>
<span class="nc" id="L556">    options[current++] = &quot;&quot; + getSampleSize();</span>
<span class="nc" id="L557">    options[current++] = &quot;-D&quot;;</span>
<span class="nc" id="L558">    options[current++] = &quot;&quot; + getSeed();</span>
<span class="nc" id="L559">    options[current++] = &quot;-K&quot;;</span>
<span class="nc" id="L560">    options[current++] = &quot;&quot; + getNumNeighbours();</span>
    
<span class="nc bnc" id="L562" title="All 2 branches missed.">    if (getWeightByDistance()) {</span>
<span class="nc" id="L563">      options[current++] = &quot;-A&quot;;</span>
<span class="nc" id="L564">      options[current++] = &quot;&quot; + getSigma();</span>
    }

<span class="nc bnc" id="L567" title="All 2 branches missed.">    while (current &lt; options.length) {</span>
<span class="nc" id="L568">      options[current++] = &quot;&quot;;</span>
    }

<span class="nc" id="L571">    return  options;</span>
  }


  /**
   * Return a description of the ReliefF attribute evaluator.
   *
   * @return a description of the evaluator as a String.
   */
  public String toString () {
<span class="nc" id="L581">    StringBuffer text = new StringBuffer();</span>

<span class="nc bnc" id="L583" title="All 2 branches missed.">    if (m_trainInstances == null) {</span>
<span class="nc" id="L584">      text.append(&quot;ReliefF feature evaluator has not been built yet\n&quot;);</span>
    }
    else {
<span class="nc" id="L587">      text.append(&quot;\tReliefF Ranking Filter&quot;);</span>
<span class="nc" id="L588">      text.append(&quot;\n\tInstances sampled: &quot;);</span>

<span class="nc bnc" id="L590" title="All 2 branches missed.">      if (m_sampleM == -1) {</span>
<span class="nc" id="L591">        text.append(&quot;all\n&quot;);</span>
      }
      else {
<span class="nc" id="L594">        text.append(m_sampleM + &quot;\n&quot;);</span>
      }

<span class="nc" id="L597">      text.append(&quot;\tNumber of nearest neighbours (k): &quot; + m_Knn + &quot;\n&quot;);</span>

<span class="nc bnc" id="L599" title="All 2 branches missed.">      if (m_weightByDistance) {</span>
<span class="nc" id="L600">        text.append(&quot;\tExponentially decreasing (with distance) &quot; </span>
                    + &quot;influence for\n&quot; 
                    + &quot;\tnearest neighbours. Sigma: &quot; 
<span class="nc" id="L603">                    + m_sigma + &quot;\n&quot;);</span>
      }
      else {
<span class="nc" id="L606">        text.append(&quot;\tEqual influence nearest neighbours\n&quot;);</span>
      }
    }

<span class="nc" id="L610">    return  text.toString();</span>
  }

  /**
   * Returns the capabilities of this evaluator.
   *
   * @return            the capabilities of this evaluator
   * @see               Capabilities
   */
  public Capabilities getCapabilities() {
<span class="nc" id="L620">    Capabilities result = super.getCapabilities();</span>
<span class="nc" id="L621">    result.disableAll();</span>
    
    // attributes
<span class="nc" id="L624">    result.enable(Capability.NOMINAL_ATTRIBUTES);</span>
<span class="nc" id="L625">    result.enable(Capability.NUMERIC_ATTRIBUTES);</span>
<span class="nc" id="L626">    result.enable(Capability.DATE_ATTRIBUTES);</span>
<span class="nc" id="L627">    result.enable(Capability.MISSING_VALUES);</span>
    
    // class
<span class="nc" id="L630">    result.enable(Capability.NOMINAL_CLASS);</span>
<span class="nc" id="L631">    result.enable(Capability.NUMERIC_CLASS);</span>
<span class="nc" id="L632">    result.enable(Capability.DATE_CLASS);</span>
<span class="nc" id="L633">    result.enable(Capability.MISSING_CLASS_VALUES);</span>
    
<span class="nc" id="L635">    return result;</span>
  }

  /**
   * Initializes a ReliefF attribute evaluator. 
   *
   * @param data set of instances serving as training data 
   * @throws Exception if the evaluator has not been 
   * generated successfully
   */
  public void buildEvaluator (Instances data)
    throws Exception {
    
    int z, totalInstances;
<span class="nc" id="L649">    Random r = new Random(m_seed);</span>

    // can evaluator handle data?
<span class="nc" id="L652">    getCapabilities().testWithFail(data);</span>

<span class="nc" id="L654">    m_trainInstances = data;</span>
<span class="nc" id="L655">    m_classIndex = m_trainInstances.classIndex();</span>
<span class="nc" id="L656">    m_numAttribs = m_trainInstances.numAttributes();</span>
<span class="nc" id="L657">    m_numInstances = m_trainInstances.numInstances();</span>

<span class="nc bnc" id="L659" title="All 2 branches missed.">    if (m_trainInstances.attribute(m_classIndex).isNumeric()) {</span>
<span class="nc" id="L660">      m_numericClass = true;</span>
    }
    else {
<span class="nc" id="L663">      m_numericClass = false;</span>
    }

<span class="nc bnc" id="L666" title="All 2 branches missed.">    if (!m_numericClass) {</span>
<span class="nc" id="L667">      m_numClasses = m_trainInstances.attribute(m_classIndex).numValues();</span>
    }
    else {
<span class="nc" id="L670">      m_ndc = 0;</span>
<span class="nc" id="L671">      m_numClasses = 1;</span>
<span class="nc" id="L672">      m_nda = new double[m_numAttribs];</span>
<span class="nc" id="L673">      m_ndcda = new double[m_numAttribs];</span>
    }

<span class="nc bnc" id="L676" title="All 2 branches missed.">    if (m_weightByDistance) // set up the rank based weights</span>
      {
<span class="nc" id="L678">        m_weightsByRank = new double[m_Knn];</span>

<span class="nc bnc" id="L680" title="All 2 branches missed.">        for (int i = 0; i &lt; m_Knn; i++) {</span>
<span class="nc" id="L681">          m_weightsByRank[i] = </span>
<span class="nc" id="L682">            Math.exp(-((i/(double)m_sigma)*(i/(double)m_sigma)));</span>
        }
      }

    // the final attribute weights
<span class="nc" id="L687">    m_weights = new double[m_numAttribs];</span>
    // num classes (1 for numeric class) knn neighbours, 
    // and 0 = distance, 1 = instance index
<span class="nc" id="L690">    m_karray = new double[m_numClasses][m_Knn][2];</span>

<span class="nc bnc" id="L692" title="All 2 branches missed.">    if (!m_numericClass) {</span>
<span class="nc" id="L693">      m_classProbs = new double[m_numClasses];</span>

<span class="nc bnc" id="L695" title="All 2 branches missed.">      for (int i = 0; i &lt; m_numInstances; i++) {</span>
<span class="nc" id="L696">        m_classProbs[(int)m_trainInstances.instance(i).value(m_classIndex)]++;</span>
      }

<span class="nc bnc" id="L699" title="All 2 branches missed.">      for (int i = 0; i &lt; m_numClasses; i++) {</span>
<span class="nc" id="L700">        m_classProbs[i] /= m_numInstances;</span>
      }
    }

<span class="nc" id="L704">    m_worst = new double[m_numClasses];</span>
<span class="nc" id="L705">    m_index = new int[m_numClasses];</span>
<span class="nc" id="L706">    m_stored = new int[m_numClasses];</span>
<span class="nc" id="L707">    m_minArray = new double[m_numAttribs];</span>
<span class="nc" id="L708">    m_maxArray = new double[m_numAttribs];</span>

<span class="nc bnc" id="L710" title="All 2 branches missed.">    for (int i = 0; i &lt; m_numAttribs; i++) {</span>
<span class="nc" id="L711">      m_minArray[i] = m_maxArray[i] = Double.NaN;</span>
    }

<span class="nc bnc" id="L714" title="All 2 branches missed.">    for (int i = 0; i &lt; m_numInstances; i++) {</span>
<span class="nc" id="L715">      updateMinMax(m_trainInstances.instance(i));</span>
    }
    
<span class="nc bnc" id="L718" title="All 4 branches missed.">    if ((m_sampleM &gt; m_numInstances) || (m_sampleM &lt; 0)) {</span>
<span class="nc" id="L719">      totalInstances = m_numInstances;</span>
    }
    else {
<span class="nc" id="L722">      totalInstances = m_sampleM;</span>
    }

    // process each instance, updating attribute weights
<span class="nc bnc" id="L726" title="All 2 branches missed.">    for (int i = 0; i &lt; totalInstances; i++) {</span>
<span class="nc bnc" id="L727" title="All 2 branches missed.">      if (totalInstances == m_numInstances) {</span>
<span class="nc" id="L728">        z = i;</span>
      }
      else {
<span class="nc" id="L731">        z = r.nextInt()%m_numInstances;</span>
      }

<span class="nc bnc" id="L734" title="All 2 branches missed.">      if (z &lt; 0) {</span>
<span class="nc" id="L735">        z *= -1;</span>
      }

<span class="nc bnc" id="L738" title="All 2 branches missed.">      if (!(m_trainInstances.instance(z).isMissing(m_classIndex))) {</span>
        // first clear the knn and worst index stuff for the classes
<span class="nc bnc" id="L740" title="All 2 branches missed.">        for (int j = 0; j &lt; m_numClasses; j++) {</span>
<span class="nc" id="L741">          m_index[j] = m_stored[j] = 0;</span>

<span class="nc bnc" id="L743" title="All 2 branches missed.">          for (int k = 0; k &lt; m_Knn; k++) {</span>
<span class="nc" id="L744">            m_karray[j][k][0] = m_karray[j][k][1] = 0;</span>
          }
        }

<span class="nc" id="L748">        findKHitMiss(z);</span>

<span class="nc bnc" id="L750" title="All 2 branches missed.">        if (m_numericClass) {</span>
<span class="nc" id="L751">          updateWeightsNumericClass(z);</span>
        }
        else {
<span class="nc" id="L754">          updateWeightsDiscreteClass(z);</span>
        }
      }
    }

    // now scale weights by 1/m_numInstances (nominal class) or
    // calculate weights numeric class
    // System.out.println(&quot;num inst:&quot;+m_numInstances+&quot; r_ndc:&quot;+r_ndc);
<span class="nc bnc" id="L762" title="All 4 branches missed.">    for (int i = 0; i &lt; m_numAttribs; i++) {if (i != m_classIndex) {</span>
<span class="nc bnc" id="L763" title="All 2 branches missed.">      if (m_numericClass) {</span>
<span class="nc" id="L764">        m_weights[i] = m_ndcda[i]/m_ndc - </span>
<span class="nc" id="L765">          ((m_nda[i] - m_ndcda[i])/((double)totalInstances - m_ndc));</span>
      }
      else {
<span class="nc" id="L768">        m_weights[i] *= (1.0/(double)totalInstances);</span>
      }

      //          System.out.println(r_weights[i]);
    }
    }
<span class="nc" id="L774">  }</span>


  /**
   * Evaluates an individual attribute using ReliefF's instance based approach.
   * The actual work is done by buildEvaluator which evaluates all features.
   *
   * @param attribute the index of the attribute to be evaluated
   * @throws Exception if the attribute could not be evaluated
   */
  public double evaluateAttribute (int attribute)
    throws Exception {
<span class="nc" id="L786">    return  m_weights[attribute];</span>
  }


  /**
   * Reset options to their default values
   */
  protected void resetOptions () {
<span class="nc" id="L794">    m_trainInstances = null;</span>
<span class="nc" id="L795">    m_sampleM = -1;</span>
<span class="nc" id="L796">    m_Knn = 10;</span>
<span class="nc" id="L797">    m_sigma = 2;</span>
<span class="nc" id="L798">    m_weightByDistance = false;</span>
<span class="nc" id="L799">    m_seed = 1;</span>
<span class="nc" id="L800">  }</span>


  /**
   * Normalizes a given value of a numeric attribute.
   *
   * @param x the value to be normalized
   * @param i the attribute's index
   * @return the normalized value
   */
  private double norm (double x, int i) {
<span class="nc bnc" id="L811" title="All 2 branches missed.">    if (Double.isNaN(m_minArray[i]) || </span>
<span class="nc bnc" id="L812" title="All 2 branches missed.">        Utils.eq(m_maxArray[i], m_minArray[i])) {</span>
<span class="nc" id="L813">      return  0;</span>
    }
    else {
<span class="nc" id="L816">      return  (x - m_minArray[i])/(m_maxArray[i] - m_minArray[i]);</span>
    }
  }


  /**
   * Updates the minimum and maximum values for all the attributes
   * based on a new instance.
   *
   * @param instance the new instance
   */
  private void updateMinMax (Instance instance) {
    //    for (int j = 0; j &lt; m_numAttribs; j++) {
    try {
<span class="nc bnc" id="L830" title="All 2 branches missed.">      for (int j = 0; j &lt; instance.numValues(); j++) {</span>
<span class="nc bnc" id="L831" title="All 2 branches missed.">        if ((instance.attributeSparse(j).isNumeric()) &amp;&amp; </span>
<span class="nc bnc" id="L832" title="All 2 branches missed.">            (!instance.isMissingSparse(j))) {</span>
<span class="nc bnc" id="L833" title="All 2 branches missed.">          if (Double.isNaN(m_minArray[instance.index(j)])) {</span>
<span class="nc" id="L834">            m_minArray[instance.index(j)] = instance.valueSparse(j);</span>
<span class="nc" id="L835">            m_maxArray[instance.index(j)] = instance.valueSparse(j);</span>
          }
        else {
<span class="nc bnc" id="L838" title="All 2 branches missed.">          if (instance.valueSparse(j) &lt; m_minArray[instance.index(j)]) {</span>
<span class="nc" id="L839">            m_minArray[instance.index(j)] = instance.valueSparse(j);</span>
          }
          else {
<span class="nc bnc" id="L842" title="All 2 branches missed.">            if (instance.valueSparse(j) &gt; m_maxArray[instance.index(j)]) {</span>
<span class="nc" id="L843">              m_maxArray[instance.index(j)] = instance.valueSparse(j);</span>
            }
          }
        }
        }
      }
<span class="nc" id="L849">    } catch (Exception ex) {</span>
<span class="nc" id="L850">      System.err.println(ex);</span>
<span class="nc" id="L851">      ex.printStackTrace();</span>
    }
<span class="nc" id="L853">  }</span>

  /**
   * Computes the difference between two given attribute
   * values.
   */
  private double difference(int index, double val1, double val2) {

<span class="nc bnc" id="L861" title="All 3 branches missed.">    switch (m_trainInstances.attribute(index).type()) {</span>
    case Attribute.NOMINAL:
      
      // If attribute is nominal
<span class="nc bnc" id="L865" title="All 2 branches missed.">      if (Instance.isMissingValue(val1) || </span>
<span class="nc bnc" id="L866" title="All 2 branches missed.">          Instance.isMissingValue(val2)) {</span>
<span class="nc" id="L867">        return (1.0 - (1.0/((double)m_trainInstances.</span>
<span class="nc" id="L868">                            attribute(index).numValues())));</span>
<span class="nc bnc" id="L869" title="All 2 branches missed.">      } else if ((int)val1 != (int)val2) {</span>
<span class="nc" id="L870">        return 1;</span>
      } else {
<span class="nc" id="L872">        return 0;</span>
      }
    case Attribute.NUMERIC:

      // If attribute is numeric
<span class="nc bnc" id="L877" title="All 2 branches missed.">      if (Instance.isMissingValue(val1) || </span>
<span class="nc bnc" id="L878" title="All 2 branches missed.">          Instance.isMissingValue(val2)) {</span>
<span class="nc bnc" id="L879" title="All 2 branches missed.">        if (Instance.isMissingValue(val1) &amp;&amp; </span>
<span class="nc bnc" id="L880" title="All 2 branches missed.">            Instance.isMissingValue(val2)) {</span>
<span class="nc" id="L881">          return 1;</span>
        } else {
          double diff;
<span class="nc bnc" id="L884" title="All 2 branches missed.">          if (Instance.isMissingValue(val2)) {</span>
<span class="nc" id="L885">            diff = norm(val1, index);</span>
          } else {
<span class="nc" id="L887">            diff = norm(val2, index);</span>
          }
<span class="nc bnc" id="L889" title="All 2 branches missed.">          if (diff &lt; 0.5) {</span>
<span class="nc" id="L890">            diff = 1.0 - diff;</span>
          }
<span class="nc" id="L892">          return diff;</span>
        }
      } else {
<span class="nc" id="L895">        return Math.abs(norm(val1, index) - norm(val2, index));</span>
      }
    default:
<span class="nc" id="L898">      return 0;</span>
    }
  }

  /**
   * Calculates the distance between two instances
   *
   * @param first the first instance
   * @param second the second instance
   * @return the distance between the two given instances, between 0 and 1
   */          
  private double distance(Instance first, Instance second) {  

<span class="nc" id="L911">    double distance = 0;</span>
    int firstI, secondI;

<span class="nc" id="L914">    for (int p1 = 0, p2 = 0; </span>
<span class="nc bnc" id="L915" title="All 4 branches missed.">         p1 &lt; first.numValues() || p2 &lt; second.numValues();) {</span>
<span class="nc bnc" id="L916" title="All 2 branches missed.">      if (p1 &gt;= first.numValues()) {</span>
<span class="nc" id="L917">        firstI = m_trainInstances.numAttributes();</span>
      } else {
<span class="nc" id="L919">        firstI = first.index(p1); </span>
      }
<span class="nc bnc" id="L921" title="All 2 branches missed.">      if (p2 &gt;= second.numValues()) {</span>
<span class="nc" id="L922">        secondI = m_trainInstances.numAttributes();</span>
      } else {
<span class="nc" id="L924">        secondI = second.index(p2);</span>
      }
<span class="nc bnc" id="L926" title="All 2 branches missed.">      if (firstI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L927">        p1++; continue;</span>
      } 
<span class="nc bnc" id="L929" title="All 2 branches missed.">      if (secondI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L930">        p2++; continue;</span>
      } 
      double diff;
<span class="nc bnc" id="L933" title="All 2 branches missed.">      if (firstI == secondI) {</span>
<span class="nc" id="L934">        diff = difference(firstI, </span>
<span class="nc" id="L935">                          first.valueSparse(p1),</span>
<span class="nc" id="L936">                          second.valueSparse(p2));</span>
<span class="nc" id="L937">        p1++; p2++;</span>
<span class="nc bnc" id="L938" title="All 2 branches missed.">      } else if (firstI &gt; secondI) {</span>
<span class="nc" id="L939">        diff = difference(secondI, </span>
<span class="nc" id="L940">                          0, second.valueSparse(p2));</span>
<span class="nc" id="L941">        p2++;</span>
      } else {
<span class="nc" id="L943">        diff = difference(firstI, </span>
<span class="nc" id="L944">                          first.valueSparse(p1), 0);</span>
<span class="nc" id="L945">        p1++;</span>
      }
      //      distance += diff * diff;
<span class="nc" id="L948">      distance += diff;</span>
    }
    
    //    return Math.sqrt(distance / m_NumAttributesUsed);
<span class="nc" id="L952">    return distance;</span>
  }


  /**
   * update attribute weights given an instance when the class is numeric
   *
   * @param instNum the index of the instance to use when updating weights
   */
  private void updateWeightsNumericClass (int instNum) {
    int i, j;
    double temp,temp2;
<span class="nc" id="L964">    int[] tempSorted = null;</span>
<span class="nc" id="L965">    double[] tempDist = null;</span>
<span class="nc" id="L966">    double distNorm = 1.0;</span>
    int firstI, secondI;

<span class="nc" id="L969">    Instance inst = m_trainInstances.instance(instNum);</span>
   
    // sort nearest neighbours and set up normalization variable
<span class="nc bnc" id="L972" title="All 2 branches missed.">    if (m_weightByDistance) {</span>
<span class="nc" id="L973">      tempDist = new double[m_stored[0]];</span>

<span class="nc bnc" id="L975" title="All 2 branches missed.">      for (j = 0, distNorm = 0; j &lt; m_stored[0]; j++) {</span>
        // copy the distances
<span class="nc" id="L977">        tempDist[j] = m_karray[0][j][0];</span>
        // sum normalizer
<span class="nc" id="L979">        distNorm += m_weightsByRank[j];</span>
      }

<span class="nc" id="L982">      tempSorted = Utils.sort(tempDist);</span>
    }

<span class="nc bnc" id="L985" title="All 2 branches missed.">    for (i = 0; i &lt; m_stored[0]; i++) {</span>
      // P diff prediction (class) given nearest instances
<span class="nc bnc" id="L987" title="All 2 branches missed.">      if (m_weightByDistance) {</span>
<span class="nc" id="L988">        temp = difference(m_classIndex, </span>
<span class="nc" id="L989">                          inst.value(m_classIndex),</span>
<span class="nc" id="L990">                          m_trainInstances.</span>
<span class="nc" id="L991">                          instance((int)m_karray[0][tempSorted[i]][1]).</span>
<span class="nc" id="L992">                          value(m_classIndex));</span>
<span class="nc" id="L993">        temp *= (m_weightsByRank[i]/distNorm);</span>
      }
      else {
<span class="nc" id="L996">        temp = difference(m_classIndex, </span>
<span class="nc" id="L997">                          inst.value(m_classIndex), </span>
<span class="nc" id="L998">                          m_trainInstances.</span>
<span class="nc" id="L999">                          instance((int)m_karray[0][i][1]).</span>
<span class="nc" id="L1000">                          value(m_classIndex));</span>
<span class="nc" id="L1001">        temp *= (1.0/(double)m_stored[0]); // equal influence</span>
      }

<span class="nc" id="L1004">      m_ndc += temp;</span>

      Instance cmp;
<span class="nc bnc" id="L1007" title="All 2 branches missed.">      cmp = (m_weightByDistance) </span>
<span class="nc" id="L1008">        ? m_trainInstances.instance((int)m_karray[0][tempSorted[i]][1])</span>
<span class="nc" id="L1009">        : m_trainInstances.instance((int)m_karray[0][i][1]);</span>
 
<span class="nc" id="L1011">      double temp_diffP_diffA_givNearest = </span>
<span class="nc" id="L1012">        difference(m_classIndex, inst.value(m_classIndex),</span>
<span class="nc" id="L1013">                   cmp.value(m_classIndex));</span>
      // now the attributes
<span class="nc" id="L1015">      for (int p1 = 0, p2 = 0; </span>
<span class="nc bnc" id="L1016" title="All 4 branches missed.">           p1 &lt; inst.numValues() || p2 &lt; cmp.numValues();) {</span>
<span class="nc bnc" id="L1017" title="All 2 branches missed.">        if (p1 &gt;= inst.numValues()) {</span>
<span class="nc" id="L1018">          firstI = m_trainInstances.numAttributes();</span>
        } else {
<span class="nc" id="L1020">          firstI = inst.index(p1); </span>
        }
<span class="nc bnc" id="L1022" title="All 2 branches missed.">        if (p2 &gt;= cmp.numValues()) {</span>
<span class="nc" id="L1023">          secondI = m_trainInstances.numAttributes();</span>
        } else {
<span class="nc" id="L1025">          secondI = cmp.index(p2);</span>
        }
<span class="nc bnc" id="L1027" title="All 2 branches missed.">        if (firstI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1028">          p1++; continue;</span>
        } 
<span class="nc bnc" id="L1030" title="All 2 branches missed.">        if (secondI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1031">          p2++; continue;</span>
        } 
<span class="nc" id="L1033">        temp = 0.0;</span>
<span class="nc" id="L1034">        temp2 = 0.0;</span>
      
<span class="nc bnc" id="L1036" title="All 2 branches missed.">        if (firstI == secondI) {</span>
<span class="nc" id="L1037">          j = firstI;</span>
<span class="nc" id="L1038">          temp = difference(j, inst.valueSparse(p1), cmp.valueSparse(p2)); </span>
<span class="nc" id="L1039">          p1++;p2++;</span>
<span class="nc bnc" id="L1040" title="All 2 branches missed.">        } else if (firstI &gt; secondI) {</span>
<span class="nc" id="L1041">          j = secondI;</span>
<span class="nc" id="L1042">          temp = difference(j, 0, cmp.valueSparse(p2));</span>
<span class="nc" id="L1043">          p2++;</span>
        } else {
<span class="nc" id="L1045">          j = firstI;</span>
<span class="nc" id="L1046">          temp = difference(j, inst.valueSparse(p1), 0);</span>
<span class="nc" id="L1047">          p1++;</span>
        } 
       
<span class="nc" id="L1050">        temp2 = temp_diffP_diffA_givNearest * temp; </span>
        // P of different prediction and different att value given
        // nearest instances
<span class="nc bnc" id="L1053" title="All 2 branches missed.">        if (m_weightByDistance) {</span>
<span class="nc" id="L1054">          temp2 *= (m_weightsByRank[i]/distNorm);</span>
        }
        else {
<span class="nc" id="L1057">          temp2 *= (1.0/(double)m_stored[0]); // equal influence</span>
        }

<span class="nc" id="L1060">        m_ndcda[j] += temp2;</span>
       
        // P of different attribute val given nearest instances
<span class="nc bnc" id="L1063" title="All 2 branches missed.">        if (m_weightByDistance) {</span>
<span class="nc" id="L1064">          temp *= (m_weightsByRank[i]/distNorm);</span>
        }
        else {
<span class="nc" id="L1067">          temp *= (1.0/(double)m_stored[0]); // equal influence</span>
        }

<span class="nc" id="L1070">        m_nda[j] += temp;</span>
      }
    }
<span class="nc" id="L1073">  }</span>


  /**
   * update attribute weights given an instance when the class is discrete
   *
   * @param instNum the index of the instance to use when updating weights
   */
  private void updateWeightsDiscreteClass (int instNum) {
    int i, j, k;
    int cl;
<span class="nc" id="L1084">    double temp_diff, w_norm = 1.0;</span>
    double[] tempDistClass;
<span class="nc" id="L1086">    int[] tempSortedClass = null;</span>
<span class="nc" id="L1087">    double distNormClass = 1.0;</span>
    double[] tempDistAtt;
<span class="nc" id="L1089">    int[][] tempSortedAtt = null;</span>
<span class="nc" id="L1090">    double[] distNormAtt = null;</span>
    int firstI, secondI;

    // store the indexes (sparse instances) of non-zero elements
<span class="nc" id="L1094">    Instance inst = m_trainInstances.instance(instNum);</span>

    // get the class of this instance
<span class="nc" id="L1097">    cl = (int)m_trainInstances.instance(instNum).value(m_classIndex);</span>

    // sort nearest neighbours and set up normalization variables
<span class="nc bnc" id="L1100" title="All 2 branches missed.">    if (m_weightByDistance) {</span>
      // do class (hits) first
      // sort the distances
<span class="nc" id="L1103">      tempDistClass = new double[m_stored[cl]];</span>

<span class="nc bnc" id="L1105" title="All 2 branches missed.">      for (j = 0, distNormClass = 0; j &lt; m_stored[cl]; j++) {</span>
        // copy the distances
<span class="nc" id="L1107">        tempDistClass[j] = m_karray[cl][j][0];</span>
        // sum normalizer
<span class="nc" id="L1109">        distNormClass += m_weightsByRank[j];</span>
      }

<span class="nc" id="L1112">      tempSortedClass = Utils.sort(tempDistClass);</span>
      // do misses (other classes)
<span class="nc" id="L1114">      tempSortedAtt = new int[m_numClasses][1];</span>
<span class="nc" id="L1115">      distNormAtt = new double[m_numClasses];</span>

<span class="nc bnc" id="L1117" title="All 2 branches missed.">      for (k = 0; k &lt; m_numClasses; k++) {</span>
<span class="nc bnc" id="L1118" title="All 2 branches missed.">        if (k != cl) // already done cl</span>
          {
            // sort the distances
<span class="nc" id="L1121">            tempDistAtt = new double[m_stored[k]];</span>

<span class="nc bnc" id="L1123" title="All 2 branches missed.">            for (j = 0, distNormAtt[k] = 0; j &lt; m_stored[k]; j++) {</span>
              // copy the distances
<span class="nc" id="L1125">              tempDistAtt[j] = m_karray[k][j][0];</span>
              // sum normalizer
<span class="nc" id="L1127">              distNormAtt[k] += m_weightsByRank[j];</span>
            }

<span class="nc" id="L1130">            tempSortedAtt[k] = Utils.sort(tempDistAtt);</span>
          }
      }
    }

<span class="nc bnc" id="L1135" title="All 2 branches missed.">    if (m_numClasses &gt; 2) {</span>
      // the amount of probability space left after removing the
      // probability of this instance's class value
<span class="nc" id="L1138">      w_norm = (1.0 - m_classProbs[cl]);</span>
    }
    
    // do the k nearest hits of the same class
<span class="nc bnc" id="L1142" title="All 2 branches missed.">    for (j = 0, temp_diff = 0.0; j &lt; m_stored[cl]; j++) {</span>
      Instance cmp;
<span class="nc bnc" id="L1144" title="All 2 branches missed.">      cmp = (m_weightByDistance) </span>
<span class="nc" id="L1145">        ? m_trainInstances.</span>
<span class="nc" id="L1146">        instance((int)m_karray[cl][tempSortedClass[j]][1])</span>
<span class="nc" id="L1147">        : m_trainInstances.instance((int)m_karray[cl][j][1]);</span>

<span class="nc" id="L1149">      for (int p1 = 0, p2 = 0; </span>
<span class="nc bnc" id="L1150" title="All 4 branches missed.">           p1 &lt; inst.numValues() || p2 &lt; cmp.numValues();) {</span>
<span class="nc bnc" id="L1151" title="All 2 branches missed.">        if (p1 &gt;= inst.numValues()) {</span>
<span class="nc" id="L1152">          firstI = m_trainInstances.numAttributes();</span>
        } else {
<span class="nc" id="L1154">          firstI = inst.index(p1); </span>
        }
<span class="nc bnc" id="L1156" title="All 2 branches missed.">        if (p2 &gt;= cmp.numValues()) {</span>
<span class="nc" id="L1157">          secondI = m_trainInstances.numAttributes();</span>
        } else {
<span class="nc" id="L1159">          secondI = cmp.index(p2);</span>
        }
<span class="nc bnc" id="L1161" title="All 2 branches missed.">        if (firstI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1162">          p1++; continue;</span>
        } 
<span class="nc bnc" id="L1164" title="All 2 branches missed.">        if (secondI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1165">          p2++; continue;</span>
        } 
<span class="nc bnc" id="L1167" title="All 2 branches missed.">        if (firstI == secondI) {</span>
<span class="nc" id="L1168">          i = firstI;</span>
<span class="nc" id="L1169">          temp_diff = difference(i, inst.valueSparse(p1), </span>
<span class="nc" id="L1170">                                 cmp.valueSparse(p2)); </span>
<span class="nc" id="L1171">          p1++;p2++;</span>
<span class="nc bnc" id="L1172" title="All 2 branches missed.">        } else if (firstI &gt; secondI) {</span>
<span class="nc" id="L1173">          i = secondI;</span>
<span class="nc" id="L1174">          temp_diff = difference(i, 0, cmp.valueSparse(p2));</span>
<span class="nc" id="L1175">          p2++;</span>
        } else {
<span class="nc" id="L1177">          i = firstI;</span>
<span class="nc" id="L1178">          temp_diff = difference(i, inst.valueSparse(p1), 0);</span>
<span class="nc" id="L1179">          p1++;</span>
        } 
        
<span class="nc bnc" id="L1182" title="All 2 branches missed.">        if (m_weightByDistance) {</span>
<span class="nc" id="L1183">          temp_diff *=</span>
<span class="nc" id="L1184">            (m_weightsByRank[j]/distNormClass);</span>
        } else {
<span class="nc bnc" id="L1186" title="All 2 branches missed.">          if (m_stored[cl] &gt; 0) {</span>
<span class="nc" id="L1187">            temp_diff /= (double)m_stored[cl];</span>
          }
        }
<span class="nc" id="L1190">        m_weights[i] -= temp_diff;</span>

      }
    }
      

    // now do k nearest misses from each of the other classes
<span class="nc" id="L1197">    temp_diff = 0.0;</span>

<span class="nc bnc" id="L1199" title="All 2 branches missed.">    for (k = 0; k &lt; m_numClasses; k++) {</span>
<span class="nc bnc" id="L1200" title="All 2 branches missed.">      if (k != cl) // already done cl</span>
        {
<span class="nc bnc" id="L1202" title="All 2 branches missed.">          for (j = 0; j &lt; m_stored[k]; j++) {</span>
            Instance cmp;
<span class="nc bnc" id="L1204" title="All 2 branches missed.">            cmp = (m_weightByDistance) </span>
<span class="nc" id="L1205">              ? m_trainInstances.</span>
<span class="nc" id="L1206">              instance((int)m_karray[k][tempSortedAtt[k][j]][1])</span>
<span class="nc" id="L1207">              : m_trainInstances.instance((int)m_karray[k][j][1]);</span>
        
<span class="nc" id="L1209">            for (int p1 = 0, p2 = 0; </span>
<span class="nc bnc" id="L1210" title="All 4 branches missed.">                 p1 &lt; inst.numValues() || p2 &lt; cmp.numValues();) {</span>
<span class="nc bnc" id="L1211" title="All 2 branches missed.">              if (p1 &gt;= inst.numValues()) {</span>
<span class="nc" id="L1212">                firstI = m_trainInstances.numAttributes();</span>
              } else {
<span class="nc" id="L1214">                firstI = inst.index(p1); </span>
              }
<span class="nc bnc" id="L1216" title="All 2 branches missed.">              if (p2 &gt;= cmp.numValues()) {</span>
<span class="nc" id="L1217">                secondI = m_trainInstances.numAttributes();</span>
              } else {
<span class="nc" id="L1219">                secondI = cmp.index(p2);</span>
              }
<span class="nc bnc" id="L1221" title="All 2 branches missed.">              if (firstI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1222">                p1++; continue;</span>
              } 
<span class="nc bnc" id="L1224" title="All 2 branches missed.">              if (secondI == m_trainInstances.classIndex()) {</span>
<span class="nc" id="L1225">                p2++; continue;</span>
              } 
<span class="nc bnc" id="L1227" title="All 2 branches missed.">              if (firstI == secondI) {</span>
<span class="nc" id="L1228">                i = firstI;</span>
<span class="nc" id="L1229">                temp_diff = difference(i, inst.valueSparse(p1), </span>
<span class="nc" id="L1230">                                       cmp.valueSparse(p2)); </span>
<span class="nc" id="L1231">                p1++;p2++;</span>
<span class="nc bnc" id="L1232" title="All 2 branches missed.">              } else if (firstI &gt; secondI) {</span>
<span class="nc" id="L1233">                i = secondI;</span>
<span class="nc" id="L1234">                temp_diff = difference(i, 0, cmp.valueSparse(p2));</span>
<span class="nc" id="L1235">                p2++;</span>
              } else {
<span class="nc" id="L1237">                i = firstI;</span>
<span class="nc" id="L1238">                temp_diff = difference(i, inst.valueSparse(p1), 0);</span>
<span class="nc" id="L1239">                p1++;</span>
              } 

<span class="nc bnc" id="L1242" title="All 2 branches missed.">              if (m_weightByDistance) {</span>
<span class="nc" id="L1243">                temp_diff *=</span>
<span class="nc" id="L1244">                  (m_weightsByRank[j]/distNormAtt[k]);</span>
              }
              else {
<span class="nc bnc" id="L1247" title="All 2 branches missed.">                if (m_stored[k] &gt; 0) {</span>
<span class="nc" id="L1248">                  temp_diff /= (double)m_stored[k];</span>
                }
              }
<span class="nc bnc" id="L1251" title="All 2 branches missed.">              if (m_numClasses &gt; 2) {</span>
<span class="nc" id="L1252">                m_weights[i] += ((m_classProbs[k]/w_norm)*temp_diff);</span>
              } else {
<span class="nc" id="L1254">                m_weights[i] += temp_diff;</span>
              }
            }
          }
        }
    }
<span class="nc" id="L1260">  }</span>


  /**
   * Find the K nearest instances to supplied instance if the class is numeric,
   * or the K nearest Hits (same class) and Misses (K from each of the other
   * classes) if the class is discrete.
   *
   * @param instNum the index of the instance to find nearest neighbours of
   */
  private void findKHitMiss (int instNum) {
    int i, j;
    int cl;
    double ww;
<span class="nc" id="L1274">    double temp_diff = 0.0;</span>
<span class="nc" id="L1275">    Instance thisInst = m_trainInstances.instance(instNum);</span>

<span class="nc bnc" id="L1277" title="All 2 branches missed.">    for (i = 0; i &lt; m_numInstances; i++) {</span>
<span class="nc bnc" id="L1278" title="All 2 branches missed.">      if (i != instNum) {</span>
<span class="nc" id="L1279">        Instance cmpInst = m_trainInstances.instance(i);</span>
<span class="nc" id="L1280">        temp_diff = distance(cmpInst, thisInst);</span>

        // class of this training instance or 0 if numeric
<span class="nc bnc" id="L1283" title="All 2 branches missed.">        if (m_numericClass) {</span>
<span class="nc" id="L1284">          cl = 0;</span>
        }
        else {
<span class="nc" id="L1287">          cl = (int)m_trainInstances.instance(i).value(m_classIndex);</span>
        }

        // add this diff to the list for the class of this instance
<span class="nc bnc" id="L1291" title="All 2 branches missed.">        if (m_stored[cl] &lt; m_Knn) {</span>
<span class="nc" id="L1292">          m_karray[cl][m_stored[cl]][0] = temp_diff;</span>
<span class="nc" id="L1293">          m_karray[cl][m_stored[cl]][1] = i;</span>
<span class="nc" id="L1294">          m_stored[cl]++;</span>

          // note the worst diff for this class
<span class="nc bnc" id="L1297" title="All 2 branches missed.">          for (j = 0, ww = -1.0; j &lt; m_stored[cl]; j++) {</span>
<span class="nc bnc" id="L1298" title="All 2 branches missed.">            if (m_karray[cl][j][0] &gt; ww) {</span>
<span class="nc" id="L1299">              ww = m_karray[cl][j][0];</span>
<span class="nc" id="L1300">              m_index[cl] = j;</span>
            }
          }

<span class="nc" id="L1304">          m_worst[cl] = ww;</span>
        }
        else 
          /* if we already have stored knn for this class then check to
             see if this instance is better than the worst */
          {
<span class="nc bnc" id="L1310" title="All 2 branches missed.">            if (temp_diff &lt; m_karray[cl][m_index[cl]][0]) {</span>
<span class="nc" id="L1311">              m_karray[cl][m_index[cl]][0] = temp_diff;</span>
<span class="nc" id="L1312">              m_karray[cl][m_index[cl]][1] = i;</span>

<span class="nc bnc" id="L1314" title="All 2 branches missed.">              for (j = 0, ww = -1.0; j &lt; m_stored[cl]; j++) {</span>
<span class="nc bnc" id="L1315" title="All 2 branches missed.">                if (m_karray[cl][j][0] &gt; ww) {</span>
<span class="nc" id="L1316">                  ww = m_karray[cl][j][0];</span>
<span class="nc" id="L1317">                  m_index[cl] = j;</span>
                }
              }

<span class="nc" id="L1321">              m_worst[cl] = ww;</span>
            }
          }
      }
    }
<span class="nc" id="L1326">  }</span>
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L1334">    return RevisionUtils.extract(&quot;$Revision: 5511 $&quot;);</span>
  }

  // ============
  // Test method.
  // ============
  /**
   * Main method for testing this class.
   *
   * @param args the options
   */
  public static void main (String[] args) {
<span class="nc" id="L1346">    runEvaluator(new ReliefFAttributeEval(), args);</span>
<span class="nc" id="L1347">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>