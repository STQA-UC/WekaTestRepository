<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>RegressionByDiscretization.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.meta</a> &gt; <span class="el_source">RegressionByDiscretization.java</span></div><h1>RegressionByDiscretization.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    RegressionByDiscretization.java
 *    Copyright (C) 1999 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.classifiers.meta;

import weka.classifiers.SingleClassifierEnhancer;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Attribute;
import weka.core.FastVector;
import weka.core.Option;
import weka.core.RevisionUtils;
import weka.core.Utils;
import weka.core.Capabilities.Capability;
import weka.filters.Filter;
import weka.filters.unsupervised.attribute.Discretize;

import java.util.Enumeration;
import java.util.Vector;

/**
 &lt;!-- globalinfo-start --&gt;
 * A regression scheme that employs any classifier on a copy of the data that has the class attribute (equal-width) discretized. The predicted value is the expected value of the mean class value for each discretized interval (based on the predicted probabilities for each interval).
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -B &amp;lt;int&amp;gt;
 *  Number of bins for equal-width discretization
 *  (default 10).
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -E
 *  Whether to delete empty bins after discretization
 *  (default false).
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -F
 *  Use equal-frequency instead of equal-width discretization.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 * &lt;pre&gt; -W
 *  Full name of base classifier.
 *  (default: weka.classifiers.trees.J48)&lt;/pre&gt;
 * 
 * &lt;pre&gt; 
 * Options specific to classifier weka.classifiers.trees.J48:
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -U
 *  Use unpruned tree.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -C &amp;lt;pruning confidence&amp;gt;
 *  Set confidence threshold for pruning.
 *  (default 0.25)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -M &amp;lt;minimum number of instances&amp;gt;
 *  Set minimum number of instances per leaf.
 *  (default 2)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -R
 *  Use reduced error pruning.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -N &amp;lt;number of folds&amp;gt;
 *  Set number of folds for reduced error
 *  pruning. One fold is used as pruning set.
 *  (default 3)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -B
 *  Use binary splits only.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -S
 *  Don't perform subtree raising.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -L
 *  Do not clean up after the tree has been built.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -A
 *  Laplace smoothing for predicted probabilities.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -Q &amp;lt;seed&amp;gt;
 *  Seed for random data shuffling (default 1).&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Len Trigg (trigg@cs.waikato.ac.nz)
 * @author Eibe Frank (eibe@cs.waikato.ac.nz)
 * @version $Revision: 4746 $
 */
public class RegressionByDiscretization 
  extends SingleClassifierEnhancer {
  
  /** for serialization */
  static final long serialVersionUID = 5066426153134050378L;
  
  /** The discretization filter. */
<span class="fc" id="L122">  protected Discretize m_Discretizer = new Discretize();</span>

  /** The number of discretization intervals. */
<span class="fc" id="L125">  protected int m_NumBins = 10;</span>

  /** The mean values for each Discretized class interval. */
  protected double [] m_ClassMeans;

  /** Whether to delete empty intervals. */
  protected boolean m_DeleteEmptyBins;

  /** Header of discretized data. */
<span class="fc" id="L134">  protected Instances m_DiscretizedHeader = null;</span>

  /** Use equal-frequency binning */
<span class="fc" id="L137">  protected boolean m_UseEqualFrequency = false;</span>

  /**
   * Returns a string describing classifier
   * @return a description suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {

<span class="nc" id="L146">    return &quot;A regression scheme that employs any &quot;</span>
      + &quot;classifier on a copy of the data that has the class attribute (equal-width) &quot;
      + &quot;discretized. The predicted value is the expected value of the &quot;
      + &quot;mean class value for each discretized interval (based on the &quot;
      + &quot;predicted probabilities for each interval).&quot;;
  }

  /**
   * String describing default classifier.
   * 
   * @return the default classifier classname
   */
  protected String defaultClassifierString() {
    
<span class="fc" id="L160">    return &quot;weka.classifiers.trees.J48&quot;;</span>
  }

  /**
   * Default constructor.
   */
<span class="fc" id="L166">  public RegressionByDiscretization() {</span>

<span class="fc" id="L168">    m_Classifier = new weka.classifiers.trees.J48();</span>
<span class="fc" id="L169">  }</span>

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L177">    Capabilities result = super.getCapabilities();</span>

    // class
<span class="fc" id="L180">    result.disableAllClasses();</span>
<span class="fc" id="L181">    result.disableAllClassDependencies();</span>
<span class="fc" id="L182">    result.enable(Capability.NUMERIC_CLASS);</span>
<span class="fc" id="L183">    result.enable(Capability.DATE_CLASS);</span>
    
<span class="fc" id="L185">    result.setMinimumNumberInstances(2);</span>
    
<span class="fc" id="L187">    return result;</span>
  }

  /**
   * Generates the classifier.
   *
   * @param instances set of instances serving as training data 
   * @throws Exception if the classifier has not been generated successfully
   */
  public void buildClassifier(Instances instances) throws Exception {

    // can classifier handle the data?
<span class="fc" id="L199">    getCapabilities().testWithFail(instances);</span>

    // remove instances with missing class
<span class="fc" id="L202">    instances = new Instances(instances);</span>
<span class="fc" id="L203">    instances.deleteWithMissingClass();</span>
    
    // Discretize the training data
<span class="fc" id="L206">    m_Discretizer.setIgnoreClass(true);</span>
<span class="fc" id="L207">    m_Discretizer.setAttributeIndices(&quot;&quot; + (instances.classIndex() + 1));</span>
<span class="fc" id="L208">    m_Discretizer.setBins(getNumBins());</span>
<span class="fc" id="L209">    m_Discretizer.setUseEqualFrequency(getUseEqualFrequency());</span>
<span class="fc" id="L210">    m_Discretizer.setInputFormat(instances);</span>
<span class="fc" id="L211">    Instances newTrain = Filter.useFilter(instances, m_Discretizer);</span>

    // Should empty bins be deleted?
<span class="pc bpc" id="L214" title="1 of 2 branches missed.">    if (m_DeleteEmptyBins) {</span>

      // Figure out which classes are empty after discretization
<span class="nc" id="L217">      int numNonEmptyClasses = 0;</span>
<span class="nc" id="L218">      boolean[] notEmptyClass = new boolean[newTrain.numClasses()];</span>
<span class="nc bnc" id="L219" title="All 2 branches missed.">      for (int i = 0; i &lt; newTrain.numInstances(); i++) {</span>
<span class="nc bnc" id="L220" title="All 2 branches missed.">        if (!notEmptyClass[(int)newTrain.instance(i).classValue()]) {</span>
<span class="nc" id="L221">          numNonEmptyClasses++;</span>
<span class="nc" id="L222">          notEmptyClass[(int)newTrain.instance(i).classValue()] = true;</span>
        }
      }
      
      // Compute new list of non-empty classes and mapping of indices
<span class="nc" id="L227">      FastVector newClassVals = new FastVector(numNonEmptyClasses);</span>
<span class="nc" id="L228">      int[] oldIndexToNewIndex = new int[newTrain.numClasses()];</span>
<span class="nc bnc" id="L229" title="All 2 branches missed.">      for (int i = 0; i &lt; newTrain.numClasses(); i++) {</span>
<span class="nc bnc" id="L230" title="All 2 branches missed.">        if (notEmptyClass[i]) {</span>
<span class="nc" id="L231">          oldIndexToNewIndex[i] = newClassVals.size();</span>
<span class="nc" id="L232">          newClassVals.addElement(newTrain.classAttribute().value(i));</span>
        }
      }
      
      // Compute new header information
<span class="nc" id="L237">      Attribute newClass = new Attribute(newTrain.classAttribute().name(), </span>
<span class="nc" id="L238">                                         newClassVals);</span>
<span class="nc" id="L239">      FastVector newAttributes = new FastVector(newTrain.numAttributes());</span>
<span class="nc bnc" id="L240" title="All 2 branches missed.">      for (int i = 0; i &lt; newTrain.numAttributes(); i++) {</span>
<span class="nc bnc" id="L241" title="All 2 branches missed.">        if (i != newTrain.classIndex()) {</span>
<span class="nc" id="L242">          newAttributes.addElement(newTrain.attribute(i).copy());</span>
        } else {
<span class="nc" id="L244">          newAttributes.addElement(newClass);</span>
        }
      }
      
      // Create new header and modify instances
<span class="nc" id="L249">      Instances newTrainTransformed = new Instances(newTrain.relationName(), </span>
<span class="nc" id="L250">                                                    newAttributes,</span>
<span class="nc" id="L251">                                                    newTrain.numInstances());</span>
<span class="nc" id="L252">      newTrainTransformed.setClassIndex(newTrain.classIndex());</span>
<span class="nc bnc" id="L253" title="All 2 branches missed.">      for (int i = 0; i &lt; newTrain.numInstances(); i++) {</span>
<span class="nc" id="L254">        Instance inst = newTrain.instance(i);</span>
<span class="nc" id="L255">        newTrainTransformed.add(inst);</span>
<span class="nc" id="L256">        newTrainTransformed.lastInstance().</span>
<span class="nc" id="L257">          setClassValue(oldIndexToNewIndex[(int)inst.classValue()]);</span>
      }
<span class="nc" id="L259">      newTrain = newTrainTransformed;</span>
    }
<span class="fc" id="L261">    m_DiscretizedHeader = new Instances(newTrain, 0);</span>

<span class="fc" id="L263">    int numClasses = newTrain.numClasses();</span>

    // Calculate the mean value for each bin of the new class attribute
<span class="fc" id="L266">    m_ClassMeans = new double [numClasses];</span>
<span class="fc" id="L267">    int [] classCounts = new int [numClasses];</span>
<span class="fc bfc" id="L268" title="All 2 branches covered.">    for (int i = 0; i &lt; instances.numInstances(); i++) {</span>
<span class="fc" id="L269">      Instance inst = newTrain.instance(i);</span>
<span class="pc bpc" id="L270" title="1 of 2 branches missed.">      if (!inst.classIsMissing()) {</span>
<span class="fc" id="L271">	int classVal = (int) inst.classValue();</span>
<span class="fc" id="L272">	classCounts[classVal]++;</span>
<span class="fc" id="L273">	m_ClassMeans[classVal] += instances.instance(i).classValue();</span>
      }
    }

<span class="fc bfc" id="L277" title="All 2 branches covered.">    for (int i = 0; i &lt; numClasses; i++) {</span>
<span class="fc bfc" id="L278" title="All 2 branches covered.">      if (classCounts[i] &gt; 0) {</span>
<span class="fc" id="L279">	m_ClassMeans[i] /= classCounts[i];</span>
      }
    }

<span class="pc bpc" id="L283" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L284">      System.out.println(&quot;Bin Means&quot;);</span>
<span class="nc" id="L285">      System.out.println(&quot;==========&quot;);</span>
<span class="nc bnc" id="L286" title="All 2 branches missed.">      for (int i = 0; i &lt; m_ClassMeans.length; i++) {</span>
<span class="nc" id="L287">	System.out.println(m_ClassMeans[i]);</span>
      }
<span class="nc" id="L289">      System.out.println();</span>
    }

    // Train the sub-classifier
<span class="fc" id="L293">    m_Classifier.buildClassifier(newTrain);</span>
<span class="fc" id="L294">  }</span>

  /**
   * Returns a predicted class for the test instance.
   *
   * @param instance the instance to be classified
   * @return predicted class value
   * @throws Exception if the prediction couldn't be made
   */
  public double classifyInstance(Instance instance) throws Exception {  

    // Make sure structure of class attribute correct
<span class="fc" id="L306">    Instance newInstance = (Instance)instance.copy();</span>
<span class="fc" id="L307">    newInstance.setDataset(m_DiscretizedHeader);</span>
<span class="fc" id="L308">    double [] probs = m_Classifier.distributionForInstance(newInstance);</span>

    // Copmute actual prediction
<span class="fc" id="L311">    double prediction = 0, probSum = 0;</span>
<span class="fc bfc" id="L312" title="All 2 branches covered.">    for (int j = 0; j &lt; probs.length; j++) {</span>
<span class="fc" id="L313">      prediction += probs[j] * m_ClassMeans[j];</span>
<span class="fc" id="L314">      probSum += probs[j];</span>
    }
    
<span class="fc" id="L317">    return prediction /  probSum;</span>
  }

  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration listOptions() {

<span class="fc" id="L327">    Vector newVector = new Vector(3);</span>

<span class="fc" id="L329">    newVector.addElement(new Option(</span>
<span class="fc" id="L330">	      &quot;\tNumber of bins for equal-width discretization\n&quot;</span>
	      + &quot;\t(default 10).\n&quot;,
<span class="fc" id="L332">	      &quot;B&quot;, 1, &quot;-B &lt;int&gt;&quot;));</span>

<span class="fc" id="L334">    newVector.addElement(new Option(</span>
<span class="fc" id="L335">	      &quot;\tWhether to delete empty bins after discretization\n&quot;</span>
	      + &quot;\t(default false).\n&quot;,
<span class="fc" id="L337">	      &quot;E&quot;, 0, &quot;-E&quot;));</span>
    
<span class="fc" id="L339">    newVector.addElement(new Option(</span>
<span class="fc" id="L340">	     &quot;\tUse equal-frequency instead of equal-width discretization.&quot;,</span>
<span class="fc" id="L341">	     &quot;F&quot;, 0, &quot;-F&quot;));</span>

<span class="fc" id="L343">    Enumeration enu = super.listOptions();</span>
<span class="fc bfc" id="L344" title="All 2 branches covered.">    while (enu.hasMoreElements()) {</span>
<span class="fc" id="L345">      newVector.addElement(enu.nextElement());</span>
    }

<span class="fc" id="L348">    return newVector.elements();</span>
  }

  /**
   * Parses a given list of options. &lt;p/&gt;
   *
   &lt;!-- options-start --&gt;
   * Valid options are: &lt;p/&gt;
   * 
   * &lt;pre&gt; -B &amp;lt;int&amp;gt;
   *  Number of bins for equal-width discretization
   *  (default 10).
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -E
   *  Whether to delete empty bins after discretization
   *  (default false).
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -F
   *  Use equal-frequency instead of equal-width discretization.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -D
   *  If set, classifier is run in debug mode and
   *  may output additional info to the console&lt;/pre&gt;
   * 
   * &lt;pre&gt; -W
   *  Full name of base classifier.
   *  (default: weka.classifiers.trees.J48)&lt;/pre&gt;
   * 
   * &lt;pre&gt; 
   * Options specific to classifier weka.classifiers.trees.J48:
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -U
   *  Use unpruned tree.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -C &amp;lt;pruning confidence&amp;gt;
   *  Set confidence threshold for pruning.
   *  (default 0.25)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -M &amp;lt;minimum number of instances&amp;gt;
   *  Set minimum number of instances per leaf.
   *  (default 2)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -R
   *  Use reduced error pruning.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -N &amp;lt;number of folds&amp;gt;
   *  Set number of folds for reduced error
   *  pruning. One fold is used as pruning set.
   *  (default 3)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -B
   *  Use binary splits only.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -S
   *  Don't perform subtree raising.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -L
   *  Do not clean up after the tree has been built.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -A
   *  Laplace smoothing for predicted probabilities.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -Q &amp;lt;seed&amp;gt;
   *  Seed for random data shuffling (default 1).&lt;/pre&gt;
   * 
   &lt;!-- options-end --&gt;
   *
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {

<span class="fc" id="L423">    String binsString = Utils.getOption('B', options);</span>
<span class="fc bfc" id="L424" title="All 2 branches covered.">    if (binsString.length() != 0) {</span>
<span class="fc" id="L425">      setNumBins(Integer.parseInt(binsString));</span>
    } else {
<span class="fc" id="L427">      setNumBins(10);</span>
    }

<span class="fc" id="L430">    setDeleteEmptyBins(Utils.getFlag('E', options));</span>
<span class="fc" id="L431">    setUseEqualFrequency(Utils.getFlag('F', options));</span>

<span class="fc" id="L433">    super.setOptions(options);</span>
<span class="fc" id="L434">  }</span>

  /**
   * Gets the current settings of the Classifier.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String [] getOptions() {

<span class="fc" id="L443">    String [] superOptions = super.getOptions();</span>
<span class="fc" id="L444">    String [] options = new String [superOptions.length + 4];</span>
<span class="fc" id="L445">    int current = 0;</span>

<span class="fc" id="L447">    options[current++] = &quot;-B&quot;;</span>
<span class="fc" id="L448">    options[current++] = &quot;&quot; + getNumBins();</span>

<span class="pc bpc" id="L450" title="1 of 2 branches missed.">    if (getDeleteEmptyBins()) {</span>
<span class="nc" id="L451">      options[current++] = &quot;-E&quot;;</span>
    }
    
<span class="pc bpc" id="L454" title="1 of 2 branches missed.">    if (getUseEqualFrequency()) {</span>
<span class="nc" id="L455">      options[current++] = &quot;-F&quot;;</span>
    }

<span class="fc" id="L458">    System.arraycopy(superOptions, 0, options, current, </span>
<span class="fc" id="L459">		     superOptions.length);</span>

<span class="fc" id="L461">    current += superOptions.length;</span>
<span class="fc bfc" id="L462" title="All 2 branches covered.">    while (current &lt; options.length) {</span>
<span class="fc" id="L463">      options[current++] = &quot;&quot;;</span>
    }

<span class="fc" id="L466">    return options;</span>
  }

  /**
   * Returns the tip text for this property
   *
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String numBinsTipText() {

<span class="nc" id="L477">    return &quot;Number of bins for discretization.&quot;;</span>
  }

  /**
   * Gets the number of bins numeric attributes will be divided into
   *
   * @return the number of bins.
   */
  public int getNumBins() {

<span class="fc" id="L487">    return m_NumBins;</span>
  }

  /**
   * Sets the number of bins to divide each selected numeric attribute into
   *
   * @param numBins the number of bins
   */
  public void setNumBins(int numBins) {

<span class="fc" id="L497">    m_NumBins = numBins;</span>
<span class="fc" id="L498">  }</span>


  /**
   * Returns the tip text for this property
   *
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String deleteEmptyBinsTipText() {

<span class="nc" id="L509">    return &quot;Whether to delete empty bins after discretization.&quot;;</span>
  }


  /**
   * Gets the number of bins numeric attributes will be divided into
   *
   * @return the number of bins.
   */
  public boolean getDeleteEmptyBins() {

<span class="fc" id="L520">    return m_DeleteEmptyBins;</span>
  }

  /**
   * Sets the number of bins to divide each selected numeric attribute into
   *
   * @param numBins the number of bins
   */
  public void setDeleteEmptyBins(boolean b) {

<span class="fc" id="L530">    m_DeleteEmptyBins = b;</span>
<span class="fc" id="L531">  }</span>
  
  /**
   * Returns the tip text for this property
   *
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String useEqualFrequencyTipText() {

<span class="nc" id="L541">    return &quot;If set to true, equal-frequency binning will be used instead of&quot; +</span>
      &quot; equal-width binning.&quot;;
  }
  
  /**
   * Get the value of UseEqualFrequency.
   *
   * @return Value of UseEqualFrequency.
   */
  public boolean getUseEqualFrequency() {
    
<span class="fc" id="L552">    return m_UseEqualFrequency;</span>
  }
  
  /**
   * Set the value of UseEqualFrequency.
   *
   * @param newUseEqualFrequency Value to assign to UseEqualFrequency.
   */
  public void setUseEqualFrequency(boolean newUseEqualFrequency) {
    
<span class="fc" id="L562">    m_UseEqualFrequency = newUseEqualFrequency;</span>
<span class="fc" id="L563">  }</span>

  /**
   * Returns a description of the classifier.
   *
   * @return a description of the classifier as a string.
   */
  public String toString() {

<span class="fc" id="L572">    StringBuffer text = new StringBuffer();</span>

<span class="fc" id="L574">    text.append(&quot;Regression by discretization&quot;);</span>
<span class="pc bpc" id="L575" title="1 of 2 branches missed.">    if (m_ClassMeans == null) {</span>
<span class="fc" id="L576">      text.append(&quot;: No model built yet.&quot;);</span>
    } else {
<span class="nc" id="L578">      text.append(&quot;\n\nClass attribute discretized into &quot; </span>
<span class="nc" id="L579">		  + m_ClassMeans.length + &quot; values\n&quot;);</span>

<span class="nc" id="L581">      text.append(&quot;\nClassifier spec: &quot; + getClassifierSpec() </span>
<span class="nc" id="L582">		  + &quot;\n&quot;);</span>
<span class="nc" id="L583">      text.append(m_Classifier.toString());</span>
    }
<span class="fc" id="L585">    return text.toString();</span>
  }
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L594">    return RevisionUtils.extract(&quot;$Revision: 4746 $&quot;);</span>
  }
 
  /**
   * Main method for testing this class.
   *
   * @param argv the options
   */
  public static void main(String [] argv) {
<span class="nc" id="L603">    runClassifier(new RegressionByDiscretization(), argv);</span>
<span class="nc" id="L604">  }</span>
}

</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>