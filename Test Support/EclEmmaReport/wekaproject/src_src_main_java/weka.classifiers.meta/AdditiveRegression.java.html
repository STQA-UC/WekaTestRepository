<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>AdditiveRegression.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.meta</a> &gt; <span class="el_source">AdditiveRegression.java</span></div><h1>AdditiveRegression.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    AdditiveRegression.java
 *    Copyright (C) 2000 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.classifiers.meta;

import weka.classifiers.Classifier;
import weka.classifiers.IteratedSingleClassifierEnhancer;
import weka.classifiers.rules.ZeroR;
import weka.core.AdditionalMeasureProducer;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.OptionHandler;
import weka.core.RevisionUtils;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.WeightedInstancesHandler;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;

import java.util.Enumeration;
import java.util.Vector;

/**
 &lt;!-- globalinfo-start --&gt;
 * Meta classifier that enhances the performance of a regression base classifier. Each iteration fits a model to the residuals left by the classifier on the previous iteration. Prediction is accomplished by adding the predictions of each classifier. Reducing the shrinkage (learning rate) parameter helps prevent overfitting and has a smoothing effect but increases the learning time.&lt;br/&gt;
 * &lt;br/&gt;
 * For more information see:&lt;br/&gt;
 * &lt;br/&gt;
 * J.H. Friedman (1999). Stochastic Gradient Boosting.
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;techreport{Friedman1999,
 *    author = {J.H. Friedman},
 *    institution = {Stanford University},
 *    title = {Stochastic Gradient Boosting},
 *    year = {1999},
 *    PS = {http://www-stat.stanford.edu/\~jhf/ftp/stobst.ps}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -S
 *  Specify shrinkage rate. (default = 1.0, ie. no shrinkage)
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -I &amp;lt;num&amp;gt;
 *  Number of iterations.
 *  (default 10)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 * &lt;pre&gt; -W
 *  Full name of base classifier.
 *  (default: weka.classifiers.trees.DecisionStump)&lt;/pre&gt;
 * 
 * &lt;pre&gt; 
 * Options specific to classifier weka.classifiers.trees.DecisionStump:
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Mark Hall (mhall@cs.waikato.ac.nz)
 * @version $Revision: 1.25 $
 */
public class AdditiveRegression 
  extends IteratedSingleClassifierEnhancer 
  implements OptionHandler,
	     AdditionalMeasureProducer,
	     WeightedInstancesHandler,
	     TechnicalInformationHandler {

  /** for serialization */
  static final long serialVersionUID = -2368937577670527151L;
  
  /**
   * Shrinkage (Learning rate). Default = no shrinkage.
   */
<span class="fc" id="L115">  protected double m_shrinkage = 1.0;</span>

  /** The number of successfully generated base classifiers. */
  protected int m_NumIterationsPerformed;

  /** The model for the mean */
  protected ZeroR m_zeroR;

  /** whether we have suitable data or nor (if not, ZeroR model is used) */
<span class="fc" id="L124">  protected boolean m_SuitableData = true;</span>
  
  /**
   * Returns a string describing this attribute evaluator
   * @return a description of the evaluator suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L132">    return &quot; Meta classifier that enhances the performance of a regression &quot;</span>
      +&quot;base classifier. Each iteration fits a model to the residuals left &quot;
      +&quot;by the classifier on the previous iteration. Prediction is &quot;
      +&quot;accomplished by adding the predictions of each classifier. &quot;
      +&quot;Reducing the shrinkage (learning rate) parameter helps prevent &quot;
      +&quot;overfitting and has a smoothing effect but increases the learning &quot;
      +&quot;time.\n\n&quot;
      +&quot;For more information see:\n\n&quot;
<span class="nc" id="L140">      + getTechnicalInformation().toString();</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;
    
<span class="nc" id="L153">    result = new TechnicalInformation(Type.TECHREPORT);</span>
<span class="nc" id="L154">    result.setValue(Field.AUTHOR, &quot;J.H. Friedman&quot;);</span>
<span class="nc" id="L155">    result.setValue(Field.YEAR, &quot;1999&quot;);</span>
<span class="nc" id="L156">    result.setValue(Field.TITLE, &quot;Stochastic Gradient Boosting&quot;);</span>
<span class="nc" id="L157">    result.setValue(Field.INSTITUTION, &quot;Stanford University&quot;);</span>
<span class="nc" id="L158">    result.setValue(Field.PS, &quot;http://www-stat.stanford.edu/~jhf/ftp/stobst.ps&quot;);</span>
    
<span class="nc" id="L160">    return result;</span>
  }

  /**
   * Default constructor specifying DecisionStump as the classifier
   */
  public AdditiveRegression() {

<span class="fc" id="L168">    this(new weka.classifiers.trees.DecisionStump());</span>
<span class="fc" id="L169">  }</span>

  /**
   * Constructor which takes base classifier as argument.
   *
   * @param classifier the base classifier to use
   */
<span class="fc" id="L176">  public AdditiveRegression(Classifier classifier) {</span>

<span class="fc" id="L178">    m_Classifier = classifier;</span>
<span class="fc" id="L179">  }</span>

  /**
   * String describing default classifier.
   * 
   * @return the default classifier classname
   */
  protected String defaultClassifierString() {
    
<span class="fc" id="L188">    return &quot;weka.classifiers.trees.DecisionStump&quot;;</span>
  }

  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration listOptions() {

<span class="fc" id="L198">    Vector newVector = new Vector(4);</span>

<span class="fc" id="L200">    newVector.addElement(new Option(</span>
<span class="fc" id="L201">	      &quot;\tSpecify shrinkage rate. &quot;</span>
	      +&quot;(default = 1.0, ie. no shrinkage)\n&quot;, 
<span class="fc" id="L203">	      &quot;S&quot;, 1, &quot;-S&quot;));</span>

<span class="fc" id="L205">    Enumeration enu = super.listOptions();</span>
<span class="fc bfc" id="L206" title="All 2 branches covered.">    while (enu.hasMoreElements()) {</span>
<span class="fc" id="L207">      newVector.addElement(enu.nextElement());</span>
    }
<span class="fc" id="L209">    return newVector.elements();</span>
  }

  /**
   * Parses a given list of options. &lt;p/&gt;
   *
   &lt;!-- options-start --&gt;
   * Valid options are: &lt;p/&gt;
   * 
   * &lt;pre&gt; -S
   *  Specify shrinkage rate. (default = 1.0, ie. no shrinkage)
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -I &amp;lt;num&amp;gt;
   *  Number of iterations.
   *  (default 10)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -D
   *  If set, classifier is run in debug mode and
   *  may output additional info to the console&lt;/pre&gt;
   * 
   * &lt;pre&gt; -W
   *  Full name of base classifier.
   *  (default: weka.classifiers.trees.DecisionStump)&lt;/pre&gt;
   * 
   * &lt;pre&gt; 
   * Options specific to classifier weka.classifiers.trees.DecisionStump:
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -D
   *  If set, classifier is run in debug mode and
   *  may output additional info to the console&lt;/pre&gt;
   * 
   &lt;!-- options-end --&gt;
   *
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {

<span class="fc" id="L249">    String optionString = Utils.getOption('S', options);</span>
<span class="fc bfc" id="L250" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L251">      Double temp = Double.valueOf(optionString);</span>
<span class="fc" id="L252">      setShrinkage(temp.doubleValue());</span>
    }

<span class="fc" id="L255">    super.setOptions(options);</span>
<span class="fc" id="L256">  }</span>

  /**
   * Gets the current settings of the Classifier.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String [] getOptions() {
    
<span class="fc" id="L265">    String [] superOptions = super.getOptions();</span>
<span class="fc" id="L266">    String [] options = new String [superOptions.length + 2];</span>
<span class="fc" id="L267">    int current = 0;</span>

<span class="fc" id="L269">    options[current++] = &quot;-S&quot;; options[current++] = &quot;&quot; + getShrinkage();</span>

<span class="fc" id="L271">    System.arraycopy(superOptions, 0, options, current, </span>
<span class="fc" id="L272">		     superOptions.length);</span>

<span class="fc" id="L274">    current += superOptions.length;</span>
<span class="pc bpc" id="L275" title="1 of 2 branches missed.">    while (current &lt; options.length) {</span>
<span class="nc" id="L276">      options[current++] = &quot;&quot;;</span>
    }
<span class="fc" id="L278">    return options;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String shrinkageTipText() {
<span class="nc" id="L287">    return &quot;Shrinkage rate. Smaller values help prevent overfitting and &quot;</span>
      + &quot;have a smoothing effect (but increase learning time). &quot;
      +&quot;Default = 1.0, ie. no shrinkage.&quot;; 
  }

  /**
   * Set the shrinkage parameter
   *
   * @param l the shrinkage rate.
   */
  public void setShrinkage(double l) {
<span class="fc" id="L298">    m_shrinkage = l;</span>
<span class="fc" id="L299">  }</span>

  /**
   * Get the shrinkage rate.
   *
   * @return the value of the learning rate
   */
  public double getShrinkage() {
<span class="fc" id="L307">    return m_shrinkage;</span>
  }

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L316">    Capabilities result = super.getCapabilities();</span>

    // class
<span class="fc" id="L319">    result.disableAllClasses();</span>
<span class="fc" id="L320">    result.disableAllClassDependencies();</span>
<span class="fc" id="L321">    result.enable(Capability.NUMERIC_CLASS);</span>
<span class="fc" id="L322">    result.enable(Capability.DATE_CLASS);</span>
    
<span class="fc" id="L324">    return result;</span>
  }

  /**
   * Build the classifier on the supplied data
   *
   * @param data the training data
   * @throws Exception if the classifier could not be built successfully
   */
  public void buildClassifier(Instances data) throws Exception {

<span class="fc" id="L335">    super.buildClassifier(data);</span>

    // can classifier handle the data?
<span class="fc" id="L338">    getCapabilities().testWithFail(data);</span>

    // remove instances with missing class
<span class="fc" id="L341">    Instances newData = new Instances(data);</span>
<span class="fc" id="L342">    newData.deleteWithMissingClass();</span>

<span class="fc" id="L344">    double sum = 0;</span>
<span class="fc" id="L345">    double temp_sum = 0;</span>
    // Add the model for the mean first
<span class="fc" id="L347">    m_zeroR = new ZeroR();</span>
<span class="fc" id="L348">    m_zeroR.buildClassifier(newData);</span>
    
    // only class? -&gt; use only ZeroR model
<span class="fc bfc" id="L351" title="All 2 branches covered.">    if (newData.numAttributes() == 1) {</span>
<span class="fc" id="L352">      System.err.println(</span>
<span class="fc" id="L353">	  &quot;Cannot build model (only class attribute present in data!), &quot;</span>
	  + &quot;using ZeroR model instead!&quot;);
<span class="fc" id="L355">      m_SuitableData = false;</span>
<span class="fc" id="L356">      return;</span>
    }
    else {
<span class="fc" id="L359">      m_SuitableData = true;</span>
    }
    
<span class="fc" id="L362">    newData = residualReplace(newData, m_zeroR, false);</span>
<span class="fc bfc" id="L363" title="All 2 branches covered.">    for (int i = 0; i &lt; newData.numInstances(); i++) {</span>
<span class="fc" id="L364">      sum += newData.instance(i).weight() *</span>
<span class="fc" id="L365">	newData.instance(i).classValue() * newData.instance(i).classValue();</span>
    }
<span class="pc bpc" id="L367" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L368">      System.err.println(&quot;Sum of squared residuals &quot;</span>
<span class="nc" id="L369">			 +&quot;(predicting the mean) : &quot; + sum);</span>
    }

<span class="fc" id="L372">    m_NumIterationsPerformed = 0;</span>
    do {
<span class="fc" id="L374">      temp_sum = sum;</span>

      // Build the classifier
<span class="fc" id="L377">      m_Classifiers[m_NumIterationsPerformed].buildClassifier(newData);</span>

<span class="fc" id="L379">      newData = residualReplace(newData, m_Classifiers[m_NumIterationsPerformed], true);</span>
<span class="fc" id="L380">      sum = 0;</span>
<span class="fc bfc" id="L381" title="All 2 branches covered.">      for (int i = 0; i &lt; newData.numInstances(); i++) {</span>
<span class="fc" id="L382">	sum += newData.instance(i).weight() *</span>
<span class="fc" id="L383">	  newData.instance(i).classValue() * newData.instance(i).classValue();</span>
      }
<span class="pc bpc" id="L385" title="1 of 2 branches missed.">      if (m_Debug) {</span>
<span class="nc" id="L386">	System.err.println(&quot;Sum of squared residuals : &quot;+sum);</span>
      }
<span class="fc" id="L388">      m_NumIterationsPerformed++;</span>
<span class="fc bfc" id="L389" title="All 2 branches covered.">    } while (((temp_sum - sum) &gt; Utils.SMALL) &amp;&amp; </span>
<span class="fc bfc" id="L390" title="All 2 branches covered.">	     (m_NumIterationsPerformed &lt; m_Classifiers.length));</span>
<span class="fc" id="L391">  }</span>

  /**
   * Classify an instance.
   *
   * @param inst the instance to predict
   * @return a prediction for the instance
   * @throws Exception if an error occurs
   */
  public double classifyInstance(Instance inst) throws Exception {

<span class="fc" id="L402">    double prediction = m_zeroR.classifyInstance(inst);</span>

    // default model?
<span class="fc bfc" id="L405" title="All 2 branches covered.">    if (!m_SuitableData) {</span>
<span class="fc" id="L406">      return prediction;</span>
    }
    
<span class="fc bfc" id="L409" title="All 2 branches covered.">    for (int i = 0; i &lt; m_NumIterationsPerformed; i++) {</span>
<span class="fc" id="L410">      double toAdd = m_Classifiers[i].classifyInstance(inst);</span>
<span class="fc" id="L411">      toAdd *= getShrinkage();</span>
<span class="fc" id="L412">      prediction += toAdd;</span>
    }

<span class="fc" id="L415">    return prediction;</span>
  }

  /**
   * Replace the class values of the instances from the current iteration
   * with residuals ater predicting with the supplied classifier.
   *
   * @param data the instances to predict
   * @param c the classifier to use
   * @param useShrinkage whether shrinkage is to be applied to the model's output
   * @return a new set of instances with class values replaced by residuals
   * @throws Exception if something goes wrong
   */
  private Instances residualReplace(Instances data, Classifier c, 
				    boolean useShrinkage) throws Exception {
    double pred,residual;
<span class="fc" id="L431">    Instances newInst = new Instances(data);</span>

<span class="fc bfc" id="L433" title="All 2 branches covered.">    for (int i = 0; i &lt; newInst.numInstances(); i++) {</span>
<span class="fc" id="L434">      pred = c.classifyInstance(newInst.instance(i));</span>
<span class="fc bfc" id="L435" title="All 2 branches covered.">      if (useShrinkage) {</span>
<span class="fc" id="L436">	pred *= getShrinkage();</span>
      }
<span class="fc" id="L438">      residual = newInst.instance(i).classValue() - pred;</span>
<span class="fc" id="L439">      newInst.instance(i).setClassValue(residual);</span>
    }
    //    System.err.print(newInst);
<span class="fc" id="L442">    return newInst;</span>
  }

  /**
   * Returns an enumeration of the additional measure names
   * @return an enumeration of the measure names
   */
  public Enumeration enumerateMeasures() {
<span class="nc" id="L450">    Vector newVector = new Vector(1);</span>
<span class="nc" id="L451">    newVector.addElement(&quot;measureNumIterations&quot;);</span>
<span class="nc" id="L452">    return newVector.elements();</span>
  }

  /**
   * Returns the value of the named measure
   * @param additionalMeasureName the name of the measure to query for its value
   * @return the value of the named measure
   * @throws IllegalArgumentException if the named measure is not supported
   */
  public double getMeasure(String additionalMeasureName) {
<span class="nc bnc" id="L462" title="All 2 branches missed.">    if (additionalMeasureName.compareToIgnoreCase(&quot;measureNumIterations&quot;) == 0) {</span>
<span class="nc" id="L463">      return measureNumIterations();</span>
    } else {
<span class="nc" id="L465">      throw new IllegalArgumentException(additionalMeasureName </span>
<span class="nc" id="L466">			  + &quot; not supported (AdditiveRegression)&quot;);</span>
    }
  }

  /**
   * return the number of iterations (base classifiers) completed
   * @return the number of iterations (same as number of base classifier
   * models)
   */
  public double measureNumIterations() {
<span class="nc" id="L476">    return m_NumIterationsPerformed;</span>
  }

  /**
   * Returns textual description of the classifier.
   *
   * @return a description of the classifier as a string
   */
  public String toString() {
<span class="fc" id="L485">    StringBuffer text = new StringBuffer();</span>

    // only ZeroR model?
<span class="pc bpc" id="L488" title="1 of 2 branches missed.">    if (!m_SuitableData) {</span>
<span class="nc" id="L489">      StringBuffer buf = new StringBuffer();</span>
<span class="nc" id="L490">      buf.append(this.getClass().getName().replaceAll(&quot;.*\\.&quot;, &quot;&quot;) + &quot;\n&quot;);</span>
<span class="nc" id="L491">      buf.append(this.getClass().getName().replaceAll(&quot;.*\\.&quot;, &quot;&quot;).replaceAll(&quot;.&quot;, &quot;=&quot;) + &quot;\n\n&quot;);</span>
<span class="nc" id="L492">      buf.append(&quot;Warning: No model could be built, hence ZeroR model is used:\n\n&quot;);</span>
<span class="nc" id="L493">      buf.append(m_zeroR.toString());</span>
<span class="nc" id="L494">      return buf.toString();</span>
    }
    
<span class="pc bpc" id="L497" title="1 of 2 branches missed.">    if (m_NumIterations == 0) {</span>
<span class="nc" id="L498">      return &quot;Classifier hasn't been built yet!&quot;;</span>
    }

<span class="fc" id="L501">    text.append(&quot;Additive Regression\n\n&quot;);</span>

<span class="fc" id="L503">    text.append(&quot;ZeroR model\n\n&quot; + m_zeroR + &quot;\n\n&quot;);</span>

<span class="fc" id="L505">    text.append(&quot;Base classifier &quot; </span>
<span class="fc" id="L506">		+ getClassifier().getClass().getName()</span>
<span class="fc" id="L507">		+ &quot;\n\n&quot;);</span>
<span class="fc" id="L508">    text.append(&quot;&quot; + m_NumIterationsPerformed + &quot; models generated.\n&quot;);</span>

<span class="pc bpc" id="L510" title="1 of 2 branches missed.">    for (int i = 0; i &lt; m_NumIterationsPerformed; i++) {</span>
<span class="nc" id="L511">      text.append(&quot;\nModel number &quot; + i + &quot;\n\n&quot; +</span>
<span class="nc" id="L512">		  m_Classifiers[i] + &quot;\n&quot;);</span>
    }

<span class="fc" id="L515">    return text.toString();</span>
  }
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L524">    return RevisionUtils.extract(&quot;$Revision: 1.25 $&quot;);</span>
  }

  /**
   * Main method for testing this class.
   *
   * @param argv should contain the following arguments:
   * -t training file [-T test file] [-c class index]
   */
  public static void main(String [] argv) {
<span class="nc" id="L534">    runClassifier(new AdditiveRegression(), argv);</span>
<span class="nc" id="L535">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>