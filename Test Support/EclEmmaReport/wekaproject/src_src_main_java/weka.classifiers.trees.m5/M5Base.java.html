<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>M5Base.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.trees.m5</a> &gt; <span class="el_source">M5Base.java</span></div><h1>M5Base.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    M5Base.java
 *    Copyright (C) 2000 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.classifiers.trees.m5;

import weka.classifiers.Classifier;
import weka.classifiers.functions.LinearRegression;
import weka.core.AdditionalMeasureProducer;
import weka.core.Capabilities;
import weka.core.FastVector;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;
import weka.filters.Filter;
import weka.filters.supervised.attribute.NominalToBinary;
import weka.filters.unsupervised.attribute.RemoveUseless;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

import java.util.Enumeration;
import java.util.Random;
import java.util.Vector;

/**
 * M5Base. Implements base routines
 * for generating M5 Model trees and rules. &lt;p&gt;
 * 
 * The original algorithm M5 was invented by Quinlan: &lt;br/&gt;
 * 
 * Quinlan J. R. (1992). Learning with continuous classes. Proceedings of
 * the Australian Joint Conference on Artificial Intelligence. 343--348.
 * World Scientific, Singapore. &lt;p/&gt;
 * 
 * Yong Wang made improvements and created M5': &lt;br/&gt;
 * 
 * Wang, Y and Witten, I. H. (1997). Induction of model trees for
 * predicting continuous classes. Proceedings of the poster papers of the
 * European Conference on Machine Learning. University of Economics,
 * Faculty of Informatics and Statistics, Prague. &lt;p/&gt;
 *
 * Valid options are:&lt;p&gt;
 * 
 * -U &lt;br&gt;
 * Use unsmoothed predictions. &lt;p&gt;
 *
 * -R &lt;br&gt;
 * Build regression tree/rule rather than model tree/rule
 *
 * @author Mark Hall (mhall@cs.waikato.ac.nz)
 * @version $Revision: 6260 $
 */
public abstract class M5Base 
  extends Classifier 
  implements AdditionalMeasureProducer,
	     TechnicalInformationHandler {

  /** for serialization */
  private static final long serialVersionUID = -4022221950191647679L;

  /**
   * the instances covered by the tree/rules
   */
  private Instances m_instances;

  /**
   * the rule set
   */
  protected FastVector m_ruleSet;

  /**
   * generate a decision list instead of a single tree.
   */
  private boolean m_generateRules;

  /**
   * use unsmoothed predictions
   */
  private boolean m_unsmoothedPredictions;

  /**
   * filter to fill in missing values
   */
  private ReplaceMissingValues m_replaceMissing;

  /**
   * filter to convert nominal attributes to binary
   */
  private NominalToBinary m_nominalToBinary;
  
  /**
   * for removing useless attributes 
   */
  private RemoveUseless m_removeUseless;

  /**
   * Save instances at each node in an M5 tree for visualization purposes.
   */
<span class="fc" id="L121">  protected boolean m_saveInstances = false;</span>

  /**
   * Make a regression tree/rule instead of a model tree/rule
   */
  protected boolean m_regressionTree;

  /**
   * Do not prune tree/rules
   */
<span class="fc" id="L131">  protected boolean m_useUnpruned = false;</span>

  /**
   * The minimum number of instances to allow at a leaf node
   */
<span class="fc" id="L136">  protected double m_minNumInstances = 4;</span>

  /**
   * Constructor
   */
<span class="fc" id="L141">  public M5Base() {</span>
<span class="fc" id="L142">    m_generateRules = false;</span>
<span class="fc" id="L143">    m_unsmoothedPredictions = false;</span>
<span class="fc" id="L144">    m_useUnpruned = false;</span>
<span class="fc" id="L145">    m_minNumInstances = 4;</span>
<span class="fc" id="L146">  }</span>

  /**
   * returns information about the classifier
   * @return a description suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L154">    return </span>
<span class="nc" id="L155">        &quot;M5Base. Implements base routines for generating M5 Model trees and &quot; </span>
      + &quot;rules\n&quot;
      + &quot;The original algorithm M5 was invented by R. Quinlan and Yong Wang &quot;
      + &quot;made improvements.\n\n&quot;
      + &quot;For more information see:\n\n&quot;
<span class="nc" id="L160">      + getTechnicalInformation().toString();</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;
    TechnicalInformation 	additional;
    
<span class="nc" id="L174">    result = new TechnicalInformation(Type.INPROCEEDINGS);</span>
<span class="nc" id="L175">    result.setValue(Field.AUTHOR, &quot;Ross J. Quinlan&quot;);</span>
<span class="nc" id="L176">    result.setValue(Field.TITLE, &quot;Learning with Continuous Classes&quot;);</span>
<span class="nc" id="L177">    result.setValue(Field.BOOKTITLE, &quot;5th Australian Joint Conference on Artificial Intelligence&quot;);</span>
<span class="nc" id="L178">    result.setValue(Field.YEAR, &quot;1992&quot;);</span>
<span class="nc" id="L179">    result.setValue(Field.PAGES, &quot;343-348&quot;);</span>
<span class="nc" id="L180">    result.setValue(Field.PUBLISHER, &quot;World Scientific&quot;);</span>
<span class="nc" id="L181">    result.setValue(Field.ADDRESS, &quot;Singapore&quot;);</span>
    
<span class="nc" id="L183">    additional = result.add(Type.INPROCEEDINGS);</span>
<span class="nc" id="L184">    additional.setValue(Field.AUTHOR, &quot;Y. Wang and I. H. Witten&quot;);</span>
<span class="nc" id="L185">    additional.setValue(Field.TITLE, &quot;Induction of model trees for predicting continuous classes&quot;);</span>
<span class="nc" id="L186">    additional.setValue(Field.BOOKTITLE, &quot;Poster papers of the 9th European Conference on Machine Learning&quot;);</span>
<span class="nc" id="L187">    additional.setValue(Field.YEAR, &quot;1997&quot;);</span>
<span class="nc" id="L188">    additional.setValue(Field.PUBLISHER, &quot;Springer&quot;);</span>
    
<span class="nc" id="L190">    return result;</span>
  }

  /**
   * Returns an enumeration describing the available options
   * 
   * @return an enumeration of all the available options
   */
  public Enumeration listOptions() {
<span class="fc" id="L199">    Vector newVector = new Vector(4);</span>

<span class="fc" id="L201">    newVector.addElement(new Option(&quot;\tUse unpruned tree/rules&quot;, </span>
<span class="fc" id="L202">				    &quot;N&quot;, 0, &quot;-N&quot;));</span>

<span class="fc" id="L204">    newVector.addElement(new Option(&quot;\tUse unsmoothed predictions&quot;, </span>
<span class="fc" id="L205">				    &quot;U&quot;, 0, &quot;-U&quot;));</span>

<span class="fc" id="L207">    newVector.addElement(new Option(&quot;\tBuild regression tree/rule rather &quot;</span>
				    +&quot;than a model tree/rule&quot;, 
<span class="fc" id="L209">				    &quot;R&quot;, 0, &quot;-R&quot;));</span>

<span class="fc" id="L211">    newVector.addElement(new Option(&quot;\tSet minimum number of instances &quot;</span>
				    +&quot;per leaf\n\t(default 4)&quot;,
<span class="fc" id="L213">				    &quot;M&quot;,1,&quot;-M &lt;minimum number of instances&gt;&quot;));</span>
<span class="fc" id="L214">    return newVector.elements();</span>
  } 

  /**
   * Parses a given list of options. &lt;p/&gt;
   * 
   * Valid options are:&lt;p&gt;
   * 
   * -U &lt;br&gt;
   * Use unsmoothed predictions. &lt;p&gt;
   *
   * -R &lt;br&gt;
   * Build a regression tree rather than a model tree. &lt;p&gt;
   * 
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {
<span class="fc" id="L232">    setUnpruned(Utils.getFlag('N', options));</span>
<span class="fc" id="L233">    setUseUnsmoothed(Utils.getFlag('U', options));</span>
<span class="fc" id="L234">    setBuildRegressionTree(Utils.getFlag('R', options));</span>
<span class="fc" id="L235">    String optionString = Utils.getOption('M', options);</span>
<span class="fc bfc" id="L236" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L237">      setMinNumInstances((new Double(optionString)).doubleValue());</span>
    }
<span class="fc" id="L239">    Utils.checkForRemainingOptions(options);</span>
<span class="fc" id="L240">  } </span>

  /**
   * Gets the current settings of the classifier.
   * 
   * @return an array of strings suitable for passing to setOptions
   */
  public String[] getOptions() {
<span class="fc" id="L248">    String[] options = new String[5];</span>
<span class="fc" id="L249">    int current = 0;</span>

<span class="pc bpc" id="L251" title="1 of 2 branches missed.">    if (getUnpruned()) {</span>
<span class="nc" id="L252">      options[current++] = &quot;-N&quot;;</span>
    }

<span class="pc bpc" id="L255" title="1 of 2 branches missed.">    if (getUseUnsmoothed()) {</span>
<span class="nc" id="L256">      options[current++] = &quot;-U&quot;;</span>
    } 

<span class="pc bpc" id="L259" title="1 of 2 branches missed.">    if (getBuildRegressionTree()) {</span>
<span class="nc" id="L260">      options[current++] = &quot;-R&quot;;</span>
    }

<span class="fc" id="L263">    options[current++] = &quot;-M&quot;; </span>
<span class="fc" id="L264">    options[current++] = &quot;&quot;+getMinNumInstances();</span>

<span class="fc bfc" id="L266" title="All 2 branches covered.">    while (current &lt; options.length) {</span>
<span class="fc" id="L267">      options[current++] = &quot;&quot;;</span>
    } 
<span class="fc" id="L269">    return options;</span>
  } 

  /**
   * Returns the tip text for this property
   * 
   * @return 		tip text for this property suitable for
   * 			displaying in the explorer/experimenter gui
   */
  public String unprunedTipText() {
<span class="nc" id="L279">    return &quot;Whether unpruned tree/rules are to be generated.&quot;;</span>
  }

  /**
   * Use unpruned tree/rules
   *
   * @param unpruned true if unpruned tree/rules are to be generated
   */
  public void setUnpruned(boolean unpruned) {
<span class="fc" id="L288">    m_useUnpruned = unpruned;</span>
<span class="fc" id="L289">  }</span>

  /**
   * Get whether unpruned tree/rules are being generated
   *
   * @return true if unpruned tree/rules are to be generated
   */
  public boolean getUnpruned() {
<span class="fc" id="L297">    return m_useUnpruned;</span>
  }

  /**
   * Returns the tip text for this property
   * 
   * @return 		tip text for this property suitable for
   * 			displaying in the explorer/experimenter gui
   */
  public String generateRulesTipText() {
<span class="nc" id="L307">    return &quot;Whether to generate rules (decision list) rather than a tree.&quot;;</span>
  }

  /**
   * Generate rules (decision list) rather than a tree
   * 
   * @param u true if rules are to be generated
   */
  protected void setGenerateRules(boolean u) {
<span class="fc" id="L316">    m_generateRules = u;</span>
<span class="fc" id="L317">  } </span>

  /**
   * get whether rules are being generated rather than a tree
   * 
   * @return true if rules are to be generated
   */
  protected boolean getGenerateRules() {
<span class="nc" id="L325">    return m_generateRules;</span>
  } 

  /**
   * Returns the tip text for this property
   * 
   * @return 		tip text for this property suitable for
   * 			displaying in the explorer/experimenter gui
   */
  public String useUnsmoothedTipText() {
<span class="nc" id="L335">    return &quot;Whether to use unsmoothed predictions.&quot;;</span>
  }

  /**
   * Use unsmoothed predictions
   * 
   * @param s true if unsmoothed predictions are to be used
   */
  public void setUseUnsmoothed(boolean s) {
<span class="fc" id="L344">    m_unsmoothedPredictions = s;</span>
<span class="fc" id="L345">  } </span>

  /**
   * Get whether or not smoothing is being used
   * 
   * @return true if unsmoothed predictions are to be used
   */
  public boolean getUseUnsmoothed() {
<span class="fc" id="L353">    return m_unsmoothedPredictions;</span>
  } 

  /**
   * Returns the tip text for this property
   * 
   * @return 		tip text for this property suitable for
   * 			displaying in the explorer/experimenter gui
   */
  public String buildRegressionTreeTipText() {
<span class="nc" id="L363">    return &quot;Whether to generate a regression tree/rule instead of a model tree/rule.&quot;;</span>
  }

  /**
   * Get the value of regressionTree.
   *
   * @return Value of regressionTree.
   */
  public boolean getBuildRegressionTree() {
    
<span class="fc" id="L373">    return m_regressionTree;</span>
  }
  
  /**
   * Set the value of regressionTree.
   *
   * @param newregressionTree Value to assign to regressionTree.
   */
  public void setBuildRegressionTree(boolean newregressionTree) {
    
<span class="fc" id="L383">    m_regressionTree = newregressionTree;</span>
<span class="fc" id="L384">  }</span>

  /**
   * Returns the tip text for this property
   * 
   * @return 		tip text for this property suitable for
   * 			displaying in the explorer/experimenter gui
   */
  public String minNumInstancesTipText() {
<span class="nc" id="L393">    return &quot;The minimum number of instances to allow at a leaf node.&quot;;</span>
  }

  /**
   * Set the minimum number of instances to allow at a leaf node
   *
   * @param minNum the minimum number of instances
   */
  public void setMinNumInstances(double minNum) {
<span class="fc" id="L402">    m_minNumInstances = minNum;</span>
<span class="fc" id="L403">  }</span>

  /**
   * Get the minimum number of instances to allow at a leaf node
   *
   * @return a &lt;code&gt;double&lt;/code&gt; value
   */
  public double getMinNumInstances() {
<span class="fc" id="L411">    return m_minNumInstances;</span>
  }

  /**
   * Returns default capabilities of the classifier, i.e., of LinearRegression.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L420">    return new LinearRegression().getCapabilities();</span>
  }

  /**
   * Generates the classifier.
   * 
   * @param data set of instances serving as training data
   * @throws Exception if the classifier has not been generated
   * successfully
   */
  public void buildClassifier(Instances data) throws Exception {
    // can classifier handle the data?
<span class="fc" id="L432">    getCapabilities().testWithFail(data);</span>

    // remove instances with missing class
<span class="fc" id="L435">    data = new Instances(data);</span>
<span class="fc" id="L436">    data.deleteWithMissingClass();</span>
    
<span class="fc" id="L438">    m_instances = new Instances(data);</span>

<span class="fc" id="L440">    m_replaceMissing = new ReplaceMissingValues();</span>
<span class="fc" id="L441">    m_replaceMissing.setInputFormat(m_instances);</span>
<span class="fc" id="L442">    m_instances = Filter.useFilter(m_instances, m_replaceMissing);</span>

<span class="fc" id="L444">    m_nominalToBinary = new NominalToBinary();</span>
<span class="fc" id="L445">    m_nominalToBinary.setInputFormat(m_instances);</span>
<span class="fc" id="L446">    m_instances = Filter.useFilter(m_instances, m_nominalToBinary);</span>

<span class="fc" id="L448">    m_removeUseless = new RemoveUseless();</span>
<span class="fc" id="L449">    m_removeUseless.setInputFormat(m_instances);</span>
<span class="fc" id="L450">    m_instances = Filter.useFilter(m_instances, m_removeUseless);</span>
    
<span class="fc" id="L452">    m_instances.randomize(new Random(1));</span>

<span class="fc" id="L454">    m_ruleSet = new FastVector();</span>

    Rule tempRule;

<span class="fc bfc" id="L458" title="All 2 branches covered.">    if (m_generateRules) {</span>
<span class="fc" id="L459">      Instances tempInst = m_instances;</span>
     
      do {
<span class="fc" id="L462">	tempRule = new Rule();</span>
<span class="pc bpc" id="L463" title="1 of 2 branches missed.">	tempRule.setSmoothing(!m_unsmoothedPredictions);</span>
<span class="fc" id="L464">	tempRule.setRegressionTree(m_regressionTree);</span>
<span class="fc" id="L465">	tempRule.setUnpruned(m_useUnpruned);</span>
<span class="fc" id="L466">	tempRule.setSaveInstances(false);</span>
<span class="fc" id="L467">	tempRule.setMinNumInstances(m_minNumInstances);</span>
<span class="fc" id="L468">	tempRule.buildClassifier(tempInst);</span>
<span class="fc" id="L469">	m_ruleSet.addElement(tempRule);</span>
	//	System.err.println(&quot;Built rule : &quot;+tempRule.toString());
<span class="fc" id="L471">	tempInst = tempRule.notCoveredInstances();</span>
<span class="fc" id="L472">	tempRule.freeNotCoveredInstances();</span>
<span class="fc bfc" id="L473" title="All 2 branches covered.">      } while (tempInst.numInstances() &gt; 0);</span>
    } else {
      // just build a single tree
<span class="fc" id="L476">      tempRule = new Rule();</span>

<span class="fc" id="L478">      tempRule.setUseTree(true);</span>
      //      tempRule.setGrowFullTree(true);
<span class="pc bpc" id="L480" title="1 of 2 branches missed.">      tempRule.setSmoothing(!m_unsmoothedPredictions);</span>
<span class="fc" id="L481">      tempRule.setSaveInstances(m_saveInstances);</span>
<span class="fc" id="L482">      tempRule.setRegressionTree(m_regressionTree);</span>
<span class="fc" id="L483">      tempRule.setUnpruned(m_useUnpruned);</span>
<span class="fc" id="L484">      tempRule.setMinNumInstances(m_minNumInstances);</span>

      Instances temp_train;

<span class="fc" id="L488">      temp_train = m_instances;</span>

<span class="fc" id="L490">      tempRule.buildClassifier(temp_train);</span>

<span class="fc" id="L492">      m_ruleSet.addElement(tempRule);      </span>

      //      System.err.print(tempRule.m_topOfTree.treeToString(0));
    }
    
    // save space
<span class="fc" id="L498">    m_instances = new Instances(m_instances, 0);</span>
<span class="fc" id="L499">  } </span>

  /**
   * Calculates a prediction for an instance using a set of rules
   * or an M5 model tree
   * 
   * @param inst the instance whos class value is to be predicted
   * @return the prediction
   * @throws Exception if a prediction can't be made.
   */
  public double classifyInstance(Instance inst) throws Exception {
    Rule   temp;
<span class="fc" id="L511">    double prediction = 0;</span>
<span class="fc" id="L512">    boolean success = false;</span>

<span class="fc" id="L514">    m_replaceMissing.input(inst);</span>
<span class="fc" id="L515">    inst = m_replaceMissing.output();</span>
<span class="fc" id="L516">    m_nominalToBinary.input(inst);</span>
<span class="fc" id="L517">    inst = m_nominalToBinary.output();</span>
<span class="fc" id="L518">    m_removeUseless.input(inst);</span>
<span class="fc" id="L519">    inst = m_removeUseless.output();</span>

<span class="pc bpc" id="L521" title="1 of 2 branches missed.">    if (m_ruleSet == null) {</span>
<span class="nc" id="L522">      throw new Exception(&quot;Classifier has not been built yet!&quot;);</span>
    } 

<span class="fc bfc" id="L525" title="All 2 branches covered.">    if (!m_generateRules) {</span>
<span class="fc" id="L526">      temp = (Rule) m_ruleSet.elementAt(0);</span>
<span class="fc" id="L527">      return temp.classifyInstance(inst);</span>
    } 

    boolean cont;
    int     i;

<span class="pc bpc" id="L533" title="1 of 2 branches missed.">    for (i = 0; i &lt; m_ruleSet.size(); i++) {</span>
<span class="fc" id="L534">      cont = false;</span>
<span class="fc" id="L535">      temp = (Rule) m_ruleSet.elementAt(i);</span>

      try {
<span class="fc" id="L538">	prediction = temp.classifyInstance(inst);</span>
<span class="fc" id="L539">	success = true;</span>
<span class="fc" id="L540">      } catch (Exception e) {</span>
<span class="fc" id="L541">	cont = true;</span>
      } 

<span class="fc bfc" id="L544" title="All 2 branches covered.">      if (!cont) {</span>
<span class="fc" id="L545">	break;</span>
      } 
    } 

<span class="pc bpc" id="L549" title="1 of 2 branches missed.">    if (!success) {</span>
<span class="nc" id="L550">      System.out.println(&quot;Error in predicting (DecList)&quot;);</span>
    } 
<span class="fc" id="L552">    return prediction;</span>
  } 

  /**
   * Returns a description of the classifier
   * 
   * @return a description of the classifier as a String
   */
  public String toString() {
<span class="fc" id="L561">    StringBuffer text = new StringBuffer();</span>
    Rule	 temp;

<span class="pc bpc" id="L564" title="1 of 2 branches missed.">    if (m_ruleSet == null) {</span>
<span class="fc" id="L565">      return &quot;Classifier hasn't been built yet!&quot;;</span>
    } 

<span class="nc bnc" id="L568" title="All 2 branches missed.">    if (m_generateRules) {</span>
<span class="nc" id="L569">      text.append(&quot;M5 &quot;</span>
<span class="nc bnc" id="L570" title="All 2 branches missed.">		  + ((m_useUnpruned == true)</span>
<span class="nc" id="L571">		     ? &quot;unpruned &quot;</span>
<span class="nc" id="L572">		     : &quot;pruned &quot;)</span>
<span class="nc bnc" id="L573" title="All 2 branches missed.">		  + ((m_regressionTree == true) </span>
<span class="nc" id="L574">		     ?  &quot;regression &quot;</span>
<span class="nc" id="L575">		     : &quot;model &quot;)</span>
<span class="nc" id="L576">		  + &quot;rules &quot;);</span>

<span class="nc bnc" id="L578" title="All 2 branches missed.">      if (!m_unsmoothedPredictions) {</span>
<span class="nc" id="L579">	text.append(&quot;\n(using smoothed linear models) &quot;);</span>
      }

<span class="nc" id="L582">      text.append(&quot;:\n&quot;);</span>

<span class="nc" id="L584">      text.append(&quot;Number of Rules : &quot; + m_ruleSet.size() + &quot;\n\n&quot;);</span>

<span class="nc bnc" id="L586" title="All 2 branches missed.">      for (int j = 0; j &lt; m_ruleSet.size(); j++) {</span>
<span class="nc" id="L587">	temp = (Rule) m_ruleSet.elementAt(j);</span>

<span class="nc" id="L589">	text.append(&quot;Rule: &quot; + (j + 1) + &quot;\n&quot;);</span>
<span class="nc" id="L590">	text.append(temp.toString());</span>
      } 
    } else {
<span class="nc" id="L593">      temp = (Rule) m_ruleSet.elementAt(0);</span>
<span class="nc" id="L594">      text.append(temp.toString());</span>
    } 
<span class="nc" id="L596">    return text.toString();</span>
  } 

  /**
   * Returns an enumeration of the additional measure names
   * @return an enumeration of the measure names
   */
  public Enumeration enumerateMeasures() {
<span class="nc" id="L604">    Vector newVector = new Vector(1);</span>
<span class="nc" id="L605">    newVector.addElement(&quot;measureNumRules&quot;);</span>
<span class="nc" id="L606">    return newVector.elements();</span>
  }

  /**
   * Returns the value of the named measure
   * @param additionalMeasureName the name of the measure to query for its value
   * @return the value of the named measure
   * @throws Exception if the named measure is not supported
   */
  public double getMeasure(String additionalMeasureName) 
    {
<span class="nc bnc" id="L617" title="All 2 branches missed.">    if (additionalMeasureName.compareToIgnoreCase(&quot;measureNumRules&quot;) == 0) {</span>
<span class="nc" id="L618">      return measureNumRules();</span>
    } else {
<span class="nc" id="L620">      throw new IllegalArgumentException(additionalMeasureName </span>
<span class="nc" id="L621">					 + &quot; not supported (M5)&quot;);</span>
    }
  }

  /**
   * return the number of rules
   * @return the number of rules (same as # linear models &amp;
   * # leaves in the tree)
   */
  public double measureNumRules() {
<span class="nc bnc" id="L631" title="All 2 branches missed.">    if (m_generateRules) {</span>
<span class="nc" id="L632">      return m_ruleSet.size();</span>
    }
<span class="nc" id="L634">    return ((Rule)m_ruleSet.elementAt(0)).m_topOfTree.numberOfLinearModels();</span>
  }

  public RuleNode getM5RootNode() {
<span class="nc" id="L638">    Rule temp = (Rule) m_ruleSet.elementAt(0);</span>
<span class="nc" id="L639">    return temp.getM5RootNode();</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>