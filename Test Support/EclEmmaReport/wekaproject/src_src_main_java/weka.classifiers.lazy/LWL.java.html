<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>LWL.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.lazy</a> &gt; <span class="el_source">LWL.java</span></div><h1>LWL.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    LWL.java
 *    Copyright (C) 1999, 2002, 2003 University of Waikato, Hamilton, New Zealand
 *
 */

package weka.classifiers.lazy;

import weka.classifiers.Classifier;
import weka.classifiers.SingleClassifierEnhancer;
import weka.classifiers.UpdateableClassifier;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.neighboursearch.NearestNeighbourSearch;
import weka.core.Option;
import weka.core.RevisionUtils;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.WeightedInstancesHandler;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;

import java.util.Enumeration;
import java.util.Vector;

/**
 &lt;!-- globalinfo-start --&gt;
 * Locally weighted learning. Uses an instance-based algorithm to assign instance weights which are then used by a specified WeightedInstancesHandler.&lt;br/&gt;
 * Can do classification (e.g. using naive Bayes) or regression (e.g. using linear regression).&lt;br/&gt;
 * &lt;br/&gt;
 * For more info, see&lt;br/&gt;
 * &lt;br/&gt;
 * Eibe Frank, Mark Hall, Bernhard Pfahringer: Locally Weighted Naive Bayes. In: 19th Conference in Uncertainty in Artificial Intelligence, 249-256, 2003.&lt;br/&gt;
 * &lt;br/&gt;
 * C. Atkeson, A. Moore, S. Schaal (1996). Locally weighted learning. AI Review..
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;inproceedings{Frank2003,
 *    author = {Eibe Frank and Mark Hall and Bernhard Pfahringer},
 *    booktitle = {19th Conference in Uncertainty in Artificial Intelligence},
 *    pages = {249-256},
 *    publisher = {Morgan Kaufmann},
 *    title = {Locally Weighted Naive Bayes},
 *    year = {2003}
 * }
 * 
 * &amp;#64;article{Atkeson1996,
 *    author = {C. Atkeson and A. Moore and S. Schaal},
 *    journal = {AI Review},
 *    title = {Locally weighted learning},
 *    year = {1996}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -A
 *  The nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -K &amp;lt;number of neighbours&amp;gt;
 *  Set the number of neighbours used to set the kernel bandwidth.
 *  (default all)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -U &amp;lt;number of weighting method&amp;gt;
 *  Set the weighting kernel shape to use. 0=Linear, 1=Epanechnikov,
 *  2=Tricube, 3=Inverse, 4=Gaussian.
 *  (default 0 = Linear)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 * &lt;pre&gt; -W
 *  Full name of base classifier.
 *  (default: weka.classifiers.trees.DecisionStump)&lt;/pre&gt;
 * 
 * &lt;pre&gt; 
 * Options specific to classifier weka.classifiers.trees.DecisionStump:
 * &lt;/pre&gt;
 * 
 * &lt;pre&gt; -D
 *  If set, classifier is run in debug mode and
 *  may output additional info to the console&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Len Trigg (trigg@cs.waikato.ac.nz)
 * @author Eibe Frank (eibe@cs.waikato.ac.nz)
 * @author Ashraf M. Kibriya (amk14[at-the-rate]cs[dot]waikato[dot]ac[dot]nz)
 * @version $Revision: 5011 $ 
 */
public class LWL 
  extends SingleClassifierEnhancer
  implements UpdateableClassifier, WeightedInstancesHandler, 
             TechnicalInformationHandler {

  /** for serialization. */
  static final long serialVersionUID = 1979797405383665815L;

  /** The training instances used for classification. */
  protected Instances m_Train;
    
  /** The number of neighbours used to select the kernel bandwidth. */
<span class="fc" id="L132">  protected int m_kNN = -1;</span>

  /** The weighting kernel method currently selected. */
<span class="fc" id="L135">  protected int m_WeightKernel = LINEAR;</span>

  /** True if m_kNN should be set to all instances. */
<span class="fc" id="L138">  protected boolean m_UseAllK = true;</span>
  
  /** The nearest neighbour search algorithm to use. 
   * (Default: weka.core.neighboursearch.LinearNNSearch) 
   */
<span class="fc" id="L143">  protected NearestNeighbourSearch m_NNSearch =  new LinearNNSearch();</span>
  
  /** The available kernel weighting methods. */
  protected static final int LINEAR       = 0;
  protected static final int EPANECHNIKOV = 1;
  protected static final int TRICUBE      = 2;  
  protected static final int INVERSE      = 3;
  protected static final int GAUSS        = 4;
  protected static final int CONSTANT     = 5;

  /** a ZeroR model in case no model can be built from the data. */
  protected Classifier m_ZeroR;
    
  /**
   * Returns a string describing classifier.
   * @return a description suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L162">    return </span>
<span class="nc" id="L163">        &quot;Locally weighted learning. Uses an instance-based algorithm to &quot;</span>
      + &quot;assign instance weights which are then used by a specified &quot;
      + &quot;WeightedInstancesHandler.\n&quot;
      + &quot;Can do classification (e.g. using naive Bayes) or regression &quot;
      + &quot;(e.g. using linear regression).\n\n&quot;
      + &quot;For more info, see\n\n&quot;
<span class="nc" id="L169">      + getTechnicalInformation().toString();</span>
  }

  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;
    TechnicalInformation 	additional;
    
<span class="nc" id="L183">    result = new TechnicalInformation(Type.INPROCEEDINGS);</span>
<span class="nc" id="L184">    result.setValue(Field.AUTHOR, &quot;Eibe Frank and Mark Hall and Bernhard Pfahringer&quot;);</span>
<span class="nc" id="L185">    result.setValue(Field.YEAR, &quot;2003&quot;);</span>
<span class="nc" id="L186">    result.setValue(Field.TITLE, &quot;Locally Weighted Naive Bayes&quot;);</span>
<span class="nc" id="L187">    result.setValue(Field.BOOKTITLE, &quot;19th Conference in Uncertainty in Artificial Intelligence&quot;);</span>
<span class="nc" id="L188">    result.setValue(Field.PAGES, &quot;249-256&quot;);</span>
<span class="nc" id="L189">    result.setValue(Field.PUBLISHER, &quot;Morgan Kaufmann&quot;);</span>
    
<span class="nc" id="L191">    additional = result.add(Type.ARTICLE);</span>
<span class="nc" id="L192">    additional.setValue(Field.AUTHOR, &quot;C. Atkeson and A. Moore and S. Schaal&quot;);</span>
<span class="nc" id="L193">    additional.setValue(Field.YEAR, &quot;1996&quot;);</span>
<span class="nc" id="L194">    additional.setValue(Field.TITLE, &quot;Locally weighted learning&quot;);</span>
<span class="nc" id="L195">    additional.setValue(Field.JOURNAL, &quot;AI Review&quot;);</span>
    
<span class="nc" id="L197">    return result;</span>
  }
    
  /**
   * Constructor.
   */
<span class="fc" id="L203">  public LWL() {    </span>
<span class="fc" id="L204">    m_Classifier = new weka.classifiers.trees.DecisionStump();</span>
<span class="fc" id="L205">  }</span>

  /**
   * String describing default classifier.
   * 
   * @return the default classifier classname
   */
  protected String defaultClassifierString() {
    
<span class="fc" id="L214">    return &quot;weka.classifiers.trees.DecisionStump&quot;;</span>
  }

  /**
   * Returns an enumeration of the additional measure names 
   * produced by the neighbour search algorithm.
   * @return an enumeration of the measure names
   */
  public Enumeration enumerateMeasures() {
<span class="nc" id="L223">    return m_NNSearch.enumerateMeasures();</span>
  }
  
  /**
   * Returns the value of the named measure from the 
   * neighbour search algorithm.
   * @param additionalMeasureName the name of the measure to query for its value
   * @return the value of the named measure
   * @throws IllegalArgumentException if the named measure is not supported
   */
  public double getMeasure(String additionalMeasureName) {
<span class="nc" id="L234">    return m_NNSearch.getMeasure(additionalMeasureName);</span>
  }

  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration listOptions() {
    
<span class="fc" id="L244">    Vector newVector = new Vector(3);</span>
<span class="fc" id="L245">    newVector.addElement(new Option(&quot;\tThe nearest neighbour search &quot; +</span>
                                    &quot;algorithm to use &quot; +
                                    &quot;(default: weka.core.neighboursearch.LinearNNSearch).\n&quot;,
<span class="fc" id="L248">                                    &quot;A&quot;, 0, &quot;-A&quot;));</span>
<span class="fc" id="L249">    newVector.addElement(new Option(&quot;\tSet the number of neighbours used to set&quot;</span>
				    +&quot; the kernel bandwidth.\n&quot;
				    +&quot;\t(default all)&quot;,
<span class="fc" id="L252">				    &quot;K&quot;, 1, &quot;-K &lt;number of neighbours&gt;&quot;));</span>
<span class="fc" id="L253">    newVector.addElement(new Option(&quot;\tSet the weighting kernel shape to use.&quot;</span>
				    +&quot; 0=Linear, 1=Epanechnikov,\n&quot;
				    +&quot;\t2=Tricube, 3=Inverse, 4=Gaussian.\n&quot;
				    +&quot;\t(default 0 = Linear)&quot;,
<span class="fc" id="L257">				    &quot;U&quot;, 1,&quot;-U &lt;number of weighting method&gt;&quot;));</span>
    
<span class="fc" id="L259">    Enumeration enu = super.listOptions();</span>
<span class="fc bfc" id="L260" title="All 2 branches covered.">    while (enu.hasMoreElements()) {</span>
<span class="fc" id="L261">      newVector.addElement(enu.nextElement());</span>
    }

<span class="fc" id="L264">    return newVector.elements();</span>
  }

  /**
   * Parses a given list of options. &lt;p/&gt;
   *
   &lt;!-- options-start --&gt;
   * Valid options are: &lt;p/&gt;
   * 
   * &lt;pre&gt; -A
   *  The nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -K &amp;lt;number of neighbours&amp;gt;
   *  Set the number of neighbours used to set the kernel bandwidth.
   *  (default all)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -U &amp;lt;number of weighting method&amp;gt;
   *  Set the weighting kernel shape to use. 0=Linear, 1=Epanechnikov,
   *  2=Tricube, 3=Inverse, 4=Gaussian.
   *  (default 0 = Linear)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -D
   *  If set, classifier is run in debug mode and
   *  may output additional info to the console&lt;/pre&gt;
   * 
   * &lt;pre&gt; -W
   *  Full name of base classifier.
   *  (default: weka.classifiers.trees.DecisionStump)&lt;/pre&gt;
   * 
   * &lt;pre&gt; 
   * Options specific to classifier weka.classifiers.trees.DecisionStump:
   * &lt;/pre&gt;
   * 
   * &lt;pre&gt; -D
   *  If set, classifier is run in debug mode and
   *  may output additional info to the console&lt;/pre&gt;
   * 
   &lt;!-- options-end --&gt;
   *
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {

<span class="fc" id="L309">    String knnString = Utils.getOption('K', options);</span>
<span class="fc bfc" id="L310" title="All 2 branches covered.">    if (knnString.length() != 0) {</span>
<span class="fc" id="L311">      setKNN(Integer.parseInt(knnString));</span>
    } else {
<span class="fc" id="L313">      setKNN(-1);</span>
    }

<span class="fc" id="L316">    String weightString = Utils.getOption('U', options);</span>
<span class="fc bfc" id="L317" title="All 2 branches covered.">    if (weightString.length() != 0) {</span>
<span class="fc" id="L318">      setWeightingKernel(Integer.parseInt(weightString));</span>
    } else {
<span class="fc" id="L320">      setWeightingKernel(LINEAR);</span>
    }
    
<span class="fc" id="L323">    String nnSearchClass = Utils.getOption('A', options);</span>
<span class="fc bfc" id="L324" title="All 2 branches covered.">    if(nnSearchClass.length() != 0) {</span>
<span class="fc" id="L325">      String nnSearchClassSpec[] = Utils.splitOptions(nnSearchClass);</span>
<span class="pc bpc" id="L326" title="1 of 2 branches missed.">      if(nnSearchClassSpec.length == 0) { </span>
<span class="nc" id="L327">        throw new Exception(&quot;Invalid NearestNeighbourSearch algorithm &quot; +</span>
                            &quot;specification string.&quot;); 
      }
<span class="fc" id="L330">      String className = nnSearchClassSpec[0];</span>
<span class="fc" id="L331">      nnSearchClassSpec[0] = &quot;&quot;;</span>

<span class="fc" id="L333">      setNearestNeighbourSearchAlgorithm( (NearestNeighbourSearch)</span>
<span class="fc" id="L334">                  Utils.forName( NearestNeighbourSearch.class, </span>
<span class="fc" id="L335">                                 className, </span>
<span class="fc" id="L336">                                 nnSearchClassSpec)</span>
                                        );
    }
    else 
<span class="fc" id="L340">      this.setNearestNeighbourSearchAlgorithm(new LinearNNSearch());</span>

<span class="fc" id="L342">    super.setOptions(options);</span>
<span class="fc" id="L343">  }</span>

  /**
   * Gets the current settings of the classifier.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String [] getOptions() {

<span class="fc" id="L352">    String [] superOptions = super.getOptions();</span>
<span class="fc" id="L353">    String [] options = new String [superOptions.length + 6];</span>

<span class="fc" id="L355">    int current = 0;</span>

<span class="fc" id="L357">    options[current++] = &quot;-U&quot;; options[current++] = &quot;&quot; + getWeightingKernel();</span>
<span class="pc bpc" id="L358" title="1 of 4 branches missed.">    if ( (getKNN() == 0) &amp;&amp; m_UseAllK) {</span>
<span class="fc" id="L359">      options[current++] = &quot;-K&quot;; options[current++] = &quot;-1&quot;;</span>
    }
    else {
<span class="fc" id="L362">      options[current++] = &quot;-K&quot;; options[current++] = &quot;&quot; + getKNN();</span>
    }
<span class="fc" id="L364">    options[current++] = &quot;-A&quot;;</span>
<span class="fc" id="L365">    options[current++] = m_NNSearch.getClass().getName()+&quot; &quot;+Utils.joinOptions(m_NNSearch.getOptions()); </span>

<span class="fc" id="L367">    System.arraycopy(superOptions, 0, options, current,</span>
<span class="fc" id="L368">                     superOptions.length);</span>

<span class="fc" id="L370">    return options;</span>
  }
  
  /**
   * Returns the tip text for this property.
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String KNNTipText() {
<span class="nc" id="L379">    return &quot;How many neighbours are used to determine the width of the &quot;</span>
      + &quot;weighting function (&lt;= 0 means all neighbours).&quot;;
  }

  /**
   * Sets the number of neighbours used for kernel bandwidth setting.
   * The bandwidth is taken as the distance to the kth neighbour.
   *
   * @param knn the number of neighbours included inside the kernel
   * bandwidth, or 0 to specify using all neighbors.
   */
  public void setKNN(int knn) {

<span class="fc" id="L392">    m_kNN = knn;</span>
<span class="pc bpc" id="L393" title="1 of 2 branches missed.">    if (knn &lt;= 0) {</span>
<span class="fc" id="L394">      m_kNN = 0;</span>
<span class="fc" id="L395">      m_UseAllK = true;</span>
    } else {
<span class="nc" id="L397">      m_UseAllK = false;</span>
    }
<span class="fc" id="L399">  }</span>

  /**
   * Gets the number of neighbours used for kernel bandwidth setting.
   * The bandwidth is taken as the distance to the kth neighbour.
   *
   * @return the number of neighbours included inside the kernel
   * bandwidth, or 0 for all neighbours
   */
  public int getKNN() {

<span class="fc" id="L410">    return m_kNN;</span>
  }

  /**
   * Returns the tip text for this property.
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String weightingKernelTipText() {
<span class="nc" id="L419">    return &quot;Determines weighting function. [0 = Linear, 1 = Epnechnikov,&quot;+</span>
	   &quot;2 = Tricube, 3 = Inverse, 4 = Gaussian and 5 = Constant. &quot;+
	   &quot;(default 0 = Linear)].&quot;;
  }

  /**
   * Sets the kernel weighting method to use. Must be one of LINEAR, 
   * EPANECHNIKOV,  TRICUBE, INVERSE, GAUSS or CONSTANT, other values
   * are ignored.
   *
   * @param kernel the new kernel method to use. Must be one of LINEAR,
   * EPANECHNIKOV,  TRICUBE, INVERSE, GAUSS or CONSTANT.
   */
  public void setWeightingKernel(int kernel) {

<span class="pc bpc" id="L434" title="1 of 2 branches missed.">    if ((kernel != LINEAR)</span>
<span class="nc bnc" id="L435" title="All 2 branches missed.">	&amp;&amp; (kernel != EPANECHNIKOV)</span>
<span class="nc bnc" id="L436" title="All 2 branches missed.">	&amp;&amp; (kernel != TRICUBE)</span>
<span class="nc bnc" id="L437" title="All 2 branches missed.">	&amp;&amp; (kernel != INVERSE)</span>
<span class="nc bnc" id="L438" title="All 2 branches missed.">	&amp;&amp; (kernel != GAUSS)</span>
<span class="nc bnc" id="L439" title="All 2 branches missed.">	&amp;&amp; (kernel != CONSTANT)) {</span>
<span class="nc" id="L440">      return;</span>
    }
<span class="fc" id="L442">    m_WeightKernel = kernel;</span>
<span class="fc" id="L443">  }</span>

  /**
   * Gets the kernel weighting method to use.
   *
   * @return the new kernel method to use. Will be one of LINEAR,
   * EPANECHNIKOV,  TRICUBE, INVERSE, GAUSS or CONSTANT.
   */
  public int getWeightingKernel() {

<span class="fc" id="L453">    return m_WeightKernel;</span>
  }

  /**
   * Returns the tip text for this property.
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String nearestNeighbourSearchAlgorithmTipText() {
<span class="nc" id="L462">    return &quot;The nearest neighbour search algorithm to use (Default: LinearNN).&quot;;</span>
  }
  
  /**
   * Returns the current nearestNeighbourSearch algorithm in use.
   * @return the NearestNeighbourSearch algorithm currently in use.
   */
  public NearestNeighbourSearch getNearestNeighbourSearchAlgorithm() {
<span class="nc" id="L470">    return m_NNSearch;</span>
  }
  
  /**
   * Sets the nearestNeighbourSearch algorithm to be used for finding nearest
   * neighbour(s).
   * @param nearestNeighbourSearchAlgorithm - The NearestNeighbourSearch class.
   */
  public void setNearestNeighbourSearchAlgorithm(NearestNeighbourSearch nearestNeighbourSearchAlgorithm) {
<span class="fc" id="L479">    m_NNSearch = nearestNeighbourSearchAlgorithm;</span>
<span class="fc" id="L480">  }</span>

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
    Capabilities      result;
    
<span class="pc bpc" id="L490" title="1 of 2 branches missed.">    if (m_Classifier != null)</span>
<span class="fc" id="L491">      result = m_Classifier.getCapabilities();</span>
    else
<span class="nc" id="L493">      result = super.getCapabilities();</span>
    
<span class="fc" id="L495">    result.setMinimumNumberInstances(0);</span>
    
    // set dependencies
<span class="fc bfc" id="L498" title="All 2 branches covered.">    for (Capability cap: Capability.values())</span>
<span class="fc" id="L499">      result.enableDependency(cap);</span>
    
<span class="fc" id="L501">    return result;</span>
  }
  
  /**
   * Generates the classifier.
   *
   * @param instances set of instances serving as training data 
   * @throws Exception if the classifier has not been generated successfully
   */
  public void buildClassifier(Instances instances) throws Exception {

<span class="pc bpc" id="L512" title="1 of 2 branches missed.">    if (!(m_Classifier instanceof WeightedInstancesHandler)) {</span>
<span class="nc" id="L513">      throw new IllegalArgumentException(&quot;Classifier must be a &quot;</span>
					 + &quot;WeightedInstancesHandler!&quot;);
    }

    // can classifier handle the data?
<span class="fc" id="L518">    getCapabilities().testWithFail(instances);</span>

    // remove instances with missing class
<span class="fc" id="L521">    instances = new Instances(instances);</span>
<span class="fc" id="L522">    instances.deleteWithMissingClass();</span>
    
    // only class? -&gt; build ZeroR model
<span class="fc bfc" id="L525" title="All 2 branches covered.">    if (instances.numAttributes() == 1) {</span>
<span class="fc" id="L526">      System.err.println(</span>
<span class="fc" id="L527">	  &quot;Cannot build model (only class attribute present in data!), &quot;</span>
	  + &quot;using ZeroR model instead!&quot;);
<span class="fc" id="L529">      m_ZeroR = new weka.classifiers.rules.ZeroR();</span>
<span class="fc" id="L530">      m_ZeroR.buildClassifier(instances);</span>
<span class="fc" id="L531">      return;</span>
    }
    else {
<span class="fc" id="L534">      m_ZeroR = null;</span>
    }
    
<span class="fc" id="L537">    m_Train = new Instances(instances, 0, instances.numInstances());</span>

<span class="fc" id="L539">    m_NNSearch.setInstances(m_Train);</span>
<span class="fc" id="L540">  }</span>

  /**
   * Adds the supplied instance to the training set.
   *
   * @param instance the instance to add
   * @throws Exception if instance could not be incorporated
   * successfully
   */
  public void updateClassifier(Instance instance) throws Exception {

<span class="pc bpc" id="L551" title="1 of 2 branches missed.">    if (m_Train == null) {</span>
<span class="nc" id="L552">      throw new Exception(&quot;No training instance structure set!&quot;);</span>
    }
<span class="pc bpc" id="L554" title="1 of 2 branches missed.">    else if (m_Train.equalHeaders(instance.dataset()) == false) {</span>
<span class="nc" id="L555">      throw new Exception(&quot;Incompatible instance types&quot;);</span>
    }
<span class="pc bpc" id="L557" title="1 of 2 branches missed.">    if (!instance.classIsMissing()) {</span>
<span class="fc" id="L558">      m_NNSearch.update(instance);</span>
<span class="fc" id="L559">      m_Train.add(instance);</span>
    }
<span class="fc" id="L561">  }</span>
  
  /**
   * Calculates the class membership probabilities for the given test instance.
   *
   * @param instance the instance to be classified
   * @return preedicted class probability distribution
   * @throws Exception if distribution can't be computed successfully
   */
  public double[] distributionForInstance(Instance instance) throws Exception {
    
    // default model?
<span class="fc bfc" id="L573" title="All 2 branches covered.">    if (m_ZeroR != null) {</span>
<span class="fc" id="L574">      return m_ZeroR.distributionForInstance(instance);</span>
    }
    
<span class="fc bfc" id="L577" title="All 2 branches covered.">    if (m_Train.numInstances() == 0) {</span>
<span class="fc" id="L578">      throw new Exception(&quot;No training instances!&quot;);</span>
    }
    
<span class="fc" id="L581">    m_NNSearch.addInstanceInfo(instance);</span>
    
<span class="fc" id="L583">    int k = m_Train.numInstances();</span>
<span class="pc bpc" id="L584" title="3 of 4 branches missed.">    if( (!m_UseAllK &amp;&amp; (m_kNN &lt; k)) &amp;&amp;</span>
<span class="nc bnc" id="L585" title="All 2 branches missed.">       !(m_WeightKernel==INVERSE ||</span>
<span class="nc bnc" id="L586" title="All 2 branches missed.">         m_WeightKernel==GAUSS) ) {</span>
<span class="nc" id="L587">      k = m_kNN;</span>
    }
    
<span class="fc" id="L590">    Instances neighbours = m_NNSearch.kNearestNeighbours(instance, k);</span>
<span class="fc" id="L591">    double distances[] = m_NNSearch.getDistances();</span>

<span class="pc bpc" id="L593" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L594">      System.out.println(&quot;Test Instance: &quot;+instance);</span>
<span class="nc" id="L595">      System.out.println(&quot;For &quot;+k+&quot; kept &quot; + neighbours.numInstances() + &quot; out of &quot; + </span>
<span class="nc" id="L596">                         m_Train.numInstances() + &quot; instances.&quot;);</span>
    }
    
    //IF LinearNN has skipped so much that &lt;k neighbours are remaining.
<span class="pc bpc" id="L600" title="1 of 2 branches missed.">    if(k&gt;distances.length)</span>
<span class="nc" id="L601">      k = distances.length;</span>

<span class="pc bpc" id="L603" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L604">      System.out.println(&quot;Instance Distances&quot;);</span>
<span class="nc bnc" id="L605" title="All 2 branches missed.">      for (int i = 0; i &lt; distances.length; i++) {</span>
<span class="nc" id="L606">	System.out.println(&quot;&quot; + distances[i]);</span>
      }
    }

    // Determine the bandwidth
<span class="fc" id="L611">    double bandwidth = distances[k-1];</span>

    // Check for bandwidth zero
<span class="fc bfc" id="L614" title="All 2 branches covered.">    if (bandwidth &lt;= 0) {</span>
      //if the kth distance is zero than give all instances the same weight
<span class="fc bfc" id="L616" title="All 2 branches covered.">      for(int i=0; i &lt; distances.length; i++)</span>
<span class="fc" id="L617">        distances[i] = 1;</span>
    } else {
      // Rescale the distances by the bandwidth
<span class="fc bfc" id="L620" title="All 2 branches covered.">      for (int i = 0; i &lt; distances.length; i++)</span>
<span class="fc" id="L621">        distances[i] = distances[i] / bandwidth;</span>
    }
    
    // Pass the distances through a weighting kernel
<span class="fc bfc" id="L625" title="All 2 branches covered.">    for (int i = 0; i &lt; distances.length; i++) {</span>
<span class="pc bpc" id="L626" title="6 of 7 branches missed.">      switch (m_WeightKernel) {</span>
        case LINEAR:
<span class="fc" id="L628">          distances[i] = 1.0001 - distances[i];</span>
<span class="fc" id="L629">          break;</span>
        case EPANECHNIKOV:
<span class="nc" id="L631">          distances[i] = 3/4D*(1.0001 - distances[i]*distances[i]);</span>
<span class="nc" id="L632">          break;</span>
        case TRICUBE:
<span class="nc" id="L634">          distances[i] = Math.pow( (1.0001 - Math.pow(distances[i], 3)), 3 );</span>
<span class="nc" id="L635">          break;</span>
        case CONSTANT:
          //System.err.println(&quot;using constant kernel&quot;);
<span class="nc" id="L638">          distances[i] = 1;</span>
<span class="nc" id="L639">          break;</span>
        case INVERSE:
<span class="nc" id="L641">          distances[i] = 1.0 / (1.0 + distances[i]);</span>
<span class="nc" id="L642">          break;</span>
        case GAUSS:
<span class="nc" id="L644">          distances[i] = Math.exp(-distances[i] * distances[i]);</span>
          break;
      }
    }

<span class="pc bpc" id="L649" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L650">      System.out.println(&quot;Instance Weights&quot;);</span>
<span class="nc bnc" id="L651" title="All 2 branches missed.">      for (int i = 0; i &lt; distances.length; i++) {</span>
<span class="nc" id="L652">	System.out.println(&quot;&quot; + distances[i]);</span>
      }
    }
    
    // Set the weights on the training data
<span class="fc" id="L657">    double sumOfWeights = 0, newSumOfWeights = 0;</span>
<span class="fc bfc" id="L658" title="All 2 branches covered.">    for (int i = 0; i &lt; distances.length; i++) {</span>
<span class="fc" id="L659">      double weight = distances[i];</span>
<span class="fc" id="L660">      Instance inst = (Instance) neighbours.instance(i);</span>
<span class="fc" id="L661">      sumOfWeights += inst.weight();</span>
<span class="fc" id="L662">      newSumOfWeights += inst.weight() * weight;</span>
<span class="fc" id="L663">      inst.setWeight(inst.weight() * weight);</span>
      //weightedTrain.add(newInst);
    }
    
    // Rescale weights
<span class="fc bfc" id="L668" title="All 2 branches covered.">    for (int i = 0; i &lt; neighbours.numInstances(); i++) {</span>
<span class="fc" id="L669">      Instance inst = neighbours.instance(i);</span>
<span class="fc" id="L670">      inst.setWeight(inst.weight() * sumOfWeights / newSumOfWeights);</span>
    }

    // Create a weighted classifier
<span class="fc" id="L674">    m_Classifier.buildClassifier(neighbours);</span>

<span class="pc bpc" id="L676" title="1 of 2 branches missed.">    if (m_Debug) {</span>
<span class="nc" id="L677">      System.out.println(&quot;Classifying test instance: &quot; + instance);</span>
<span class="nc" id="L678">      System.out.println(&quot;Built base classifier:\n&quot; </span>
<span class="nc" id="L679">			 + m_Classifier.toString());</span>
    }

    // Return the classifier's predictions
<span class="fc" id="L683">    return m_Classifier.distributionForInstance(instance);</span>
  }
 
  /**
   * Returns a description of this classifier.
   *
   * @return a description of this classifier as a string.
   */
  public String toString() {

    // only ZeroR model?
<span class="pc bpc" id="L694" title="1 of 2 branches missed.">    if (m_ZeroR != null) {</span>
<span class="nc" id="L695">      StringBuffer buf = new StringBuffer();</span>
<span class="nc" id="L696">      buf.append(this.getClass().getName().replaceAll(&quot;.*\\.&quot;, &quot;&quot;) + &quot;\n&quot;);</span>
<span class="nc" id="L697">      buf.append(this.getClass().getName().replaceAll(&quot;.*\\.&quot;, &quot;&quot;).replaceAll(&quot;.&quot;, &quot;=&quot;) + &quot;\n\n&quot;);</span>
<span class="nc" id="L698">      buf.append(&quot;Warning: No model could be built, hence ZeroR model is used:\n\n&quot;);</span>
<span class="nc" id="L699">      buf.append(m_ZeroR.toString());</span>
<span class="nc" id="L700">      return buf.toString();</span>
    }
    
<span class="pc bpc" id="L703" title="1 of 2 branches missed.">    if (m_Train == null) {</span>
<span class="fc" id="L704">      return &quot;Locally weighted learning: No model built yet.&quot;;</span>
    }
<span class="nc" id="L706">    String result = &quot;Locally weighted learning\n&quot;</span>
      + &quot;===========================\n&quot;;

<span class="nc" id="L709">    result += &quot;Using classifier: &quot; + m_Classifier.getClass().getName() + &quot;\n&quot;;</span>

<span class="nc bnc" id="L711" title="All 7 branches missed.">    switch (m_WeightKernel) {</span>
    case LINEAR:
<span class="nc" id="L713">      result += &quot;Using linear weighting kernels\n&quot;;</span>
<span class="nc" id="L714">      break;</span>
    case EPANECHNIKOV:
<span class="nc" id="L716">      result += &quot;Using epanechnikov weighting kernels\n&quot;;</span>
<span class="nc" id="L717">      break;</span>
    case TRICUBE:
<span class="nc" id="L719">      result += &quot;Using tricube weighting kernels\n&quot;;</span>
<span class="nc" id="L720">      break;</span>
    case INVERSE:
<span class="nc" id="L722">      result += &quot;Using inverse-distance weighting kernels\n&quot;;</span>
<span class="nc" id="L723">      break;</span>
    case GAUSS:
<span class="nc" id="L725">      result += &quot;Using gaussian weighting kernels\n&quot;;</span>
<span class="nc" id="L726">      break;</span>
    case CONSTANT:
<span class="nc" id="L728">      result += &quot;Using constant weighting kernels\n&quot;;</span>
      break;
<span class="nc" id="L730">    }</span>
<span class="nc bnc" id="L731" title="All 2 branches missed.">    result += &quot;Using &quot; + (m_UseAllK ? &quot;all&quot; : &quot;&quot; + m_kNN) + &quot; neighbours&quot;;</span>
<span class="nc" id="L732">    return result;</span>
  }
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L741">    return RevisionUtils.extract(&quot;$Revision: 5011 $&quot;);</span>
  }
  
  /**
   * Main method for testing this class.
   *
   * @param argv the options
   */
  public static void main(String [] argv) {
<span class="nc" id="L750">    runClassifier(new LWL(), argv);</span>
<span class="nc" id="L751">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>