<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>FT.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/main/java</a> &gt; <a href="index.source.html" class="el_package">weka.classifiers.trees</a> &gt; <span class="el_source">FT.java</span></div><h1>FT.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 *    FT.java
 *    Copyright (C) 2007 University of Porto, Porto, Portugal
 *
 */

package weka.classifiers.trees;

import weka.classifiers.Classifier;
import weka.classifiers.trees.ft.FTInnerNode;
import weka.classifiers.trees.ft.FTLeavesNode;
import weka.classifiers.trees.ft.FTNode;
import weka.classifiers.trees.ft.FTtree;
import weka.core.AdditionalMeasureProducer;
import weka.core.Capabilities;
import weka.core.Drawable;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.Option;
import weka.core.OptionHandler;
import weka.core.RevisionUtils;
import weka.core.SelectedTag;
import weka.core.Tag;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformationHandler;
import weka.core.Utils;
import weka.core.Capabilities.Capability;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;
import weka.filters.Filter;
import weka.filters.supervised.attribute.NominalToBinary;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

import java.util.Enumeration;
import java.util.Vector;

/**
 &lt;!-- globalinfo-start --&gt;
 * Classifier for building 'Functional trees', which are classification trees  that could have logistic regression functions at the inner nodes and/or leaves. The algorithm can deal with binary and multi-class target variables, numeric and nominal attributes and missing values.&lt;br/&gt;
 * &lt;br/&gt;
 * For more information see: &lt;br/&gt;
 * &lt;br/&gt;
 * Joao Gama (2004). Functional Trees.&lt;br/&gt;
 * &lt;br/&gt;
 * Niels Landwehr, Mark Hall, Eibe Frank (2005). Logistic Model Trees.
 * &lt;p/&gt;
 &lt;!-- globalinfo-end --&gt;
 *
 &lt;!-- technical-bibtex-start --&gt;
 * BibTeX:
 * &lt;pre&gt;
 * &amp;#64;article{Gama2004,
 *    author = {Joao Gama},
 *    booktitle = {Machine Learning},
 *    number = {3},
 *    pages = {219-250},
 *    title = {Functional Trees},
 *    volume = {55},
 *    year = {2004}
 * }
 * 
 * &amp;#64;article{Landwehr2005,
 *    author = {Niels Landwehr and Mark Hall and Eibe Frank},
 *    booktitle = {Machine Learning},
 *    number = {1-2},
 *    pages = {161-205},
 *    title = {Logistic Model Trees},
 *    volume = {95},
 *    year = {2005}
 * }
 * &lt;/pre&gt;
 * &lt;p/&gt;
 &lt;!-- technical-bibtex-end --&gt;
 *
 &lt;!-- options-start --&gt;
 * Valid options are: &lt;p/&gt;
 * 
 * &lt;pre&gt; -B
 *  Binary splits (convert nominal attributes to binary ones) &lt;/pre&gt;
 * 
 * &lt;pre&gt; -P
 *  Use error on probabilities instead of misclassification error for stopping criterion of LogitBoost.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -I &amp;lt;numIterations&amp;gt;
 *  Set fixed number of iterations for LogitBoost (instead of using cross-validation)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -F &amp;lt;modelType&amp;gt;
 *  Set Funtional Tree type to be generate:  0 for FT, 1 for FTLeaves and 2 for FTInner&lt;/pre&gt;
 * 
 * &lt;pre&gt; -M &amp;lt;numInstances&amp;gt;
 *  Set minimum number of instances at which a node can be split (default 15)&lt;/pre&gt;
 * 
 * &lt;pre&gt; -W &amp;lt;beta&amp;gt;
 *  Set beta for weight trimming for LogitBoost. Set to 0 (default) for no weight trimming.&lt;/pre&gt;
 * 
 * &lt;pre&gt; -A
 *  The AIC is used to choose the best iteration.&lt;/pre&gt;
 * 
 &lt;!-- options-end --&gt;
 *
 * @author Jo\~{a}o Gama
 * @author Carlos Ferreira  
 * @version $Revision: 5535 $
 */
<span class="fc" id="L121">public class FT </span>
  extends Classifier 
  implements OptionHandler, AdditionalMeasureProducer, Drawable,
             TechnicalInformationHandler {
    
  /** for serialization */
  static final long serialVersionUID = -1113212459618105000L;
  
  /** Filter to replace missing values*/
  protected ReplaceMissingValues m_replaceMissing;
  
  /** Filter to replace nominal attributes*/
  protected NominalToBinary m_nominalToBinary;
    
  /** root of the logistic model tree*/
  protected FTtree m_tree;
  
  /** convert nominal attributes to binary ?*/
  protected boolean m_convertNominal;
  
  /**use error on probabilties instead of misclassification for stopping criterion of LogitBoost?*/
  protected boolean m_errorOnProbabilities;
    
  /**minimum number of instances at which a node is considered for splitting*/
  protected int m_minNumInstances;

  /**if non-zero, use fixed number of iterations for LogitBoost*/
  protected int m_numBoostingIterations;
  
  /**Model Type, value: 0 is FT, 1 is FTLeaves, 2  is FTInner*/
  protected int m_modelType;
    
  /**Threshold for trimming weights. Instances with a weight lower than this (as a percentage
   * of total weights) are not included in the regression fit.
   **/
  protected double m_weightTrimBeta;
  
  /** If true, the AIC is used to choose the best LogitBoost iteration*/
  protected boolean m_useAIC ;

  /** model types */
  public static final int MODEL_FT = 0;
  public static final int MODEL_FTLeaves = 1;
  public static final int MODEL_FTInner = 2;

  /** possible model types. */
<span class="fc" id="L167">  public static final Tag [] TAGS_MODEL = {</span>
<span class="fc" id="L168">    new Tag(MODEL_FT, &quot;FT&quot;),</span>
<span class="fc" id="L169">    new Tag(MODEL_FTLeaves, &quot;FTLeaves&quot;),</span>
<span class="fc" id="L170">    new Tag(MODEL_FTInner, &quot;FTInner&quot;)</span>
  };

  
  /**
   * Creates an instance of FT with standard options
   */
<span class="fc" id="L177">  public FT() {</span>
<span class="fc" id="L178">    m_numBoostingIterations=15;</span>
<span class="fc" id="L179">    m_minNumInstances = 15;</span>
<span class="fc" id="L180">    m_weightTrimBeta = 0;</span>
<span class="fc" id="L181">    m_useAIC = false;</span>
<span class="fc" id="L182">    m_modelType=0;</span>
<span class="fc" id="L183">  }    </span>

  /**
   * Returns default capabilities of the classifier.
   *
   * @return      the capabilities of this classifier
   */
  public Capabilities getCapabilities() {
<span class="fc" id="L191">    Capabilities result = super.getCapabilities();</span>
<span class="fc" id="L192">    result.disableAll();</span>

    // attributes
<span class="fc" id="L195">    result.enable(Capability.NOMINAL_ATTRIBUTES);</span>
<span class="fc" id="L196">    result.enable(Capability.NUMERIC_ATTRIBUTES);</span>
<span class="fc" id="L197">    result.enable(Capability.DATE_ATTRIBUTES);</span>
<span class="fc" id="L198">    result.enable(Capability.MISSING_VALUES);</span>

    // class
<span class="fc" id="L201">    result.enable(Capability.NOMINAL_CLASS);</span>
<span class="fc" id="L202">    result.enable(Capability.MISSING_CLASS_VALUES);</span>
    
<span class="fc" id="L204">    return result;</span>
  }

  /**
   * Builds the classifier.
   *
   * @param data the data to train with
   * @throws Exception if classifier can't be built successfully
   */
  public void buildClassifier(Instances data) throws Exception{
	
      
    // can classifier handle the data?
<span class="fc" id="L217">    getCapabilities().testWithFail(data);</span>

    // remove instances with missing class
<span class="fc" id="L220">    Instances filteredData = new Instances(data);</span>
<span class="fc" id="L221">    filteredData.deleteWithMissingClass();</span>
    
    //replace missing values
<span class="fc" id="L224">    m_replaceMissing = new ReplaceMissingValues();</span>
<span class="fc" id="L225">    m_replaceMissing.setInputFormat(filteredData);	</span>
<span class="fc" id="L226">    filteredData = Filter.useFilter(filteredData, m_replaceMissing);</span>
    
    //possibly convert nominal attributes globally
<span class="pc bpc" id="L229" title="1 of 2 branches missed.">    if (m_convertNominal) {	    </span>
<span class="nc" id="L230">      m_nominalToBinary = new NominalToBinary();</span>
<span class="nc" id="L231">      m_nominalToBinary.setInputFormat(filteredData);	</span>
<span class="nc" id="L232">      filteredData = Filter.useFilter(filteredData, m_nominalToBinary);</span>
    }
	
<span class="fc" id="L235">    int minNumInstances = 2;  </span>
    
    
    //create a FT  tree root
<span class="pc bpc" id="L239" title="1 of 2 branches missed.">    if (m_modelType==0)</span>
<span class="fc" id="L240">      m_tree = new FTNode( m_errorOnProbabilities, m_numBoostingIterations, m_minNumInstances, </span>
<span class="fc" id="L241">                           m_weightTrimBeta, m_useAIC);</span>
                       
    //create a FTLeaves  tree root
<span class="pc bpc" id="L244" title="1 of 2 branches missed.">    if (m_modelType==1){ </span>
<span class="nc" id="L245">      m_tree = new FTLeavesNode(m_errorOnProbabilities, m_numBoostingIterations, m_minNumInstances, </span>
<span class="nc" id="L246">                                m_weightTrimBeta, m_useAIC);</span>
    }
    //create a FTInner  tree root
<span class="pc bpc" id="L249" title="1 of 2 branches missed.">    if (m_modelType==2)</span>
<span class="nc" id="L250">      m_tree = new FTInnerNode(m_errorOnProbabilities, m_numBoostingIterations, m_minNumInstances, </span>
<span class="nc" id="L251">                               m_weightTrimBeta, m_useAIC);</span>
        
    //build tree
<span class="fc" id="L254">    m_tree.buildClassifier(filteredData);</span>
    // prune tree
<span class="fc" id="L256">    m_tree.prune();</span>
<span class="fc" id="L257">    m_tree.assignIDs(0);</span>
<span class="fc" id="L258">    m_tree.cleanup();         </span>
<span class="fc" id="L259">  }</span>
  
  /** 
   * Returns class probabilities for an instance.
   *
   * @param instance the instance to compute the distribution for
   * @return the class probabilities
   * @throws Exception if distribution can't be computed successfully
   */
  public double [] distributionForInstance(Instance instance) throws Exception {
     
    //replace missing values
<span class="fc" id="L271">    m_replaceMissing.input(instance);</span>
<span class="fc" id="L272">    instance = m_replaceMissing.output();</span>
    
    //possibly convert nominal attributes
<span class="pc bpc" id="L275" title="1 of 2 branches missed.">    if (m_convertNominal) {</span>
<span class="nc" id="L276">      m_nominalToBinary.input(instance);</span>
<span class="nc" id="L277">      instance = m_nominalToBinary.output();</span>
    }
<span class="fc" id="L279">    return m_tree.distributionForInstance(instance);</span>
  }

  /**
   * Classifies an instance.
   *
   * @param instance the instance to classify
   * @return the classification
   * @throws Exception if instance can't be classified successfully
   */
  public double classifyInstance(Instance instance) throws Exception {

<span class="nc" id="L291">    double maxProb = -1;</span>
<span class="nc" id="L292">    int maxIndex = 0;</span>
   
    //classify by maximum probability
<span class="nc" id="L295">    double[] probs = distributionForInstance(instance);       </span>
<span class="nc bnc" id="L296" title="All 2 branches missed.">    for (int j = 0; j &lt; instance.numClasses(); j++) {</span>
<span class="nc bnc" id="L297" title="All 2 branches missed.">      if (Utils.gr(probs[j], maxProb)) {</span>
<span class="nc" id="L298">	maxIndex = j;</span>
<span class="nc" id="L299">	maxProb = probs[j];</span>
      }
    }     
<span class="nc" id="L302">    return (double)maxIndex;      </span>
  }    
     
  /**
   * Returns a description of the classifier.
   * 
   * @return a string representation of the classifier
   */
  public String toString() {
<span class="pc bpc" id="L311" title="1 of 2 branches missed.">    if (m_tree!=null) {</span>
<span class="nc bnc" id="L312" title="All 2 branches missed.">      if (m_modelType==0)</span>
<span class="nc" id="L313">        return &quot;FT tree \n------------------\n&quot; + m_tree.toString();</span>
      else { 
<span class="nc bnc" id="L315" title="All 2 branches missed.">        if (m_modelType==1)</span>
<span class="nc" id="L316">          return &quot;FT Leaves tree \n------------------\n&quot; + m_tree.toString();</span>
        else  
<span class="nc" id="L318">          return &quot;FT Inner tree \n------------------\n&quot; + m_tree.toString();</span>
      }
    }else{
<span class="fc" id="L321">      return &quot;No tree built&quot;;</span>
    }
  }    

  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration listOptions() {
<span class="fc" id="L331">    Vector newVector = new Vector(8);</span>
    
<span class="fc" id="L333">    newVector.addElement(new Option(&quot;\tBinary splits (convert nominal attributes to binary ones) &quot;,</span>
<span class="fc" id="L334">                                    &quot;B&quot;, 0, &quot;-B&quot;));</span>
    
<span class="fc" id="L336">    newVector.addElement(new Option(&quot;\tUse error on probabilities instead of misclassification error &quot;+</span>
                                    &quot;for stopping criterion of LogitBoost.&quot;,
<span class="fc" id="L338">                                    &quot;P&quot;, 0, &quot;-P&quot;));</span>
    
<span class="fc" id="L340">    newVector.addElement(new Option(&quot;\tSet fixed number of iterations for LogitBoost (instead of using &quot;+</span>
                                    &quot;cross-validation)&quot;,
<span class="fc" id="L342">                                    &quot;I&quot;,1,&quot;-I &lt;numIterations&gt;&quot;));</span>
    
<span class="fc" id="L344">    newVector.addElement(new Option(&quot;\tSet Funtional Tree type to be generate: &quot;+</span>
                                    &quot; 0 for FT, 1 for FTLeaves and 2 for FTInner&quot;,
<span class="fc" id="L346">                                    &quot;F&quot;,1,&quot;-F &lt;modelType&gt;&quot;));</span>
    
<span class="fc" id="L348">    newVector.addElement(new Option(&quot;\tSet minimum number of instances at which a node can be split (default 15)&quot;,</span>
<span class="fc" id="L349">                                    &quot;M&quot;,1,&quot;-M &lt;numInstances&gt;&quot;));</span>
    
<span class="fc" id="L351">    newVector.addElement(new Option(&quot;\tSet beta for weight trimming for LogitBoost. Set to 0 (default) for no weight trimming.&quot;,</span>
<span class="fc" id="L352">                                    &quot;W&quot;,1,&quot;-W &lt;beta&gt;&quot;));</span>
    
<span class="fc" id="L354">    newVector.addElement(new Option(&quot;\tThe AIC is used to choose the best iteration.&quot;,</span>
<span class="fc" id="L355">                                    &quot;A&quot;, 0, &quot;-A&quot;));</span>
    
<span class="fc" id="L357">    return newVector.elements();</span>
  }
    
  /**
   * Parses a given list of options. &lt;p/&gt;
   * 
   &lt;!-- options-start --&gt;
   * Valid options are: &lt;p/&gt;
   * 
   * &lt;pre&gt; -B
   *  Binary splits (convert nominal attributes to binary ones) &lt;/pre&gt;
   * 
   * &lt;pre&gt; -P
   *  Use error on probabilities instead of misclassification error for stopping criterion of LogitBoost.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -I &amp;lt;numIterations&amp;gt;
   *  Set fixed number of iterations for LogitBoost (instead of using cross-validation)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -F &amp;lt;modelType&amp;gt;
   *  Set Funtional Tree type to be generate:  0 for FT, 1 for FTLeaves and 2 for FTInner&lt;/pre&gt;
   * 
   * &lt;pre&gt; -M &amp;lt;numInstances&amp;gt;
   *  Set minimum number of instances at which a node can be split (default 15)&lt;/pre&gt;
   * 
   * &lt;pre&gt; -W &amp;lt;beta&amp;gt;
   *  Set beta for weight trimming for LogitBoost. Set to 0 (default) for no weight trimming.&lt;/pre&gt;
   * 
   * &lt;pre&gt; -A
   *  The AIC is used to choose the best iteration.&lt;/pre&gt;
   * 
   &lt;!-- options-end --&gt;
   *
   * @param options the list of options as an array of strings
   * @throws Exception if an option is not supported
   */
  public void setOptions(String[] options) throws Exception {

<span class="fc" id="L394">    setBinSplit(Utils.getFlag('B', options));</span>
<span class="fc" id="L395">    setErrorOnProbabilities(Utils.getFlag('P', options));</span>

<span class="fc" id="L397">    String optionString = Utils.getOption('I', options);</span>
<span class="fc bfc" id="L398" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L399">      setNumBoostingIterations((new Integer(optionString)).intValue());</span>
    }

<span class="fc" id="L402">    optionString = Utils.getOption('F', options);</span>
<span class="fc bfc" id="L403" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L404">      setModelType(new SelectedTag(Integer.parseInt(optionString), TAGS_MODEL));</span>
      // setModelType((new Integer(optionString)).intValue());
    }
    
<span class="fc" id="L408">    optionString = Utils.getOption('M', options);</span>
<span class="fc bfc" id="L409" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L410">      setMinNumInstances((new Integer(optionString)).intValue());</span>
    }

<span class="fc" id="L413">    optionString = Utils.getOption('W', options);</span>
<span class="fc bfc" id="L414" title="All 2 branches covered.">    if (optionString.length() != 0) {</span>
<span class="fc" id="L415">      setWeightTrimBeta((new Double(optionString)).doubleValue());</span>
    }
    
<span class="fc" id="L418">    setUseAIC(Utils.getFlag('A', options));        </span>
    
<span class="fc" id="L420">    Utils.checkForRemainingOptions(options);</span>
	
<span class="fc" id="L422">  } </span>
    
  /**
   * Gets the current settings of the Classifier.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String[] getOptions() {
<span class="fc" id="L430">    String[] options = new String[11];</span>
<span class="fc" id="L431">    int current = 0;</span>

<span class="pc bpc" id="L433" title="1 of 2 branches missed.">    if (getBinSplit()) {</span>
<span class="nc" id="L434">      options[current++] = &quot;-B&quot;;</span>
    } 
    
<span class="pc bpc" id="L437" title="1 of 2 branches missed.">    if (getErrorOnProbabilities()) {</span>
<span class="nc" id="L438">      options[current++] = &quot;-P&quot;;</span>
    }
    
<span class="fc" id="L441">    options[current++] = &quot;-I&quot;; </span>
<span class="fc" id="L442">    options[current++] = &quot;&quot;+getNumBoostingIterations();</span>
    
<span class="fc" id="L444">    options[current++] = &quot;-F&quot;; </span>
    //    options[current++] = &quot;&quot;+getModelType();
<span class="fc" id="L446">    options[current++] = &quot;&quot;+getModelType().getSelectedTag().getID();</span>

<span class="fc" id="L448">    options[current++] = &quot;-M&quot;; </span>
<span class="fc" id="L449">    options[current++] = &quot;&quot;+getMinNumInstances();</span>
        
<span class="fc" id="L451">    options[current++] = &quot;-W&quot;;</span>
<span class="fc" id="L452">    options[current++] = &quot;&quot;+getWeightTrimBeta();</span>
    
<span class="pc bpc" id="L454" title="1 of 2 branches missed.">    if (getUseAIC()) {</span>
<span class="nc" id="L455">      options[current++] = &quot;-A&quot;;</span>
    }
    
<span class="pc bfc" id="L458" title="All 2 branches covered.">    while (current &lt; options.length) {</span>
<span class="fc" id="L459">      options[current++] = &quot;&quot;;</span>
    } 
<span class="fc" id="L461">    return options;</span>
  } 

  
  /**
   * Get the value of weightTrimBeta.
   */
  public double getWeightTrimBeta(){
<span class="fc" id="L469">    return m_weightTrimBeta;</span>
  }
  
  /**
   * Get the value of useAIC.
   *
   * @return Value of useAIC.
   */
  public boolean getUseAIC(){
<span class="fc" id="L478">    return m_useAIC;</span>
  }
 
  
  /**
   * Set the value of weightTrimBeta.
   */
  public void setWeightTrimBeta(double n){
<span class="fc" id="L486">    m_weightTrimBeta = n;</span>
<span class="fc" id="L487">  }</span>
  
  /**
   * Set the value of useAIC.
   *
   * @param c Value to assign to useAIC.
   */
  public void setUseAIC(boolean c){
<span class="fc" id="L495">    m_useAIC = c;</span>
<span class="fc" id="L496">  }</span>
  
  /**
   * Get the value of binarySplits.
   *
   * @return Value of binarySplits.
   */
  public boolean getBinSplit(){
<span class="fc" id="L504">    return m_convertNominal;</span>
  }

  /**
   * Get the value of errorOnProbabilities.
   *
   * @return Value of errorOnProbabilities.
   */
  public boolean getErrorOnProbabilities(){
<span class="fc" id="L513">    return m_errorOnProbabilities;</span>
  }
  
  /**
   * Get the value of numBoostingIterations.
   *
   * @return Value of numBoostingIterations.
   */
  public int getNumBoostingIterations(){
<span class="fc" id="L522">    return m_numBoostingIterations;</span>
  }
  
  /**
   * Get the type of functional tree model being used.
   *
   * @return the type of functional tree model.
   */
  public SelectedTag getModelType() {
<span class="fc" id="L531">    return new SelectedTag(m_modelType, TAGS_MODEL);</span>
  } 

  /**
   * Set the Functional Tree type.
   *
   * @param c Value corresponding to tree type.
   */
  public void setModelType(SelectedTag newMethod){
<span class="pc bpc" id="L540" title="1 of 2 branches missed.">    if (newMethod.getTags() == TAGS_MODEL) {</span>
<span class="fc" id="L541">      int c = newMethod.getSelectedTag().getID();</span>
<span class="pc bpc" id="L542" title="5 of 6 branches missed.">      if (c==0 || c==1 || c==2) {</span>
<span class="fc" id="L543">        m_modelType = c;</span>
      } else  {
<span class="nc" id="L545">        throw new IllegalArgumentException(&quot;Wrong model type, -F value should be: 0, for FT, 1, &quot; +</span>
                                           &quot;for FTLeaves, and 2, for FTInner &quot;); 
      }
    }
<span class="fc" id="L549">  }</span>
  
  /**
   * Get the value of minNumInstances.
   *
   * @return Value of minNumInstances.
   */
  public int getMinNumInstances(){
<span class="fc" id="L557">    return m_minNumInstances;</span>
  }
    
  /**
   * Set the value of binarySplits.
   *
   * @param c Value to assign to binarySplits.
   */
  public void setBinSplit(boolean c){
<span class="fc" id="L566">    m_convertNominal=c;</span>
<span class="fc" id="L567">  }</span>

  /**
   * Set the value of errorOnProbabilities.
   *
   * @param c Value to assign to errorOnProbabilities.
   */
  public void setErrorOnProbabilities(boolean c){
<span class="fc" id="L575">    m_errorOnProbabilities = c;</span>
<span class="fc" id="L576">  }</span>
  
  /**
   * Set the value of numBoostingIterations.
   *
   * @param c Value to assign to numBoostingIterations.
   */
  public void setNumBoostingIterations(int c){
<span class="fc" id="L584">    m_numBoostingIterations = c;</span>
<span class="fc" id="L585">  }</span>
   
  /**
   * Set the value of minNumInstances.
   *
   * @param c Value to assign to minNumInstances.
   */
  public void setMinNumInstances(int c){
<span class="fc" id="L593">    m_minNumInstances = c;</span>
<span class="fc" id="L594">  }</span>
    
  /**
   *  Returns the type of graph this classifier
   *  represents.
   *  @return Drawable.TREE
   */   
  public int graphType() {
<span class="nc" id="L602">    return Drawable.TREE;</span>
  }

  /**
   * Returns graph describing the tree.
   *
   * @return the graph describing the tree
   * @throws Exception if graph can't be computed
   */
  public String graph() throws Exception {

<span class="nc" id="L613">    return m_tree.graph();</span>
  }

  /**
   * Returns the size of the tree
   * @return the size of the tree
   */
  public int measureTreeSize(){
<span class="nc" id="L621">    return m_tree.numNodes();</span>
  }
    
  /**
   * Returns the number of leaves in the tree
   * @return the number of leaves in the tree
   */
  public int measureNumLeaves(){
<span class="nc" id="L629">    return m_tree.numLeaves();</span>
  }
     
  /**
   * Returns an enumeration of the additional measure names
   * @return an enumeration of the measure names
   */
  public Enumeration enumerateMeasures() {
<span class="nc" id="L637">    Vector newVector = new Vector(2);</span>
<span class="nc" id="L638">    newVector.addElement(&quot;measureTreeSize&quot;);</span>
<span class="nc" id="L639">    newVector.addElement(&quot;measureNumLeaves&quot;);</span>
	
<span class="nc" id="L641">    return newVector.elements();</span>
  }
    

  /**
   * Returns the value of the named measure
   * @param additionalMeasureName the name of the measure to query for its value
   * @return the value of the named measure
   * @throws IllegalArgumentException if the named measure is not supported
   */
  public double getMeasure(String additionalMeasureName) {
<span class="nc bnc" id="L652" title="All 2 branches missed.">    if (additionalMeasureName.compareToIgnoreCase(&quot;measureTreeSize&quot;) == 0) {</span>
<span class="nc" id="L653">      return measureTreeSize();</span>
<span class="nc bnc" id="L654" title="All 2 branches missed.">    } else if (additionalMeasureName.compareToIgnoreCase(&quot;measureNumLeaves&quot;) == 0) {</span>
<span class="nc" id="L655">      return measureNumLeaves();</span>
    } else {
<span class="nc" id="L657">      throw new IllegalArgumentException(additionalMeasureName </span>
<span class="nc" id="L658">					 + &quot; not supported (FT)&quot;);</span>
    }
  }    
    
  /**
   * Returns a string describing classifier
   * @return a description suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
<span class="nc" id="L668">    return &quot;Classifier for building 'Functional trees', which are classification trees  that could have &quot;</span>
      +&quot;logistic regression functions at the inner nodes and/or leaves. The algorithm can deal with &quot; 
      +&quot;binary and multi-class target variables, numeric and nominal attributes and missing values.\n\n&quot;
      +&quot;For more information see: \n\n&quot;
<span class="nc" id="L672">      + getTechnicalInformation().toString();</span>
  }


  /**
   * Returns an instance of a TechnicalInformation object, containing 
   * detailed information about the technical background of this class,
   * e.g., paper reference or book this class is based on.
   * 
   * @return the technical information about this class
   */
  public TechnicalInformation getTechnicalInformation() {
    TechnicalInformation 	result;
    TechnicalInformation 	additional;
      
<span class="nc" id="L687">    result = new TechnicalInformation(Type.ARTICLE);</span>
<span class="nc" id="L688">    result.setValue(Field.AUTHOR, &quot;Joao Gama&quot;);</span>
<span class="nc" id="L689">    result.setValue(Field.TITLE, &quot;Functional Trees&quot;);</span>
<span class="nc" id="L690">    result.setValue(Field.BOOKTITLE, &quot;Machine Learning&quot;);</span>
<span class="nc" id="L691">    result.setValue(Field.YEAR, &quot;2004&quot;);</span>
<span class="nc" id="L692">    result.setValue(Field.VOLUME, &quot;55&quot;);</span>
<span class="nc" id="L693">    result.setValue(Field.PAGES, &quot;219-250&quot;);</span>
<span class="nc" id="L694">    result.setValue(Field.NUMBER, &quot;3&quot;);</span>
    
<span class="nc" id="L696">    additional = result.add(Type.ARTICLE);</span>
<span class="nc" id="L697">    additional.setValue(Field.AUTHOR, &quot;Niels Landwehr and Mark Hall and Eibe Frank&quot;);</span>
<span class="nc" id="L698">    additional.setValue(Field.TITLE, &quot;Logistic Model Trees&quot;);</span>
<span class="nc" id="L699">    additional.setValue(Field.BOOKTITLE, &quot;Machine Learning&quot;);</span>
<span class="nc" id="L700">    additional.setValue(Field.YEAR, &quot;2005&quot;);</span>
<span class="nc" id="L701">    additional.setValue(Field.VOLUME, &quot;95&quot;);</span>
<span class="nc" id="L702">    additional.setValue(Field.PAGES, &quot;161-205&quot;);</span>
<span class="nc" id="L703">    additional.setValue(Field.NUMBER, &quot;1-2&quot;);</span>
    
<span class="nc" id="L705">    return result;</span>
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String modelTypeTipText() {
<span class="nc" id="L714">    return &quot;The type of FT model. 0, for FT, 1, &quot; +</span>
      &quot;for FTLeaves, and 2, for FTInner&quot;;
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String binSplitTipText() {
<span class="nc" id="L724">    return &quot;Convert all nominal attributes to binary ones before building the tree. &quot;</span>
      +&quot;This means that all splits in the final tree will be binary.&quot;;
    
  } 
  
  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String errorOnProbabilitiesTipText() {
<span class="nc" id="L735">    return &quot;Minimize error on probabilities instead of misclassification error when cross-validating the number &quot;</span>
      +&quot;of LogitBoost iterations. When set, the number of LogitBoost iterations is chosen that minimizes &quot;
      +&quot;the root mean squared error instead of the misclassification error.&quot;;	   
  } 
  
  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String numBoostingIterationsTipText() {
<span class="nc" id="L746">    return &quot;Set a fixed number of iterations for LogitBoost. If &gt;= 0, this sets a fixed number of LogitBoost &quot;</span>
      +&quot;iterations that is used everywhere in the tree. If &lt; 0, the number is cross-validated.&quot;;
  }  

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String minNumInstancesTipText() {
<span class="nc" id="L756">    return &quot;Set the minimum number of instances at which a node is considered for splitting. &quot;</span>
      +&quot;The default value is 15.&quot;;
  } 
      
  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String weightTrimBetaTipText() {
<span class="nc" id="L766">    return &quot;Set the beta value used for weight trimming in LogitBoost. &quot;</span>
      +&quot;Only instances carrying (1 - beta)% of the weight from previous iteration &quot;
      +&quot;are used in the next iteration. Set to 0 for no weight trimming. &quot;
      +&quot;The default value is 0.&quot;;
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String useAICTipText() {
<span class="nc" id="L778">    return &quot;The AIC is used to determine when to stop LogitBoost iterations. &quot;</span>
      +&quot;The default is not to use AIC.&quot;;
  }
  
  /**
   * Returns the revision string.
   * 
   * @return		the revision
   */
  public String getRevision() {
<span class="nc" id="L788">    return RevisionUtils.extract(&quot;$Revision: 5535 $&quot;);</span>
  }
  
  /**
   * Main method for testing this class
   *
   * @param argv the commandline options 
   */
  public static void main (String [] argv) {	
<span class="nc" id="L797">    runClassifier(new FT(), argv);</span>
<span class="nc" id="L798">  } </span>
}

</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>