<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../../.resources/report.gif" type="image/gif"/><title>NGramTokenizerTest.java</title><link rel="stylesheet" href="../../../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../../.sessions.html" class="el_session">Sessions</a></span><a href="../../../index.html" class="el_report">AllTests (Nov 28, 2015 2:34:31 PM)</a> &gt; <a href="../../index.html" class="el_group">wekaproject</a> &gt; <a href="../index.html" class="el_bundle">src/src/test/java</a> &gt; <a href="index.source.html" class="el_package">weka.core.tokenizers</a> &gt; <span class="el_source">NGramTokenizerTest.java</span></div><h1>NGramTokenizerTest.java</h1><pre class="source lang-java linenums">/*
 *    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

/*
 * Copyright (C) 2007 University of Waikato, Hamilton, New Zealand
 */

package weka.core.tokenizers;

import junit.framework.Test;
import junit.framework.TestSuite;

/**
 * Tests NGramTokenizer. Run from the command line with:&lt;p&gt;
 * java weka.core.tokenizers.NGramTokenizerTest
 *
 * @author FracPete (fracpete at waikato dot ac dot nz)
 * @version $Revision: 1.1 $
 */
public class NGramTokenizerTest
  extends AbstractTokenizerTest {

  public NGramTokenizerTest(String name) {
<span class="nc" id="L37">    super(name);</span>
<span class="nc" id="L38">  }</span>

  /** Creates a default NGramTokenizer */
  public Tokenizer getTokenizer() {
<span class="nc" id="L42">    return new NGramTokenizer();</span>
  }

  /**
   * tests the number of generated tokens
   */
  public void testNumberOfGeneratedTokens() {
    String 	s;
    String[]	result;
    
<span class="nc" id="L52">    s = &quot;HOWEVER, the egg only got larger and larger, and more and more human&quot;;</span>

    // only 1-grams
    try {
<span class="nc" id="L56">      result = Tokenizer.tokenize(m_Tokenizer, new String[]{&quot;-min&quot;, &quot;1&quot;, &quot;-max&quot;, &quot;1&quot;, s});</span>
<span class="nc" id="L57">      assertEquals(&quot;number of tokens differ (1)&quot;, 13, result.length);</span>
    }
<span class="nc" id="L59">    catch (Exception e) {</span>
<span class="nc" id="L60">      fail(&quot;Error tokenizing string '&quot; + s + &quot;'!&quot;);</span>
    }

    // only 2-grams
    try {
<span class="nc" id="L65">      result = Tokenizer.tokenize(m_Tokenizer, new String[]{&quot;-min&quot;, &quot;2&quot;, &quot;-max&quot;, &quot;2&quot;, s});</span>
<span class="nc" id="L66">      assertEquals(&quot;number of tokens differ (2)&quot;, 12, result.length);</span>
    }
<span class="nc" id="L68">    catch (Exception e) {</span>
<span class="nc" id="L69">      fail(&quot;Error tokenizing string '&quot; + s + &quot;'!&quot;);</span>
    }

    // 1 to 3-grams
    try {
<span class="nc" id="L74">      result = Tokenizer.tokenize(m_Tokenizer, new String[]{&quot;-min&quot;, &quot;1&quot;, &quot;-max&quot;, &quot;3&quot;, s});</span>
<span class="nc" id="L75">      assertEquals(&quot;number of tokens differ (3)&quot;, 36, result.length);</span>
    }
<span class="nc" id="L77">    catch (Exception e) {</span>
<span class="nc" id="L78">      fail(&quot;Error tokenizing string '&quot; + s + &quot;'!&quot;);</span>
    }
<span class="nc" id="L80">  }</span>

  public static Test suite() {
<span class="nc" id="L83">    return new TestSuite(NGramTokenizerTest.class);</span>
  }

  public static void main(String[] args){
<span class="nc" id="L87">    junit.textui.TestRunner.run(suite());</span>
<span class="nc" id="L88">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.2.201409121644</span>AllTests (Nov 28, 2015 2:34:31 PM)</div></body></html>